{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-9ec2e831c779>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-9ec2e831c779>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    Designed by Ben Usman, Kun He, and Sarah Adel Bargal, with help from Kate Saenko and Brian Kulis.\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Problem Set 4\n",
    "Designed by Ben Usman, Kun He, and Sarah Adel Bargal, with help from Kate Saenko and Brian Kulis.\n",
    "\n",
    "This assignment will introduce you to:\n",
    "1. Building and training a convolutional network\n",
    "2. Saving snapshots of your trained model\n",
    "3. Reloading weights from a saved model\n",
    "4. Fine-tuning a pre-trained network\n",
    "5. Visualizations using Tensorboard\n",
    "\n",
    "This code has been tested and should for Python 3.5 and 2.7 with tensorflow 1.0.*. Since recently, you can update to recent tensorflow version just by doing `pip install tensorflow`,  or `pip install tensorflow-gpu` if you want to use GPU.\n",
    "\n",
    "**Note:** This notebook contains problem descriptions and demo/starter code. However, you're welcome to implement and submit .py files directly, if that's easier for you. Starter .py files are provided in the same `pset4/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Tutorials\n",
    "\n",
    "You will find these TensorFlow tutorials on CNNs useful:\n",
    " - [Deep MNIST for experts](https://www.tensorflow.org/get_started/mnist/pros)\n",
    " - [Convolutional Neural Networks](https://www.tensorflow.org/tutorials/deep_cnn)\n",
    " \n",
    "Note that there are many ways to implement the same thing in TensorFlow, for example, both tf.nn and tf.layers provide convolutional layers but with slightly different interfaces. You will need to read the documentation of the functions provided below to understand how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Building and Training a ConvNet on SVHN\n",
    "(25 points)\n",
    "\n",
    "First we provide demo code that trains a convolutional network on the [SVHN Dataset](http://ufldl.stanford.edu/housenumbers/).. \n",
    "\n",
    "You will need to download   __Format 2__ from the link above.\n",
    "- Create a directory named `svhn_mat/` in the working directory. Or, you can create it anywhere you want, but change the path in `svhn_dataset_generator` to match it.\n",
    "- Download `train_32x32.mat` and `test_32x32.mat` to this directory.\n",
    "- `extra_32x32.mat` is NOT needed.\n",
    "- You may find the `wget` command useful for downloading on linux. \n",
    "\n",
    "\n",
    "\n",
    "The following defines a generator for the SVHN Dataset, yielding the next batch every time next is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "\n",
    "from six.moves import range\n",
    "\n",
    "import read_data\n",
    "\n",
    "@read_data.restartable\n",
    "def svhn_dataset_generator(dataset_name, batch_size):\n",
    "    assert dataset_name in ['train', 'test']\n",
    "    assert batch_size > 0 or batch_size == -1  # -1 for entire dataset\n",
    "    \n",
    "    path = './svhn_mat/' # path to the SVHN dataset you will download in Q1.1\n",
    "    file_name = '%s_32x32.mat' % dataset_name\n",
    "    file_dict = scipy.io.loadmat(os.path.join(path, file_name))\n",
    "    X_all = file_dict['X'].transpose((3, 0, 1, 2))\n",
    "    #print(X_all.shape)\n",
    "    y_all = file_dict['y']\n",
    "    data_len = X_all.shape[0]\n",
    "    batch_size = batch_size if batch_size > 0 else data_len\n",
    "    \n",
    "    X_all_padded = np.concatenate([X_all, X_all[:batch_size]], axis=0)\n",
    "    y_all_padded = np.concatenate([y_all, y_all[:batch_size]], axis=0)\n",
    "    y_all_padded[y_all_padded == 10] = 0\n",
    "    \n",
    "    for slice_i in range(int(math.ceil(data_len / batch_size))):\n",
    "        idx = slice_i * batch_size\n",
    "        X_batch = X_all_padded[idx:idx + batch_size]\n",
    "        y_batch = np.ravel(y_all_padded[idx:idx + batch_size])\n",
    "        yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following defines the CovNet Model. It has two identical conv layers with 32 5x5 convlution filters, followed by a fully-connected layer to output the logits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def cnn_map(x_):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv1')\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2, name = 'pool1')  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv2')\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2, name = 'pool2')  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "\n",
    "def apply_classification_loss(model_function):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        with tf.device(\"/gpu:0\"):  # use gpu:0 if on GPU\n",
    "            x_ = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "            y_ = tf.placeholder(tf.int32, [None])\n",
    "            y_logits = model_function(x_)\n",
    "            \n",
    "            y_dict = dict(labels=y_, logits=y_logits)\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict)\n",
    "            cross_entropy_loss = tf.reduce_mean(losses)\n",
    "            trainer = tf.train.AdamOptimizer()\n",
    "            train_op = trainer.minimize(cross_entropy_loss)\n",
    "            \n",
    "            y_pred = tf.argmax(tf.nn.softmax(y_logits), dimension=1)\n",
    "            correct_prediction = tf.equal(tf.cast(y_pred, tf.int32), y_)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    model_dict = {'graph': g, 'inputs': [x_, y_], 'train_op': train_op,\n",
    "                  'accuracy': accuracy, 'loss': cross_entropy_loss}\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2 Training SVHN Net\n",
    "Now we train a `cnn_map` net on Format 2 of the SVHN Dataset. We will call this \"SVHN net\". \n",
    "\n",
    "**Note:** training will take a while, so you might want to use GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result for the cnn_map training on SVHN Dataset: **   \n",
    "    Accuracy: 0.825 (averaged over 3 runs)  \n",
    "    Number of epochs: 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_dict, dataset_generators, epoch_n, print_every):\n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for epoch_i in range(epoch_n):\n",
    "            for iter_i, data_batch in enumerate(dataset_generators['train']):\n",
    "                train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
    "                sess.run(model_dict['train_op'], feed_dict=train_feed_dict)\n",
    "                \n",
    "                if iter_i % print_every == 0:\n",
    "                    collect_arr = []\n",
    "                    for test_batch in dataset_generators['test']:\n",
    "                        test_feed_dict = dict(zip(model_dict['inputs'], test_batch))\n",
    "                        to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
    "                        collect_arr.append(sess.run(to_compute, test_feed_dict))\n",
    "                    averages = np.mean(collect_arr, axis=0)\n",
    "                    fmt = (epoch_i, iter_i, ) + tuple(averages)\n",
    "                    print('epoch {:d} iter {:d}, loss: {:.3f}, '\n",
    "                          'accuracy: {:.3f}'.format(*fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_generators = {\n",
    "        'train': svhn_dataset_generator('train', 256),\n",
    "        'test': svhn_dataset_generator('test', 256)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 27.950, accuracy: 0.184\n",
      "epoch 0 iter 20, loss: 2.263, accuracy: 0.164\n",
      "epoch 0 iter 40, loss: 2.240, accuracy: 0.194\n",
      "epoch 0 iter 60, loss: 2.244, accuracy: 0.166\n",
      "epoch 0 iter 80, loss: 2.231, accuracy: 0.199\n",
      "epoch 0 iter 100, loss: 2.226, accuracy: 0.205\n",
      "epoch 0 iter 120, loss: 2.224, accuracy: 0.201\n",
      "epoch 0 iter 140, loss: 2.218, accuracy: 0.208\n",
      "epoch 0 iter 160, loss: 2.176, accuracy: 0.225\n",
      "epoch 0 iter 180, loss: 1.873, accuracy: 0.364\n",
      "epoch 0 iter 200, loss: 1.560, accuracy: 0.494\n",
      "epoch 0 iter 220, loss: 1.374, accuracy: 0.567\n",
      "epoch 0 iter 240, loss: 1.335, accuracy: 0.578\n",
      "epoch 0 iter 260, loss: 1.243, accuracy: 0.608\n",
      "epoch 0 iter 280, loss: 1.208, accuracy: 0.624\n",
      "epoch 1 iter 0, loss: 1.194, accuracy: 0.629\n",
      "epoch 1 iter 20, loss: 1.152, accuracy: 0.643\n",
      "epoch 1 iter 40, loss: 1.177, accuracy: 0.634\n",
      "epoch 1 iter 60, loss: 1.144, accuracy: 0.652\n",
      "epoch 1 iter 80, loss: 1.079, accuracy: 0.676\n",
      "epoch 1 iter 100, loss: 1.082, accuracy: 0.669\n",
      "epoch 1 iter 120, loss: 1.058, accuracy: 0.682\n",
      "epoch 1 iter 140, loss: 1.072, accuracy: 0.677\n",
      "epoch 1 iter 160, loss: 1.021, accuracy: 0.689\n",
      "epoch 1 iter 180, loss: 0.993, accuracy: 0.701\n",
      "epoch 1 iter 200, loss: 0.993, accuracy: 0.700\n",
      "epoch 1 iter 220, loss: 0.982, accuracy: 0.708\n",
      "epoch 1 iter 240, loss: 0.998, accuracy: 0.700\n",
      "epoch 1 iter 260, loss: 1.005, accuracy: 0.697\n",
      "epoch 1 iter 280, loss: 0.977, accuracy: 0.706\n",
      "epoch 2 iter 0, loss: 0.963, accuracy: 0.713\n",
      "epoch 2 iter 20, loss: 0.935, accuracy: 0.721\n",
      "epoch 2 iter 40, loss: 0.932, accuracy: 0.723\n",
      "epoch 2 iter 60, loss: 0.965, accuracy: 0.710\n",
      "epoch 2 iter 80, loss: 0.924, accuracy: 0.724\n",
      "epoch 2 iter 100, loss: 0.907, accuracy: 0.732\n",
      "epoch 2 iter 120, loss: 0.884, accuracy: 0.739\n",
      "epoch 2 iter 140, loss: 0.883, accuracy: 0.738\n",
      "epoch 2 iter 160, loss: 0.922, accuracy: 0.717\n",
      "epoch 2 iter 180, loss: 0.842, accuracy: 0.752\n",
      "epoch 2 iter 200, loss: 0.839, accuracy: 0.751\n",
      "epoch 2 iter 220, loss: 0.872, accuracy: 0.744\n",
      "epoch 2 iter 240, loss: 0.815, accuracy: 0.765\n",
      "epoch 2 iter 260, loss: 0.835, accuracy: 0.755\n",
      "epoch 2 iter 280, loss: 0.784, accuracy: 0.774\n",
      "epoch 3 iter 0, loss: 0.758, accuracy: 0.781\n",
      "epoch 3 iter 20, loss: 0.776, accuracy: 0.774\n",
      "epoch 3 iter 40, loss: 0.761, accuracy: 0.780\n",
      "epoch 3 iter 60, loss: 0.792, accuracy: 0.771\n",
      "epoch 3 iter 80, loss: 0.761, accuracy: 0.781\n",
      "epoch 3 iter 100, loss: 0.781, accuracy: 0.773\n",
      "epoch 3 iter 120, loss: 0.743, accuracy: 0.784\n",
      "epoch 3 iter 140, loss: 0.713, accuracy: 0.800\n",
      "epoch 3 iter 160, loss: 0.705, accuracy: 0.796\n",
      "epoch 3 iter 180, loss: 0.720, accuracy: 0.796\n",
      "epoch 3 iter 200, loss: 0.700, accuracy: 0.802\n",
      "epoch 3 iter 220, loss: 0.690, accuracy: 0.803\n",
      "epoch 3 iter 240, loss: 0.652, accuracy: 0.817\n",
      "epoch 3 iter 260, loss: 0.677, accuracy: 0.806\n",
      "epoch 3 iter 280, loss: 0.678, accuracy: 0.810\n",
      "epoch 4 iter 0, loss: 0.723, accuracy: 0.795\n",
      "epoch 4 iter 20, loss: 0.661, accuracy: 0.815\n",
      "epoch 4 iter 40, loss: 0.669, accuracy: 0.814\n",
      "epoch 4 iter 60, loss: 0.671, accuracy: 0.813\n",
      "epoch 4 iter 80, loss: 0.664, accuracy: 0.816\n",
      "epoch 4 iter 100, loss: 0.651, accuracy: 0.817\n",
      "epoch 4 iter 120, loss: 0.645, accuracy: 0.819\n",
      "epoch 4 iter 140, loss: 0.642, accuracy: 0.823\n",
      "epoch 4 iter 160, loss: 0.638, accuracy: 0.823\n",
      "epoch 4 iter 180, loss: 0.643, accuracy: 0.823\n",
      "epoch 4 iter 200, loss: 0.637, accuracy: 0.823\n",
      "epoch 4 iter 220, loss: 0.652, accuracy: 0.822\n",
      "epoch 4 iter 240, loss: 0.623, accuracy: 0.832\n",
      "epoch 4 iter 260, loss: 0.645, accuracy: 0.825\n",
      "epoch 4 iter 280, loss: 0.648, accuracy: 0.822\n",
      "epoch 5 iter 0, loss: 0.727, accuracy: 0.805\n",
      "epoch 5 iter 20, loss: 0.622, accuracy: 0.829\n",
      "epoch 5 iter 40, loss: 0.655, accuracy: 0.823\n",
      "epoch 5 iter 60, loss: 0.638, accuracy: 0.828\n",
      "epoch 5 iter 80, loss: 0.665, accuracy: 0.827\n",
      "epoch 5 iter 100, loss: 0.613, accuracy: 0.834\n",
      "epoch 5 iter 120, loss: 0.624, accuracy: 0.829\n",
      "epoch 5 iter 140, loss: 0.648, accuracy: 0.833\n",
      "epoch 5 iter 160, loss: 0.637, accuracy: 0.828\n",
      "epoch 5 iter 180, loss: 0.632, accuracy: 0.833\n",
      "epoch 5 iter 200, loss: 0.617, accuracy: 0.837\n",
      "epoch 5 iter 220, loss: 0.635, accuracy: 0.832\n",
      "epoch 5 iter 240, loss: 0.634, accuracy: 0.832\n",
      "epoch 5 iter 260, loss: 0.645, accuracy: 0.830\n",
      "epoch 5 iter 280, loss: 0.646, accuracy: 0.834\n",
      "epoch 6 iter 0, loss: 0.710, accuracy: 0.818\n",
      "epoch 6 iter 20, loss: 0.611, accuracy: 0.839\n",
      "epoch 6 iter 40, loss: 0.651, accuracy: 0.830\n",
      "epoch 6 iter 60, loss: 0.638, accuracy: 0.834\n",
      "epoch 6 iter 80, loss: 0.677, accuracy: 0.830\n",
      "epoch 6 iter 100, loss: 0.673, accuracy: 0.823\n",
      "epoch 6 iter 120, loss: 0.675, accuracy: 0.820\n",
      "epoch 6 iter 140, loss: 0.687, accuracy: 0.830\n",
      "epoch 6 iter 160, loss: 0.656, accuracy: 0.825\n",
      "epoch 6 iter 180, loss: 0.654, accuracy: 0.835\n",
      "epoch 6 iter 200, loss: 0.618, accuracy: 0.843\n",
      "epoch 6 iter 220, loss: 0.647, accuracy: 0.831\n",
      "epoch 6 iter 240, loss: 0.652, accuracy: 0.827\n",
      "epoch 6 iter 260, loss: 0.697, accuracy: 0.820\n",
      "epoch 6 iter 280, loss: 0.644, accuracy: 0.842\n",
      "epoch 7 iter 0, loss: 0.649, accuracy: 0.839\n",
      "epoch 7 iter 20, loss: 0.653, accuracy: 0.841\n",
      "epoch 7 iter 40, loss: 0.686, accuracy: 0.825\n",
      "epoch 7 iter 60, loss: 0.722, accuracy: 0.830\n",
      "epoch 7 iter 80, loss: 0.665, accuracy: 0.832\n",
      "epoch 7 iter 100, loss: 0.691, accuracy: 0.830\n",
      "epoch 7 iter 120, loss: 0.715, accuracy: 0.823\n",
      "epoch 7 iter 140, loss: 0.734, accuracy: 0.830\n",
      "epoch 7 iter 160, loss: 0.725, accuracy: 0.820\n",
      "epoch 7 iter 180, loss: 0.681, accuracy: 0.839\n",
      "epoch 7 iter 200, loss: 0.735, accuracy: 0.816\n",
      "epoch 7 iter 220, loss: 0.692, accuracy: 0.833\n",
      "epoch 7 iter 240, loss: 0.667, accuracy: 0.833\n",
      "epoch 7 iter 260, loss: 0.704, accuracy: 0.833\n",
      "epoch 7 iter 280, loss: 0.710, accuracy: 0.837\n",
      "epoch 8 iter 0, loss: 0.682, accuracy: 0.840\n",
      "epoch 8 iter 20, loss: 0.714, accuracy: 0.836\n",
      "epoch 8 iter 40, loss: 0.706, accuracy: 0.829\n",
      "epoch 8 iter 60, loss: 0.749, accuracy: 0.838\n",
      "epoch 8 iter 80, loss: 0.686, accuracy: 0.840\n",
      "epoch 8 iter 100, loss: 0.734, accuracy: 0.825\n",
      "epoch 8 iter 120, loss: 0.729, accuracy: 0.830\n",
      "epoch 8 iter 140, loss: 0.730, accuracy: 0.833\n",
      "epoch 8 iter 160, loss: 0.729, accuracy: 0.830\n",
      "epoch 8 iter 180, loss: 0.696, accuracy: 0.843\n",
      "epoch 8 iter 200, loss: 0.702, accuracy: 0.841\n",
      "epoch 8 iter 220, loss: 0.774, accuracy: 0.827\n",
      "epoch 8 iter 240, loss: 0.720, accuracy: 0.831\n",
      "epoch 8 iter 260, loss: 0.741, accuracy: 0.833\n",
      "epoch 8 iter 280, loss: 0.752, accuracy: 0.833\n",
      "epoch 9 iter 0, loss: 0.723, accuracy: 0.845\n",
      "epoch 9 iter 20, loss: 0.750, accuracy: 0.838\n",
      "epoch 9 iter 40, loss: 0.781, accuracy: 0.820\n",
      "epoch 9 iter 60, loss: 0.812, accuracy: 0.823\n",
      "epoch 9 iter 80, loss: 0.760, accuracy: 0.838\n",
      "epoch 9 iter 100, loss: 0.770, accuracy: 0.826\n",
      "epoch 9 iter 120, loss: 0.754, accuracy: 0.826\n",
      "epoch 9 iter 140, loss: 0.745, accuracy: 0.835\n",
      "epoch 9 iter 160, loss: 0.745, accuracy: 0.835\n",
      "epoch 9 iter 180, loss: 0.716, accuracy: 0.841\n",
      "epoch 9 iter 200, loss: 0.727, accuracy: 0.842\n",
      "epoch 9 iter 220, loss: 0.873, accuracy: 0.815\n",
      "epoch 9 iter 240, loss: 0.827, accuracy: 0.823\n",
      "epoch 9 iter 260, loss: 0.788, accuracy: 0.835\n",
      "epoch 9 iter 280, loss: 0.809, accuracy: 0.822\n",
      "epoch 10 iter 0, loss: 0.852, accuracy: 0.825\n",
      "epoch 10 iter 20, loss: 0.760, accuracy: 0.841\n",
      "epoch 10 iter 40, loss: 0.863, accuracy: 0.814\n",
      "epoch 10 iter 60, loss: 0.834, accuracy: 0.819\n",
      "epoch 10 iter 80, loss: 0.865, accuracy: 0.825\n",
      "epoch 10 iter 100, loss: 0.887, accuracy: 0.821\n",
      "epoch 10 iter 120, loss: 0.765, accuracy: 0.830\n",
      "epoch 10 iter 140, loss: 0.841, accuracy: 0.837\n",
      "epoch 10 iter 160, loss: 0.787, accuracy: 0.834\n",
      "epoch 10 iter 180, loss: 0.803, accuracy: 0.840\n",
      "epoch 10 iter 200, loss: 0.822, accuracy: 0.837\n",
      "epoch 10 iter 220, loss: 0.898, accuracy: 0.830\n",
      "epoch 10 iter 240, loss: 0.870, accuracy: 0.818\n",
      "epoch 10 iter 260, loss: 0.860, accuracy: 0.835\n",
      "epoch 10 iter 280, loss: 0.821, accuracy: 0.836\n",
      "epoch 11 iter 0, loss: 0.811, accuracy: 0.831\n",
      "epoch 11 iter 20, loss: 0.812, accuracy: 0.838\n",
      "epoch 11 iter 40, loss: 0.835, accuracy: 0.826\n",
      "epoch 11 iter 60, loss: 0.848, accuracy: 0.827\n",
      "epoch 11 iter 80, loss: 0.798, accuracy: 0.832\n",
      "epoch 11 iter 100, loss: 0.946, accuracy: 0.824\n",
      "epoch 11 iter 120, loss: 0.831, accuracy: 0.827\n",
      "epoch 11 iter 140, loss: 0.802, accuracy: 0.834\n",
      "epoch 11 iter 160, loss: 0.797, accuracy: 0.838\n",
      "epoch 11 iter 180, loss: 0.791, accuracy: 0.835\n",
      "epoch 11 iter 200, loss: 0.816, accuracy: 0.841\n",
      "epoch 11 iter 220, loss: 1.131, accuracy: 0.800\n",
      "epoch 11 iter 240, loss: 0.899, accuracy: 0.822\n",
      "epoch 11 iter 260, loss: 0.974, accuracy: 0.827\n",
      "epoch 11 iter 280, loss: 0.900, accuracy: 0.826\n",
      "epoch 12 iter 0, loss: 0.949, accuracy: 0.834\n",
      "epoch 12 iter 20, loss: 0.913, accuracy: 0.833\n",
      "epoch 12 iter 40, loss: 0.951, accuracy: 0.825\n",
      "epoch 12 iter 60, loss: 0.876, accuracy: 0.822\n",
      "epoch 12 iter 80, loss: 0.818, accuracy: 0.821\n",
      "epoch 12 iter 100, loss: 0.988, accuracy: 0.819\n",
      "epoch 12 iter 120, loss: 0.942, accuracy: 0.825\n",
      "epoch 12 iter 140, loss: 0.860, accuracy: 0.832\n",
      "epoch 12 iter 160, loss: 0.869, accuracy: 0.833\n",
      "epoch 12 iter 180, loss: 0.801, accuracy: 0.843\n",
      "epoch 12 iter 200, loss: 0.848, accuracy: 0.837\n",
      "epoch 12 iter 220, loss: 1.109, accuracy: 0.809\n",
      "epoch 12 iter 240, loss: 1.036, accuracy: 0.831\n",
      "epoch 12 iter 260, loss: 0.961, accuracy: 0.826\n",
      "epoch 12 iter 280, loss: 1.080, accuracy: 0.812\n",
      "epoch 13 iter 0, loss: 0.973, accuracy: 0.826\n",
      "epoch 13 iter 20, loss: 0.928, accuracy: 0.835\n",
      "epoch 13 iter 40, loss: 0.928, accuracy: 0.837\n",
      "epoch 13 iter 60, loss: 0.951, accuracy: 0.824\n",
      "epoch 13 iter 80, loss: 0.845, accuracy: 0.836\n",
      "epoch 13 iter 100, loss: 1.010, accuracy: 0.825\n",
      "epoch 13 iter 120, loss: 0.924, accuracy: 0.830\n",
      "epoch 13 iter 140, loss: 0.892, accuracy: 0.840\n",
      "epoch 13 iter 160, loss: 0.899, accuracy: 0.833\n",
      "epoch 13 iter 180, loss: 0.832, accuracy: 0.845\n",
      "epoch 13 iter 200, loss: 0.910, accuracy: 0.831\n",
      "epoch 13 iter 220, loss: 1.114, accuracy: 0.804\n",
      "epoch 13 iter 240, loss: 1.007, accuracy: 0.836\n",
      "epoch 13 iter 260, loss: 1.035, accuracy: 0.824\n",
      "epoch 13 iter 280, loss: 1.103, accuracy: 0.820\n",
      "epoch 14 iter 0, loss: 1.043, accuracy: 0.832\n",
      "epoch 14 iter 20, loss: 1.139, accuracy: 0.817\n",
      "epoch 14 iter 40, loss: 0.964, accuracy: 0.839\n",
      "epoch 14 iter 60, loss: 0.933, accuracy: 0.835\n",
      "epoch 14 iter 80, loss: 0.932, accuracy: 0.835\n",
      "epoch 14 iter 100, loss: 1.203, accuracy: 0.825\n",
      "epoch 14 iter 120, loss: 0.982, accuracy: 0.829\n",
      "epoch 14 iter 140, loss: 1.051, accuracy: 0.829\n",
      "epoch 14 iter 160, loss: 0.959, accuracy: 0.835\n",
      "epoch 14 iter 180, loss: 0.918, accuracy: 0.833\n",
      "epoch 14 iter 200, loss: 0.997, accuracy: 0.829\n",
      "epoch 14 iter 220, loss: 0.930, accuracy: 0.839\n",
      "epoch 14 iter 240, loss: 1.058, accuracy: 0.827\n",
      "epoch 14 iter 260, loss: 1.122, accuracy: 0.823\n",
      "epoch 14 iter 280, loss: 1.064, accuracy: 0.833\n",
      "epoch 15 iter 0, loss: 1.057, accuracy: 0.840\n",
      "epoch 15 iter 20, loss: 1.050, accuracy: 0.833\n",
      "epoch 15 iter 40, loss: 1.051, accuracy: 0.838\n",
      "epoch 15 iter 60, loss: 0.946, accuracy: 0.832\n",
      "epoch 15 iter 80, loss: 1.040, accuracy: 0.832\n",
      "epoch 15 iter 100, loss: 1.107, accuracy: 0.834\n",
      "epoch 15 iter 120, loss: 0.951, accuracy: 0.843\n",
      "epoch 15 iter 140, loss: 1.091, accuracy: 0.831\n",
      "epoch 15 iter 160, loss: 0.968, accuracy: 0.836\n",
      "epoch 15 iter 180, loss: 0.933, accuracy: 0.842\n",
      "epoch 15 iter 200, loss: 1.065, accuracy: 0.832\n",
      "epoch 15 iter 220, loss: 0.997, accuracy: 0.843\n",
      "epoch 15 iter 240, loss: 1.140, accuracy: 0.824\n",
      "epoch 15 iter 260, loss: 1.258, accuracy: 0.820\n",
      "epoch 15 iter 280, loss: 1.059, accuracy: 0.833\n",
      "epoch 16 iter 0, loss: 1.138, accuracy: 0.832\n",
      "epoch 16 iter 20, loss: 1.088, accuracy: 0.838\n",
      "epoch 16 iter 40, loss: 1.105, accuracy: 0.839\n",
      "epoch 16 iter 60, loss: 1.069, accuracy: 0.831\n",
      "epoch 16 iter 80, loss: 1.057, accuracy: 0.837\n",
      "epoch 16 iter 100, loss: 1.179, accuracy: 0.830\n",
      "epoch 16 iter 120, loss: 1.047, accuracy: 0.833\n",
      "epoch 16 iter 140, loss: 1.140, accuracy: 0.827\n",
      "epoch 16 iter 160, loss: 1.119, accuracy: 0.826\n",
      "epoch 16 iter 180, loss: 1.060, accuracy: 0.842\n",
      "epoch 16 iter 200, loss: 1.180, accuracy: 0.825\n",
      "epoch 16 iter 220, loss: 1.045, accuracy: 0.838\n",
      "epoch 16 iter 240, loss: 1.209, accuracy: 0.830\n",
      "epoch 16 iter 260, loss: 1.406, accuracy: 0.813\n",
      "epoch 16 iter 280, loss: 1.109, accuracy: 0.810\n",
      "epoch 17 iter 0, loss: 1.199, accuracy: 0.831\n",
      "epoch 17 iter 20, loss: 1.176, accuracy: 0.841\n",
      "epoch 17 iter 40, loss: 1.199, accuracy: 0.836\n",
      "epoch 17 iter 60, loss: 1.144, accuracy: 0.830\n",
      "epoch 17 iter 80, loss: 1.094, accuracy: 0.841\n",
      "epoch 17 iter 100, loss: 1.186, accuracy: 0.836\n",
      "epoch 17 iter 120, loss: 1.174, accuracy: 0.831\n",
      "epoch 17 iter 140, loss: 1.246, accuracy: 0.826\n",
      "epoch 17 iter 160, loss: 1.247, accuracy: 0.823\n",
      "epoch 17 iter 180, loss: 1.148, accuracy: 0.838\n",
      "epoch 17 iter 200, loss: 1.239, accuracy: 0.825\n",
      "epoch 17 iter 220, loss: 1.065, accuracy: 0.832\n",
      "epoch 17 iter 240, loss: 1.275, accuracy: 0.831\n",
      "epoch 17 iter 260, loss: 1.314, accuracy: 0.818\n",
      "epoch 17 iter 280, loss: 1.139, accuracy: 0.838\n",
      "epoch 18 iter 0, loss: 1.141, accuracy: 0.834\n",
      "epoch 18 iter 20, loss: 1.208, accuracy: 0.832\n",
      "epoch 18 iter 40, loss: 1.125, accuracy: 0.840\n",
      "epoch 18 iter 60, loss: 1.098, accuracy: 0.837\n",
      "epoch 18 iter 80, loss: 1.154, accuracy: 0.841\n",
      "epoch 18 iter 100, loss: 1.234, accuracy: 0.836\n",
      "epoch 18 iter 120, loss: 1.139, accuracy: 0.835\n",
      "epoch 18 iter 140, loss: 1.297, accuracy: 0.829\n",
      "epoch 18 iter 160, loss: 1.272, accuracy: 0.830\n",
      "epoch 18 iter 180, loss: 1.130, accuracy: 0.836\n",
      "epoch 18 iter 200, loss: 1.454, accuracy: 0.818\n",
      "epoch 18 iter 220, loss: 1.117, accuracy: 0.828\n",
      "epoch 18 iter 240, loss: 1.294, accuracy: 0.834\n",
      "epoch 18 iter 260, loss: 1.237, accuracy: 0.831\n",
      "epoch 18 iter 280, loss: 1.216, accuracy: 0.838\n",
      "epoch 19 iter 0, loss: 1.228, accuracy: 0.828\n",
      "epoch 19 iter 20, loss: 1.238, accuracy: 0.842\n",
      "epoch 19 iter 40, loss: 1.267, accuracy: 0.833\n",
      "epoch 19 iter 60, loss: 1.154, accuracy: 0.838\n",
      "epoch 19 iter 80, loss: 1.371, accuracy: 0.821\n",
      "epoch 19 iter 100, loss: 1.337, accuracy: 0.834\n",
      "epoch 19 iter 120, loss: 1.253, accuracy: 0.835\n",
      "epoch 19 iter 140, loss: 1.450, accuracy: 0.817\n",
      "epoch 19 iter 160, loss: 1.255, accuracy: 0.834\n",
      "epoch 19 iter 180, loss: 1.222, accuracy: 0.829\n",
      "epoch 19 iter 200, loss: 1.401, accuracy: 0.819\n",
      "epoch 19 iter 220, loss: 1.203, accuracy: 0.833\n",
      "epoch 19 iter 240, loss: 1.403, accuracy: 0.832\n",
      "epoch 19 iter 260, loss: 1.403, accuracy: 0.824\n",
      "epoch 19 iter 280, loss: 1.272, accuracy: 0.829\n",
      "epoch 20 iter 0, loss: 1.231, accuracy: 0.840\n",
      "epoch 20 iter 20, loss: 1.546, accuracy: 0.832\n",
      "epoch 20 iter 40, loss: 1.291, accuracy: 0.836\n",
      "epoch 20 iter 60, loss: 1.394, accuracy: 0.825\n",
      "epoch 20 iter 80, loss: 1.380, accuracy: 0.822\n",
      "epoch 20 iter 100, loss: 1.348, accuracy: 0.830\n",
      "epoch 20 iter 120, loss: 1.333, accuracy: 0.829\n",
      "epoch 20 iter 140, loss: 1.370, accuracy: 0.826\n",
      "epoch 20 iter 160, loss: 1.340, accuracy: 0.823\n",
      "epoch 20 iter 180, loss: 1.191, accuracy: 0.835\n",
      "epoch 20 iter 200, loss: 1.355, accuracy: 0.835\n",
      "epoch 20 iter 220, loss: 1.238, accuracy: 0.825\n",
      "epoch 20 iter 240, loss: 1.315, accuracy: 0.835\n",
      "epoch 20 iter 260, loss: 1.354, accuracy: 0.830\n",
      "epoch 20 iter 280, loss: 1.285, accuracy: 0.836\n",
      "epoch 21 iter 0, loss: 1.227, accuracy: 0.843\n",
      "epoch 21 iter 20, loss: 1.445, accuracy: 0.836\n",
      "epoch 21 iter 40, loss: 1.380, accuracy: 0.831\n",
      "epoch 21 iter 60, loss: 1.433, accuracy: 0.817\n",
      "epoch 21 iter 80, loss: 1.306, accuracy: 0.834\n",
      "epoch 21 iter 100, loss: 1.390, accuracy: 0.834\n",
      "epoch 21 iter 120, loss: 1.430, accuracy: 0.830\n",
      "epoch 21 iter 140, loss: 1.504, accuracy: 0.823\n",
      "epoch 21 iter 160, loss: 1.342, accuracy: 0.827\n",
      "epoch 21 iter 180, loss: 1.375, accuracy: 0.826\n",
      "epoch 21 iter 200, loss: 1.443, accuracy: 0.834\n",
      "epoch 21 iter 220, loss: 1.410, accuracy: 0.813\n",
      "epoch 21 iter 240, loss: 1.412, accuracy: 0.838\n",
      "epoch 21 iter 260, loss: 1.402, accuracy: 0.839\n",
      "epoch 21 iter 280, loss: 1.313, accuracy: 0.835\n",
      "epoch 22 iter 0, loss: 1.363, accuracy: 0.842\n",
      "epoch 22 iter 20, loss: 1.520, accuracy: 0.835\n",
      "epoch 22 iter 40, loss: 1.505, accuracy: 0.826\n",
      "epoch 22 iter 60, loss: 1.365, accuracy: 0.824\n",
      "epoch 22 iter 80, loss: 1.395, accuracy: 0.841\n",
      "epoch 22 iter 100, loss: 1.403, accuracy: 0.838\n",
      "epoch 22 iter 120, loss: 1.731, accuracy: 0.813\n",
      "epoch 22 iter 140, loss: 1.431, accuracy: 0.828\n",
      "epoch 22 iter 160, loss: 1.401, accuracy: 0.821\n",
      "epoch 22 iter 180, loss: 1.393, accuracy: 0.829\n",
      "epoch 22 iter 200, loss: 1.604, accuracy: 0.831\n",
      "epoch 22 iter 220, loss: 1.397, accuracy: 0.823\n",
      "epoch 22 iter 240, loss: 1.501, accuracy: 0.832\n",
      "epoch 22 iter 260, loss: 1.504, accuracy: 0.829\n",
      "epoch 22 iter 280, loss: 1.283, accuracy: 0.837\n",
      "epoch 23 iter 0, loss: 1.453, accuracy: 0.835\n",
      "epoch 23 iter 20, loss: 1.461, accuracy: 0.846\n",
      "epoch 23 iter 40, loss: 1.448, accuracy: 0.840\n",
      "epoch 23 iter 60, loss: 1.570, accuracy: 0.828\n",
      "epoch 23 iter 80, loss: 1.407, accuracy: 0.846\n",
      "epoch 23 iter 100, loss: 1.460, accuracy: 0.833\n",
      "epoch 23 iter 120, loss: 1.927, accuracy: 0.821\n",
      "epoch 23 iter 140, loss: 1.454, accuracy: 0.833\n",
      "epoch 23 iter 160, loss: 1.409, accuracy: 0.829\n",
      "epoch 23 iter 180, loss: 1.346, accuracy: 0.832\n",
      "epoch 23 iter 200, loss: 1.480, accuracy: 0.828\n",
      "epoch 23 iter 220, loss: 1.328, accuracy: 0.831\n",
      "epoch 23 iter 240, loss: 1.573, accuracy: 0.834\n",
      "epoch 23 iter 260, loss: 1.581, accuracy: 0.824\n",
      "epoch 23 iter 280, loss: 1.413, accuracy: 0.841\n",
      "epoch 24 iter 0, loss: 1.405, accuracy: 0.836\n",
      "epoch 24 iter 20, loss: 1.611, accuracy: 0.835\n",
      "epoch 24 iter 40, loss: 1.531, accuracy: 0.833\n",
      "epoch 24 iter 60, loss: 1.419, accuracy: 0.830\n",
      "epoch 24 iter 80, loss: 1.543, accuracy: 0.837\n",
      "epoch 24 iter 100, loss: 1.457, accuracy: 0.833\n",
      "epoch 24 iter 120, loss: 1.610, accuracy: 0.833\n",
      "epoch 24 iter 140, loss: 1.537, accuracy: 0.828\n",
      "epoch 24 iter 160, loss: 1.576, accuracy: 0.830\n",
      "epoch 24 iter 180, loss: 1.413, accuracy: 0.824\n",
      "epoch 24 iter 200, loss: 1.568, accuracy: 0.825\n",
      "epoch 24 iter 220, loss: 1.445, accuracy: 0.823\n",
      "epoch 24 iter 240, loss: 1.807, accuracy: 0.825\n",
      "epoch 24 iter 260, loss: 1.611, accuracy: 0.829\n",
      "epoch 24 iter 280, loss: 1.532, accuracy: 0.842\n",
      "epoch 25 iter 0, loss: 1.523, accuracy: 0.836\n",
      "epoch 25 iter 20, loss: 1.615, accuracy: 0.840\n",
      "epoch 25 iter 40, loss: 1.578, accuracy: 0.837\n",
      "epoch 25 iter 60, loss: 1.567, accuracy: 0.835\n",
      "epoch 25 iter 80, loss: 1.577, accuracy: 0.830\n",
      "epoch 25 iter 100, loss: 1.701, accuracy: 0.824\n",
      "epoch 25 iter 120, loss: 1.761, accuracy: 0.832\n",
      "epoch 25 iter 140, loss: 1.576, accuracy: 0.831\n",
      "epoch 25 iter 160, loss: 1.697, accuracy: 0.830\n",
      "epoch 25 iter 180, loss: 1.420, accuracy: 0.837\n",
      "epoch 25 iter 200, loss: 1.687, accuracy: 0.823\n",
      "epoch 25 iter 220, loss: 1.437, accuracy: 0.830\n",
      "epoch 25 iter 240, loss: 1.689, accuracy: 0.833\n",
      "epoch 25 iter 260, loss: 1.731, accuracy: 0.827\n",
      "epoch 25 iter 280, loss: 1.747, accuracy: 0.828\n",
      "epoch 26 iter 0, loss: 1.589, accuracy: 0.830\n",
      "epoch 26 iter 20, loss: 1.866, accuracy: 0.830\n",
      "epoch 26 iter 40, loss: 1.729, accuracy: 0.834\n",
      "epoch 26 iter 60, loss: 1.661, accuracy: 0.832\n",
      "epoch 26 iter 80, loss: 1.773, accuracy: 0.822\n",
      "epoch 26 iter 100, loss: 1.617, accuracy: 0.829\n",
      "epoch 26 iter 120, loss: 1.910, accuracy: 0.829\n",
      "epoch 26 iter 140, loss: 1.705, accuracy: 0.826\n",
      "epoch 26 iter 160, loss: 1.658, accuracy: 0.835\n",
      "epoch 26 iter 180, loss: 1.416, accuracy: 0.839\n",
      "epoch 26 iter 200, loss: 1.641, accuracy: 0.833\n",
      "epoch 26 iter 220, loss: 1.625, accuracy: 0.823\n",
      "epoch 26 iter 240, loss: 1.670, accuracy: 0.836\n",
      "epoch 26 iter 260, loss: 1.715, accuracy: 0.830\n",
      "epoch 26 iter 280, loss: 1.712, accuracy: 0.827\n",
      "epoch 27 iter 0, loss: 1.693, accuracy: 0.819\n",
      "epoch 27 iter 20, loss: 2.232, accuracy: 0.807\n",
      "epoch 27 iter 40, loss: 1.850, accuracy: 0.826\n",
      "epoch 27 iter 60, loss: 1.776, accuracy: 0.832\n",
      "epoch 27 iter 80, loss: 1.858, accuracy: 0.821\n",
      "epoch 27 iter 100, loss: 1.678, accuracy: 0.822\n",
      "epoch 27 iter 120, loss: 1.807, accuracy: 0.836\n",
      "epoch 27 iter 140, loss: 1.593, accuracy: 0.840\n",
      "epoch 27 iter 160, loss: 1.777, accuracy: 0.828\n",
      "epoch 27 iter 180, loss: 1.574, accuracy: 0.843\n",
      "epoch 27 iter 200, loss: 1.693, accuracy: 0.841\n",
      "epoch 27 iter 220, loss: 1.715, accuracy: 0.827\n",
      "epoch 27 iter 240, loss: 1.717, accuracy: 0.832\n",
      "epoch 27 iter 260, loss: 1.756, accuracy: 0.826\n",
      "epoch 27 iter 280, loss: 1.874, accuracy: 0.827\n",
      "epoch 28 iter 0, loss: 1.726, accuracy: 0.825\n",
      "epoch 28 iter 20, loss: 1.942, accuracy: 0.828\n",
      "epoch 28 iter 40, loss: 1.940, accuracy: 0.827\n",
      "epoch 28 iter 60, loss: 1.790, accuracy: 0.838\n",
      "epoch 28 iter 80, loss: 1.984, accuracy: 0.824\n",
      "epoch 28 iter 100, loss: 1.890, accuracy: 0.827\n",
      "epoch 28 iter 120, loss: 1.937, accuracy: 0.832\n",
      "epoch 28 iter 140, loss: 1.690, accuracy: 0.839\n",
      "epoch 28 iter 160, loss: 1.815, accuracy: 0.830\n",
      "epoch 28 iter 180, loss: 1.597, accuracy: 0.837\n",
      "epoch 28 iter 200, loss: 1.714, accuracy: 0.841\n",
      "epoch 28 iter 220, loss: 1.638, accuracy: 0.835\n",
      "epoch 28 iter 240, loss: 1.763, accuracy: 0.840\n",
      "epoch 28 iter 260, loss: 1.806, accuracy: 0.833\n",
      "epoch 28 iter 280, loss: 1.944, accuracy: 0.832\n",
      "epoch 29 iter 0, loss: 1.729, accuracy: 0.827\n",
      "epoch 29 iter 20, loss: 1.985, accuracy: 0.827\n",
      "epoch 29 iter 40, loss: 1.824, accuracy: 0.833\n",
      "epoch 29 iter 60, loss: 1.782, accuracy: 0.832\n",
      "epoch 29 iter 80, loss: 1.914, accuracy: 0.840\n",
      "epoch 29 iter 100, loss: 1.851, accuracy: 0.826\n",
      "epoch 29 iter 120, loss: 2.010, accuracy: 0.837\n",
      "epoch 29 iter 140, loss: 1.829, accuracy: 0.836\n",
      "epoch 29 iter 160, loss: 1.762, accuracy: 0.839\n",
      "epoch 29 iter 180, loss: 1.689, accuracy: 0.845\n",
      "epoch 29 iter 200, loss: 1.778, accuracy: 0.838\n",
      "epoch 29 iter 220, loss: 1.888, accuracy: 0.836\n",
      "epoch 29 iter 240, loss: 1.719, accuracy: 0.842\n",
      "epoch 29 iter 260, loss: 1.982, accuracy: 0.835\n",
      "epoch 29 iter 280, loss: 2.012, accuracy: 0.829\n",
      "epoch 30 iter 0, loss: 1.860, accuracy: 0.838\n",
      "epoch 30 iter 20, loss: 2.090, accuracy: 0.833\n",
      "epoch 30 iter 40, loss: 1.960, accuracy: 0.830\n",
      "epoch 30 iter 60, loss: 1.845, accuracy: 0.825\n",
      "epoch 30 iter 80, loss: 1.938, accuracy: 0.835\n",
      "epoch 30 iter 100, loss: 1.776, accuracy: 0.843\n",
      "epoch 30 iter 120, loss: 2.021, accuracy: 0.836\n",
      "epoch 30 iter 140, loss: 1.858, accuracy: 0.839\n",
      "epoch 30 iter 160, loss: 1.811, accuracy: 0.838\n",
      "epoch 30 iter 180, loss: 1.771, accuracy: 0.845\n",
      "epoch 30 iter 200, loss: 1.818, accuracy: 0.843\n",
      "epoch 30 iter 220, loss: 1.881, accuracy: 0.841\n",
      "epoch 30 iter 240, loss: 1.799, accuracy: 0.831\n",
      "epoch 30 iter 260, loss: 1.882, accuracy: 0.840\n",
      "epoch 30 iter 280, loss: 1.957, accuracy: 0.825\n",
      "epoch 31 iter 0, loss: 1.910, accuracy: 0.833\n",
      "epoch 31 iter 20, loss: 2.084, accuracy: 0.836\n",
      "epoch 31 iter 40, loss: 2.083, accuracy: 0.829\n",
      "epoch 31 iter 60, loss: 1.965, accuracy: 0.821\n",
      "epoch 31 iter 80, loss: 2.130, accuracy: 0.840\n",
      "epoch 31 iter 100, loss: 1.920, accuracy: 0.834\n",
      "epoch 31 iter 120, loss: 2.195, accuracy: 0.834\n",
      "epoch 31 iter 140, loss: 2.074, accuracy: 0.836\n",
      "epoch 31 iter 160, loss: 2.043, accuracy: 0.842\n",
      "epoch 31 iter 180, loss: 1.884, accuracy: 0.840\n",
      "epoch 31 iter 200, loss: 2.001, accuracy: 0.846\n",
      "epoch 31 iter 220, loss: 2.064, accuracy: 0.837\n",
      "epoch 31 iter 240, loss: 1.982, accuracy: 0.828\n",
      "epoch 31 iter 260, loss: 2.162, accuracy: 0.833\n",
      "epoch 31 iter 280, loss: 2.219, accuracy: 0.818\n",
      "epoch 32 iter 0, loss: 1.978, accuracy: 0.825\n",
      "epoch 32 iter 20, loss: 2.089, accuracy: 0.822\n",
      "epoch 32 iter 40, loss: 2.087, accuracy: 0.827\n",
      "epoch 32 iter 60, loss: 2.235, accuracy: 0.819\n",
      "epoch 32 iter 80, loss: 2.208, accuracy: 0.837\n",
      "epoch 32 iter 100, loss: 2.038, accuracy: 0.837\n",
      "epoch 32 iter 120, loss: 2.057, accuracy: 0.834\n",
      "epoch 32 iter 140, loss: 2.006, accuracy: 0.835\n",
      "epoch 32 iter 160, loss: 1.971, accuracy: 0.842\n",
      "epoch 32 iter 180, loss: 2.000, accuracy: 0.841\n",
      "epoch 32 iter 200, loss: 1.968, accuracy: 0.843\n",
      "epoch 32 iter 220, loss: 2.058, accuracy: 0.836\n",
      "epoch 32 iter 240, loss: 1.845, accuracy: 0.834\n",
      "epoch 32 iter 260, loss: 2.210, accuracy: 0.832\n",
      "epoch 32 iter 280, loss: 2.329, accuracy: 0.826\n",
      "epoch 33 iter 0, loss: 1.999, accuracy: 0.837\n",
      "epoch 33 iter 20, loss: 2.228, accuracy: 0.829\n",
      "epoch 33 iter 40, loss: 2.160, accuracy: 0.830\n",
      "epoch 33 iter 60, loss: 2.340, accuracy: 0.822\n",
      "epoch 33 iter 80, loss: 2.286, accuracy: 0.834\n",
      "epoch 33 iter 100, loss: 2.154, accuracy: 0.840\n",
      "epoch 33 iter 120, loss: 2.199, accuracy: 0.828\n",
      "epoch 33 iter 140, loss: 2.187, accuracy: 0.834\n",
      "epoch 33 iter 160, loss: 2.097, accuracy: 0.831\n",
      "epoch 33 iter 180, loss: 2.027, accuracy: 0.841\n",
      "epoch 33 iter 200, loss: 2.056, accuracy: 0.840\n",
      "epoch 33 iter 220, loss: 2.060, accuracy: 0.835\n",
      "epoch 33 iter 240, loss: 1.954, accuracy: 0.830\n",
      "epoch 33 iter 260, loss: 2.145, accuracy: 0.840\n",
      "epoch 33 iter 280, loss: 2.204, accuracy: 0.837\n",
      "epoch 34 iter 0, loss: 2.133, accuracy: 0.834\n",
      "epoch 34 iter 20, loss: 2.074, accuracy: 0.827\n",
      "epoch 34 iter 40, loss: 2.263, accuracy: 0.825\n",
      "epoch 34 iter 60, loss: 2.296, accuracy: 0.828\n",
      "epoch 34 iter 80, loss: 2.239, accuracy: 0.830\n",
      "epoch 34 iter 100, loss: 2.160, accuracy: 0.839\n",
      "epoch 34 iter 120, loss: 2.439, accuracy: 0.823\n",
      "epoch 34 iter 140, loss: 2.343, accuracy: 0.833\n",
      "epoch 34 iter 160, loss: 2.286, accuracy: 0.834\n",
      "epoch 34 iter 180, loss: 2.098, accuracy: 0.838\n",
      "epoch 34 iter 200, loss: 2.139, accuracy: 0.844\n",
      "epoch 34 iter 220, loss: 2.353, accuracy: 0.832\n",
      "epoch 34 iter 240, loss: 2.026, accuracy: 0.825\n",
      "epoch 34 iter 260, loss: 2.251, accuracy: 0.838\n",
      "epoch 34 iter 280, loss: 2.359, accuracy: 0.835\n",
      "epoch 35 iter 0, loss: 2.447, accuracy: 0.827\n",
      "epoch 35 iter 20, loss: 2.032, accuracy: 0.832\n",
      "epoch 35 iter 40, loss: 2.220, accuracy: 0.830\n",
      "epoch 35 iter 60, loss: 2.270, accuracy: 0.830\n",
      "epoch 35 iter 80, loss: 2.407, accuracy: 0.826\n",
      "epoch 35 iter 100, loss: 2.192, accuracy: 0.838\n",
      "epoch 35 iter 120, loss: 2.262, accuracy: 0.823\n",
      "epoch 35 iter 140, loss: 2.204, accuracy: 0.828\n",
      "epoch 35 iter 160, loss: 2.307, accuracy: 0.834\n",
      "epoch 35 iter 180, loss: 2.196, accuracy: 0.839\n",
      "epoch 35 iter 200, loss: 2.195, accuracy: 0.836\n",
      "epoch 35 iter 220, loss: 2.267, accuracy: 0.830\n",
      "epoch 35 iter 240, loss: 1.990, accuracy: 0.819\n",
      "epoch 35 iter 260, loss: 2.422, accuracy: 0.835\n",
      "epoch 35 iter 280, loss: 2.167, accuracy: 0.836\n",
      "epoch 36 iter 0, loss: 2.319, accuracy: 0.832\n",
      "epoch 36 iter 20, loss: 2.139, accuracy: 0.842\n",
      "epoch 36 iter 40, loss: 1.930, accuracy: 0.828\n",
      "epoch 36 iter 60, loss: 2.567, accuracy: 0.823\n",
      "epoch 36 iter 80, loss: 2.110, accuracy: 0.825\n",
      "epoch 36 iter 100, loss: 2.012, accuracy: 0.840\n",
      "epoch 36 iter 120, loss: 2.211, accuracy: 0.831\n",
      "epoch 36 iter 140, loss: 2.342, accuracy: 0.833\n",
      "epoch 36 iter 160, loss: 2.248, accuracy: 0.836\n",
      "epoch 36 iter 180, loss: 2.072, accuracy: 0.840\n",
      "epoch 36 iter 200, loss: 2.234, accuracy: 0.844\n",
      "epoch 36 iter 220, loss: 2.035, accuracy: 0.844\n",
      "epoch 36 iter 240, loss: 2.098, accuracy: 0.839\n",
      "epoch 36 iter 260, loss: 2.458, accuracy: 0.840\n",
      "epoch 36 iter 280, loss: 2.320, accuracy: 0.840\n",
      "epoch 37 iter 0, loss: 2.155, accuracy: 0.840\n",
      "epoch 37 iter 20, loss: 2.340, accuracy: 0.845\n",
      "epoch 37 iter 40, loss: 2.299, accuracy: 0.822\n",
      "epoch 37 iter 60, loss: 2.559, accuracy: 0.836\n",
      "epoch 37 iter 80, loss: 2.193, accuracy: 0.831\n",
      "epoch 37 iter 100, loss: 2.044, accuracy: 0.842\n",
      "epoch 37 iter 120, loss: 2.289, accuracy: 0.839\n",
      "epoch 37 iter 140, loss: 2.636, accuracy: 0.823\n",
      "epoch 37 iter 160, loss: 2.317, accuracy: 0.835\n",
      "epoch 37 iter 180, loss: 2.352, accuracy: 0.839\n",
      "epoch 37 iter 200, loss: 2.307, accuracy: 0.848\n",
      "epoch 37 iter 220, loss: 2.246, accuracy: 0.843\n",
      "epoch 37 iter 240, loss: 2.123, accuracy: 0.840\n",
      "epoch 37 iter 260, loss: 2.456, accuracy: 0.835\n",
      "epoch 37 iter 280, loss: 2.441, accuracy: 0.836\n",
      "epoch 38 iter 0, loss: 2.262, accuracy: 0.838\n",
      "epoch 38 iter 20, loss: 2.402, accuracy: 0.841\n",
      "epoch 38 iter 40, loss: 2.372, accuracy: 0.834\n",
      "epoch 38 iter 60, loss: 2.492, accuracy: 0.839\n",
      "epoch 38 iter 80, loss: 2.223, accuracy: 0.846\n",
      "epoch 38 iter 100, loss: 2.133, accuracy: 0.839\n",
      "epoch 38 iter 120, loss: 2.366, accuracy: 0.835\n",
      "epoch 38 iter 140, loss: 2.525, accuracy: 0.835\n",
      "epoch 38 iter 160, loss: 2.329, accuracy: 0.836\n",
      "epoch 38 iter 180, loss: 2.182, accuracy: 0.848\n",
      "epoch 38 iter 200, loss: 2.305, accuracy: 0.844\n",
      "epoch 38 iter 220, loss: 2.217, accuracy: 0.833\n",
      "epoch 38 iter 240, loss: 2.220, accuracy: 0.832\n",
      "epoch 38 iter 260, loss: 2.617, accuracy: 0.836\n",
      "epoch 38 iter 280, loss: 2.384, accuracy: 0.843\n",
      "epoch 39 iter 0, loss: 2.368, accuracy: 0.842\n",
      "epoch 39 iter 20, loss: 2.406, accuracy: 0.842\n",
      "epoch 39 iter 40, loss: 2.336, accuracy: 0.832\n",
      "epoch 39 iter 60, loss: 2.563, accuracy: 0.837\n",
      "epoch 39 iter 80, loss: 2.363, accuracy: 0.840\n",
      "epoch 39 iter 100, loss: 2.256, accuracy: 0.835\n",
      "epoch 39 iter 120, loss: 2.423, accuracy: 0.841\n",
      "epoch 39 iter 140, loss: 2.439, accuracy: 0.836\n",
      "epoch 39 iter 160, loss: 2.406, accuracy: 0.845\n",
      "epoch 39 iter 180, loss: 2.497, accuracy: 0.836\n",
      "epoch 39 iter 200, loss: 2.274, accuracy: 0.848\n",
      "epoch 39 iter 220, loss: 2.237, accuracy: 0.851\n",
      "epoch 39 iter 240, loss: 2.212, accuracy: 0.847\n",
      "epoch 39 iter 260, loss: 2.585, accuracy: 0.835\n",
      "epoch 39 iter 280, loss: 2.495, accuracy: 0.838\n",
      "epoch 40 iter 0, loss: 2.514, accuracy: 0.839\n",
      "epoch 40 iter 20, loss: 2.456, accuracy: 0.842\n",
      "epoch 40 iter 40, loss: 2.629, accuracy: 0.838\n",
      "epoch 40 iter 60, loss: 2.632, accuracy: 0.839\n",
      "epoch 40 iter 80, loss: 2.414, accuracy: 0.839\n",
      "epoch 40 iter 100, loss: 2.438, accuracy: 0.828\n",
      "epoch 40 iter 120, loss: 2.418, accuracy: 0.841\n",
      "epoch 40 iter 140, loss: 2.540, accuracy: 0.834\n",
      "epoch 40 iter 160, loss: 2.495, accuracy: 0.838\n",
      "epoch 40 iter 180, loss: 2.413, accuracy: 0.839\n",
      "epoch 40 iter 200, loss: 2.323, accuracy: 0.847\n",
      "epoch 40 iter 220, loss: 2.360, accuracy: 0.848\n",
      "epoch 40 iter 240, loss: 2.290, accuracy: 0.850\n",
      "epoch 40 iter 260, loss: 2.796, accuracy: 0.837\n",
      "epoch 40 iter 280, loss: 2.462, accuracy: 0.845\n",
      "epoch 41 iter 0, loss: 2.555, accuracy: 0.839\n",
      "epoch 41 iter 20, loss: 2.695, accuracy: 0.842\n",
      "epoch 41 iter 40, loss: 2.771, accuracy: 0.841\n",
      "epoch 41 iter 60, loss: 2.699, accuracy: 0.834\n",
      "epoch 41 iter 80, loss: 2.685, accuracy: 0.830\n",
      "epoch 41 iter 100, loss: 2.710, accuracy: 0.837\n",
      "epoch 41 iter 120, loss: 2.633, accuracy: 0.840\n",
      "epoch 41 iter 140, loss: 2.589, accuracy: 0.840\n",
      "epoch 41 iter 160, loss: 2.791, accuracy: 0.830\n",
      "epoch 41 iter 180, loss: 2.705, accuracy: 0.841\n",
      "epoch 41 iter 200, loss: 2.686, accuracy: 0.844\n",
      "epoch 41 iter 220, loss: 2.686, accuracy: 0.839\n",
      "epoch 41 iter 240, loss: 2.457, accuracy: 0.841\n",
      "epoch 41 iter 260, loss: 2.937, accuracy: 0.837\n",
      "epoch 41 iter 280, loss: 2.733, accuracy: 0.841\n",
      "epoch 42 iter 0, loss: 2.560, accuracy: 0.839\n",
      "epoch 42 iter 20, loss: 2.738, accuracy: 0.843\n",
      "epoch 42 iter 40, loss: 2.824, accuracy: 0.835\n",
      "epoch 42 iter 60, loss: 2.879, accuracy: 0.832\n",
      "epoch 42 iter 80, loss: 2.716, accuracy: 0.832\n",
      "epoch 42 iter 100, loss: 2.586, accuracy: 0.827\n",
      "epoch 42 iter 120, loss: 2.584, accuracy: 0.840\n",
      "epoch 42 iter 140, loss: 2.854, accuracy: 0.828\n",
      "epoch 42 iter 160, loss: 2.646, accuracy: 0.834\n",
      "epoch 42 iter 180, loss: 2.565, accuracy: 0.841\n",
      "epoch 42 iter 200, loss: 2.569, accuracy: 0.843\n",
      "epoch 42 iter 220, loss: 2.693, accuracy: 0.835\n",
      "epoch 42 iter 240, loss: 2.449, accuracy: 0.847\n",
      "epoch 42 iter 260, loss: 2.725, accuracy: 0.845\n",
      "epoch 42 iter 280, loss: 2.675, accuracy: 0.845\n",
      "epoch 43 iter 0, loss: 2.763, accuracy: 0.843\n",
      "epoch 43 iter 20, loss: 2.788, accuracy: 0.840\n",
      "epoch 43 iter 40, loss: 2.623, accuracy: 0.840\n",
      "epoch 43 iter 60, loss: 2.613, accuracy: 0.842\n",
      "epoch 43 iter 80, loss: 2.662, accuracy: 0.841\n",
      "epoch 43 iter 100, loss: 2.470, accuracy: 0.836\n",
      "epoch 43 iter 120, loss: 2.685, accuracy: 0.841\n",
      "epoch 43 iter 140, loss: 2.784, accuracy: 0.833\n",
      "epoch 43 iter 160, loss: 2.710, accuracy: 0.839\n",
      "epoch 43 iter 180, loss: 2.609, accuracy: 0.842\n",
      "epoch 43 iter 200, loss: 2.711, accuracy: 0.844\n",
      "epoch 43 iter 220, loss: 2.887, accuracy: 0.825\n",
      "epoch 43 iter 240, loss: 2.865, accuracy: 0.839\n",
      "epoch 43 iter 260, loss: 2.838, accuracy: 0.843\n",
      "epoch 43 iter 280, loss: 2.952, accuracy: 0.838\n",
      "epoch 44 iter 0, loss: 2.968, accuracy: 0.839\n",
      "epoch 44 iter 20, loss: 2.668, accuracy: 0.848\n",
      "epoch 44 iter 40, loss: 2.567, accuracy: 0.845\n",
      "epoch 44 iter 60, loss: 2.717, accuracy: 0.833\n",
      "epoch 44 iter 80, loss: 2.782, accuracy: 0.837\n",
      "epoch 44 iter 100, loss: 2.811, accuracy: 0.834\n",
      "epoch 44 iter 120, loss: 2.692, accuracy: 0.836\n",
      "epoch 44 iter 140, loss: 2.753, accuracy: 0.837\n",
      "epoch 44 iter 160, loss: 2.651, accuracy: 0.838\n",
      "epoch 44 iter 180, loss: 2.757, accuracy: 0.829\n",
      "epoch 44 iter 200, loss: 2.753, accuracy: 0.843\n",
      "epoch 44 iter 220, loss: 2.817, accuracy: 0.831\n",
      "epoch 44 iter 240, loss: 2.775, accuracy: 0.837\n",
      "epoch 44 iter 260, loss: 3.102, accuracy: 0.829\n",
      "epoch 44 iter 280, loss: 2.735, accuracy: 0.839\n",
      "epoch 45 iter 0, loss: 2.759, accuracy: 0.834\n",
      "epoch 45 iter 20, loss: 2.792, accuracy: 0.842\n",
      "epoch 45 iter 40, loss: 2.866, accuracy: 0.840\n",
      "epoch 45 iter 60, loss: 2.750, accuracy: 0.840\n",
      "epoch 45 iter 80, loss: 2.767, accuracy: 0.844\n",
      "epoch 45 iter 100, loss: 2.656, accuracy: 0.834\n",
      "epoch 45 iter 120, loss: 2.558, accuracy: 0.832\n",
      "epoch 45 iter 140, loss: 2.770, accuracy: 0.839\n",
      "epoch 45 iter 160, loss: 2.462, accuracy: 0.839\n",
      "epoch 45 iter 180, loss: 2.595, accuracy: 0.844\n",
      "epoch 45 iter 200, loss: 2.630, accuracy: 0.846\n",
      "epoch 45 iter 220, loss: 2.701, accuracy: 0.842\n",
      "epoch 45 iter 240, loss: 2.530, accuracy: 0.847\n",
      "epoch 45 iter 260, loss: 2.746, accuracy: 0.846\n",
      "epoch 45 iter 280, loss: 2.787, accuracy: 0.842\n",
      "epoch 46 iter 0, loss: 2.794, accuracy: 0.841\n",
      "epoch 46 iter 20, loss: 2.686, accuracy: 0.841\n",
      "epoch 46 iter 40, loss: 2.919, accuracy: 0.837\n",
      "epoch 46 iter 60, loss: 2.918, accuracy: 0.828\n",
      "epoch 46 iter 80, loss: 2.921, accuracy: 0.834\n",
      "epoch 46 iter 100, loss: 2.894, accuracy: 0.827\n",
      "epoch 46 iter 120, loss: 2.768, accuracy: 0.839\n",
      "epoch 46 iter 140, loss: 3.094, accuracy: 0.839\n",
      "epoch 46 iter 160, loss: 2.678, accuracy: 0.844\n",
      "epoch 46 iter 180, loss: 2.622, accuracy: 0.847\n",
      "epoch 46 iter 200, loss: 2.816, accuracy: 0.844\n",
      "epoch 46 iter 220, loss: 2.957, accuracy: 0.838\n",
      "epoch 46 iter 240, loss: 2.720, accuracy: 0.841\n",
      "epoch 46 iter 260, loss: 3.154, accuracy: 0.836\n",
      "epoch 46 iter 280, loss: 3.029, accuracy: 0.834\n",
      "epoch 47 iter 0, loss: 3.018, accuracy: 0.838\n",
      "epoch 47 iter 20, loss: 2.641, accuracy: 0.841\n",
      "epoch 47 iter 40, loss: 2.984, accuracy: 0.835\n",
      "epoch 47 iter 60, loss: 2.979, accuracy: 0.831\n",
      "epoch 47 iter 80, loss: 3.006, accuracy: 0.830\n",
      "epoch 47 iter 100, loss: 2.932, accuracy: 0.825\n",
      "epoch 47 iter 120, loss: 3.115, accuracy: 0.831\n",
      "epoch 47 iter 140, loss: 3.126, accuracy: 0.834\n",
      "epoch 47 iter 160, loss: 2.956, accuracy: 0.835\n",
      "epoch 47 iter 180, loss: 2.806, accuracy: 0.843\n",
      "epoch 47 iter 200, loss: 2.986, accuracy: 0.843\n",
      "epoch 47 iter 220, loss: 2.949, accuracy: 0.840\n",
      "epoch 47 iter 240, loss: 3.012, accuracy: 0.837\n",
      "epoch 47 iter 260, loss: 3.145, accuracy: 0.845\n",
      "epoch 47 iter 280, loss: 3.012, accuracy: 0.841\n",
      "epoch 48 iter 0, loss: 2.917, accuracy: 0.840\n",
      "epoch 48 iter 20, loss: 2.881, accuracy: 0.841\n",
      "epoch 48 iter 40, loss: 3.193, accuracy: 0.834\n",
      "epoch 48 iter 60, loss: 2.861, accuracy: 0.842\n",
      "epoch 48 iter 80, loss: 2.967, accuracy: 0.838\n",
      "epoch 48 iter 100, loss: 2.784, accuracy: 0.830\n",
      "epoch 48 iter 120, loss: 3.105, accuracy: 0.833\n",
      "epoch 48 iter 140, loss: 3.307, accuracy: 0.835\n",
      "epoch 48 iter 160, loss: 2.836, accuracy: 0.833\n",
      "epoch 48 iter 180, loss: 2.720, accuracy: 0.843\n",
      "epoch 48 iter 200, loss: 2.679, accuracy: 0.846\n",
      "epoch 48 iter 220, loss: 2.881, accuracy: 0.843\n",
      "epoch 48 iter 240, loss: 2.972, accuracy: 0.837\n",
      "epoch 48 iter 260, loss: 3.142, accuracy: 0.839\n",
      "epoch 48 iter 280, loss: 3.383, accuracy: 0.836\n",
      "epoch 49 iter 0, loss: 3.283, accuracy: 0.838\n",
      "epoch 49 iter 20, loss: 3.308, accuracy: 0.836\n",
      "epoch 49 iter 40, loss: 3.271, accuracy: 0.840\n",
      "epoch 49 iter 60, loss: 3.028, accuracy: 0.836\n",
      "epoch 49 iter 80, loss: 3.265, accuracy: 0.829\n",
      "epoch 49 iter 100, loss: 2.832, accuracy: 0.829\n",
      "epoch 49 iter 120, loss: 3.105, accuracy: 0.834\n",
      "epoch 49 iter 140, loss: 3.031, accuracy: 0.838\n",
      "epoch 49 iter 160, loss: 3.224, accuracy: 0.836\n",
      "epoch 49 iter 180, loss: 3.149, accuracy: 0.841\n",
      "epoch 49 iter 200, loss: 3.241, accuracy: 0.842\n",
      "epoch 49 iter 220, loss: 3.190, accuracy: 0.845\n",
      "epoch 49 iter 240, loss: 3.058, accuracy: 0.841\n",
      "epoch 49 iter 260, loss: 3.159, accuracy: 0.840\n",
      "epoch 49 iter 280, loss: 3.410, accuracy: 0.841\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "model_dict = apply_classification_loss(cnn_map)\n",
    "train_model(model_dict, dataset_generators, epoch_n=50, print_every=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3 SVHN Net Variations\n",
    "Now we vary the structure of the network. To keep things simple, we still use  two identical conv layers, but vary their parameters. \n",
    "\n",
    "Report the final test accuracy on 3 different number of filters, and 3 different number of strides. Each time when you vary one parameter, keep the other fixed at the original value.\n",
    "\n",
    "|Stride|Accuracy|\n",
    "|--|-------------------------------|\n",
    "| 1 / 1 | /0.795 |\n",
    "| 2 / 2| / 0.818|\n",
    "| 3 / 3| /0.842 |\n",
    "| 4 / 4| /0.831 |\n",
    "| 2 / 3| /0.862 |\n",
    "\n",
    "|Filters|Accuracy|\n",
    "|--|-------------------------------|\n",
    "| 32 / 32 | / 0.825|\n",
    "| 64 / 64| / 0.834 |\n",
    "| 128 / 128| / 0.829|\n",
    "| 256 / 256| / 0.838|\n",
    "| 32 / 64| / 0.851|\n",
    "\n",
    "\n",
    "A template for one sample modification is given below. \n",
    "\n",
    "**Note:** you're welcome to decide how many training epochs to use, if that gets you the same results but faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reslts for the the cnn_modification are shown above. I tried 3 different filter numbers(64,128, 256). For this I kept the same number of filters for both convolutional layers, while using a stride = 2. The results were averaged over 3 runs per filter number, however it doesn not seem to be a significant difference between the accuracies from the three different filter numbers. I also tried using different number of filters for the two convolutional layers (conv1 = 32 filters and conv2= 64) and the accuracy increased a bit.  \n",
    "  \n",
    "Also tried three diffren strides(1, 3, 4), with both pooling layers using the same stride. The results are shown above. It seams that a stride of 3 gives the best results. Also a stride of 2 in the first pooling layer and a stride of 3 in the second pooling layer gives the highest accuracy.  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 42.441, accuracy: 0.122\n",
      "epoch 0 iter 10, loss: 2.831, accuracy: 0.146\n",
      "epoch 0 iter 20, loss: 2.299, accuracy: 0.130\n",
      "epoch 0 iter 30, loss: 2.295, accuracy: 0.157\n",
      "epoch 0 iter 40, loss: 2.282, accuracy: 0.169\n",
      "epoch 0 iter 50, loss: 2.262, accuracy: 0.210\n",
      "epoch 0 iter 60, loss: 2.235, accuracy: 0.231\n",
      "epoch 0 iter 70, loss: 2.160, accuracy: 0.255\n",
      "epoch 0 iter 80, loss: 2.125, accuracy: 0.281\n",
      "epoch 0 iter 90, loss: 2.036, accuracy: 0.307\n",
      "epoch 0 iter 100, loss: 1.934, accuracy: 0.356\n",
      "epoch 0 iter 110, loss: 1.900, accuracy: 0.362\n",
      "epoch 0 iter 120, loss: 1.795, accuracy: 0.415\n",
      "epoch 0 iter 130, loss: 1.742, accuracy: 0.441\n",
      "epoch 0 iter 140, loss: 1.717, accuracy: 0.436\n",
      "epoch 0 iter 150, loss: 1.686, accuracy: 0.456\n",
      "epoch 0 iter 160, loss: 1.654, accuracy: 0.473\n",
      "epoch 0 iter 170, loss: 1.623, accuracy: 0.483\n",
      "epoch 0 iter 180, loss: 1.566, accuracy: 0.497\n",
      "epoch 0 iter 190, loss: 1.576, accuracy: 0.503\n",
      "epoch 0 iter 200, loss: 1.576, accuracy: 0.504\n",
      "epoch 0 iter 210, loss: 1.506, accuracy: 0.520\n",
      "epoch 0 iter 220, loss: 1.493, accuracy: 0.525\n",
      "epoch 0 iter 230, loss: 1.560, accuracy: 0.499\n",
      "epoch 0 iter 240, loss: 1.490, accuracy: 0.527\n",
      "epoch 0 iter 250, loss: 1.490, accuracy: 0.530\n",
      "epoch 0 iter 260, loss: 1.434, accuracy: 0.543\n",
      "epoch 0 iter 270, loss: 1.438, accuracy: 0.548\n",
      "epoch 0 iter 280, loss: 1.401, accuracy: 0.559\n",
      "epoch 1 iter 0, loss: 1.390, accuracy: 0.564\n",
      "epoch 1 iter 10, loss: 1.410, accuracy: 0.557\n",
      "epoch 1 iter 20, loss: 1.380, accuracy: 0.567\n",
      "epoch 1 iter 30, loss: 1.385, accuracy: 0.565\n",
      "epoch 1 iter 40, loss: 1.339, accuracy: 0.586\n",
      "epoch 1 iter 50, loss: 1.316, accuracy: 0.594\n",
      "epoch 1 iter 60, loss: 1.337, accuracy: 0.585\n",
      "epoch 1 iter 70, loss: 1.312, accuracy: 0.591\n",
      "epoch 1 iter 80, loss: 1.279, accuracy: 0.602\n",
      "epoch 1 iter 90, loss: 1.281, accuracy: 0.605\n",
      "epoch 1 iter 100, loss: 1.273, accuracy: 0.605\n",
      "epoch 1 iter 110, loss: 1.273, accuracy: 0.603\n",
      "epoch 1 iter 120, loss: 1.241, accuracy: 0.618\n",
      "epoch 1 iter 130, loss: 1.235, accuracy: 0.619\n",
      "epoch 1 iter 140, loss: 1.295, accuracy: 0.594\n",
      "epoch 1 iter 150, loss: 1.246, accuracy: 0.618\n",
      "epoch 1 iter 160, loss: 1.242, accuracy: 0.612\n",
      "epoch 1 iter 170, loss: 1.222, accuracy: 0.624\n",
      "epoch 1 iter 180, loss: 1.202, accuracy: 0.629\n",
      "epoch 1 iter 190, loss: 1.190, accuracy: 0.639\n",
      "epoch 1 iter 200, loss: 1.200, accuracy: 0.629\n",
      "epoch 1 iter 210, loss: 1.167, accuracy: 0.640\n",
      "epoch 1 iter 220, loss: 1.159, accuracy: 0.644\n",
      "epoch 1 iter 230, loss: 1.156, accuracy: 0.646\n",
      "epoch 1 iter 240, loss: 1.204, accuracy: 0.628\n",
      "epoch 1 iter 250, loss: 1.171, accuracy: 0.638\n",
      "epoch 1 iter 260, loss: 1.121, accuracy: 0.657\n",
      "epoch 1 iter 270, loss: 1.180, accuracy: 0.640\n",
      "epoch 1 iter 280, loss: 1.122, accuracy: 0.657\n",
      "epoch 2 iter 0, loss: 1.138, accuracy: 0.652\n",
      "epoch 2 iter 10, loss: 1.122, accuracy: 0.659\n",
      "epoch 2 iter 20, loss: 1.111, accuracy: 0.663\n",
      "epoch 2 iter 30, loss: 1.137, accuracy: 0.655\n",
      "epoch 2 iter 40, loss: 1.136, accuracy: 0.650\n",
      "epoch 2 iter 50, loss: 1.100, accuracy: 0.657\n",
      "epoch 2 iter 60, loss: 1.194, accuracy: 0.633\n",
      "epoch 2 iter 70, loss: 1.108, accuracy: 0.658\n",
      "epoch 2 iter 80, loss: 1.063, accuracy: 0.675\n",
      "epoch 2 iter 90, loss: 1.074, accuracy: 0.671\n",
      "epoch 2 iter 100, loss: 1.072, accuracy: 0.677\n",
      "epoch 2 iter 110, loss: 1.110, accuracy: 0.664\n",
      "epoch 2 iter 120, loss: 1.067, accuracy: 0.679\n",
      "epoch 2 iter 130, loss: 1.042, accuracy: 0.686\n",
      "epoch 2 iter 140, loss: 1.108, accuracy: 0.659\n",
      "epoch 2 iter 150, loss: 1.115, accuracy: 0.653\n",
      "epoch 2 iter 160, loss: 1.118, accuracy: 0.648\n",
      "epoch 2 iter 170, loss: 1.106, accuracy: 0.662\n",
      "epoch 2 iter 180, loss: 1.047, accuracy: 0.680\n",
      "epoch 2 iter 190, loss: 1.033, accuracy: 0.690\n",
      "epoch 2 iter 200, loss: 1.013, accuracy: 0.695\n",
      "epoch 2 iter 210, loss: 0.977, accuracy: 0.702\n",
      "epoch 2 iter 220, loss: 0.974, accuracy: 0.709\n",
      "epoch 2 iter 230, loss: 1.003, accuracy: 0.694\n",
      "epoch 2 iter 240, loss: 0.970, accuracy: 0.705\n",
      "epoch 2 iter 250, loss: 0.975, accuracy: 0.703\n",
      "epoch 2 iter 260, loss: 0.897, accuracy: 0.728\n",
      "epoch 2 iter 270, loss: 0.954, accuracy: 0.713\n",
      "epoch 2 iter 280, loss: 0.909, accuracy: 0.728\n",
      "epoch 3 iter 0, loss: 0.880, accuracy: 0.739\n",
      "epoch 3 iter 10, loss: 0.949, accuracy: 0.718\n",
      "epoch 3 iter 20, loss: 0.901, accuracy: 0.734\n",
      "epoch 3 iter 30, loss: 0.918, accuracy: 0.728\n",
      "epoch 3 iter 40, loss: 0.891, accuracy: 0.736\n",
      "epoch 3 iter 50, loss: 0.865, accuracy: 0.744\n",
      "epoch 3 iter 60, loss: 0.893, accuracy: 0.736\n",
      "epoch 3 iter 70, loss: 0.851, accuracy: 0.745\n",
      "epoch 3 iter 80, loss: 0.869, accuracy: 0.742\n",
      "epoch 3 iter 90, loss: 0.862, accuracy: 0.741\n",
      "epoch 3 iter 100, loss: 0.827, accuracy: 0.757\n",
      "epoch 3 iter 110, loss: 0.887, accuracy: 0.742\n",
      "epoch 3 iter 120, loss: 0.817, accuracy: 0.759\n",
      "epoch 3 iter 130, loss: 0.852, accuracy: 0.751\n",
      "epoch 3 iter 140, loss: 0.834, accuracy: 0.758\n",
      "epoch 3 iter 150, loss: 0.916, accuracy: 0.729\n",
      "epoch 3 iter 160, loss: 0.827, accuracy: 0.762\n",
      "epoch 3 iter 170, loss: 0.992, accuracy: 0.705\n",
      "epoch 3 iter 180, loss: 0.832, accuracy: 0.758\n",
      "epoch 3 iter 190, loss: 0.799, accuracy: 0.769\n",
      "epoch 3 iter 200, loss: 0.839, accuracy: 0.752\n",
      "epoch 3 iter 210, loss: 0.781, accuracy: 0.776\n",
      "epoch 3 iter 220, loss: 0.772, accuracy: 0.775\n",
      "epoch 3 iter 230, loss: 0.811, accuracy: 0.765\n",
      "epoch 3 iter 240, loss: 0.787, accuracy: 0.770\n",
      "epoch 3 iter 250, loss: 0.767, accuracy: 0.777\n",
      "epoch 3 iter 260, loss: 0.763, accuracy: 0.776\n",
      "epoch 3 iter 270, loss: 0.784, accuracy: 0.774\n",
      "epoch 3 iter 280, loss: 0.771, accuracy: 0.777\n",
      "epoch 4 iter 0, loss: 0.760, accuracy: 0.778\n",
      "epoch 4 iter 10, loss: 0.778, accuracy: 0.776\n",
      "epoch 4 iter 20, loss: 0.764, accuracy: 0.785\n",
      "epoch 4 iter 30, loss: 0.791, accuracy: 0.775\n",
      "epoch 4 iter 40, loss: 0.783, accuracy: 0.779\n",
      "epoch 4 iter 50, loss: 0.756, accuracy: 0.785\n",
      "epoch 4 iter 60, loss: 0.762, accuracy: 0.790\n",
      "epoch 4 iter 70, loss: 0.752, accuracy: 0.785\n",
      "epoch 4 iter 80, loss: 0.751, accuracy: 0.787\n",
      "epoch 4 iter 90, loss: 0.726, accuracy: 0.796\n",
      "epoch 4 iter 100, loss: 0.746, accuracy: 0.788\n",
      "epoch 4 iter 110, loss: 0.717, accuracy: 0.797\n",
      "epoch 4 iter 120, loss: 0.711, accuracy: 0.799\n",
      "epoch 4 iter 130, loss: 0.767, accuracy: 0.781\n",
      "epoch 4 iter 140, loss: 0.710, accuracy: 0.799\n",
      "epoch 4 iter 150, loss: 0.741, accuracy: 0.792\n",
      "epoch 4 iter 160, loss: 0.697, accuracy: 0.805\n",
      "epoch 4 iter 170, loss: 0.765, accuracy: 0.783\n",
      "epoch 4 iter 180, loss: 0.709, accuracy: 0.804\n",
      "epoch 4 iter 190, loss: 0.742, accuracy: 0.790\n",
      "epoch 4 iter 200, loss: 0.724, accuracy: 0.801\n",
      "epoch 4 iter 210, loss: 0.788, accuracy: 0.774\n",
      "epoch 4 iter 220, loss: 0.732, accuracy: 0.791\n",
      "epoch 4 iter 230, loss: 0.723, accuracy: 0.799\n",
      "epoch 4 iter 240, loss: 0.736, accuracy: 0.792\n",
      "epoch 4 iter 250, loss: 0.719, accuracy: 0.799\n",
      "epoch 4 iter 260, loss: 0.686, accuracy: 0.803\n",
      "epoch 4 iter 270, loss: 0.724, accuracy: 0.797\n",
      "epoch 4 iter 280, loss: 0.703, accuracy: 0.803\n",
      "epoch 5 iter 0, loss: 0.690, accuracy: 0.810\n",
      "epoch 5 iter 10, loss: 0.685, accuracy: 0.811\n",
      "epoch 5 iter 20, loss: 0.688, accuracy: 0.808\n",
      "epoch 5 iter 30, loss: 0.735, accuracy: 0.800\n",
      "epoch 5 iter 40, loss: 0.678, accuracy: 0.814\n",
      "epoch 5 iter 50, loss: 0.683, accuracy: 0.815\n",
      "epoch 5 iter 60, loss: 0.698, accuracy: 0.811\n",
      "epoch 5 iter 70, loss: 0.672, accuracy: 0.813\n",
      "epoch 5 iter 80, loss: 0.695, accuracy: 0.806\n",
      "epoch 5 iter 90, loss: 0.675, accuracy: 0.815\n",
      "epoch 5 iter 100, loss: 0.685, accuracy: 0.809\n",
      "epoch 5 iter 110, loss: 0.655, accuracy: 0.818\n",
      "epoch 5 iter 120, loss: 0.660, accuracy: 0.820\n",
      "epoch 5 iter 130, loss: 0.702, accuracy: 0.804\n",
      "epoch 5 iter 140, loss: 0.687, accuracy: 0.810\n",
      "epoch 5 iter 150, loss: 0.684, accuracy: 0.813\n",
      "epoch 5 iter 160, loss: 0.707, accuracy: 0.801\n",
      "epoch 5 iter 170, loss: 0.686, accuracy: 0.814\n",
      "epoch 5 iter 180, loss: 0.688, accuracy: 0.813\n",
      "epoch 5 iter 190, loss: 0.675, accuracy: 0.814\n",
      "epoch 5 iter 200, loss: 0.725, accuracy: 0.807\n",
      "epoch 5 iter 210, loss: 0.716, accuracy: 0.796\n",
      "epoch 5 iter 220, loss: 0.701, accuracy: 0.807\n",
      "epoch 5 iter 230, loss: 0.675, accuracy: 0.814\n",
      "epoch 5 iter 240, loss: 0.678, accuracy: 0.813\n",
      "epoch 5 iter 250, loss: 0.679, accuracy: 0.816\n",
      "epoch 5 iter 260, loss: 0.668, accuracy: 0.811\n",
      "epoch 5 iter 270, loss: 0.680, accuracy: 0.816\n",
      "epoch 5 iter 280, loss: 0.743, accuracy: 0.789\n",
      "epoch 6 iter 0, loss: 0.671, accuracy: 0.817\n",
      "epoch 6 iter 10, loss: 0.687, accuracy: 0.815\n",
      "epoch 6 iter 20, loss: 0.676, accuracy: 0.816\n",
      "epoch 6 iter 30, loss: 0.713, accuracy: 0.812\n",
      "epoch 6 iter 40, loss: 0.666, accuracy: 0.817\n",
      "epoch 6 iter 50, loss: 0.656, accuracy: 0.826\n",
      "epoch 6 iter 60, loss: 0.703, accuracy: 0.813\n",
      "epoch 6 iter 70, loss: 0.688, accuracy: 0.817\n",
      "epoch 6 iter 80, loss: 0.659, accuracy: 0.818\n",
      "epoch 6 iter 90, loss: 0.660, accuracy: 0.822\n",
      "epoch 6 iter 100, loss: 0.652, accuracy: 0.826\n",
      "epoch 6 iter 110, loss: 0.670, accuracy: 0.818\n",
      "epoch 6 iter 120, loss: 0.672, accuracy: 0.824\n",
      "epoch 6 iter 130, loss: 0.714, accuracy: 0.809\n",
      "epoch 6 iter 140, loss: 0.676, accuracy: 0.817\n",
      "epoch 6 iter 150, loss: 0.741, accuracy: 0.799\n",
      "epoch 6 iter 160, loss: 0.683, accuracy: 0.814\n",
      "epoch 6 iter 170, loss: 0.665, accuracy: 0.825\n",
      "epoch 6 iter 180, loss: 0.750, accuracy: 0.791\n",
      "epoch 6 iter 190, loss: 0.737, accuracy: 0.797\n",
      "epoch 6 iter 200, loss: 0.679, accuracy: 0.823\n",
      "epoch 6 iter 210, loss: 0.684, accuracy: 0.811\n",
      "epoch 6 iter 220, loss: 0.646, accuracy: 0.824\n",
      "epoch 6 iter 230, loss: 0.652, accuracy: 0.824\n",
      "epoch 6 iter 240, loss: 0.665, accuracy: 0.820\n",
      "epoch 6 iter 250, loss: 0.660, accuracy: 0.825\n",
      "epoch 6 iter 260, loss: 0.672, accuracy: 0.819\n",
      "epoch 6 iter 270, loss: 0.677, accuracy: 0.821\n",
      "epoch 6 iter 280, loss: 0.692, accuracy: 0.809\n",
      "epoch 7 iter 0, loss: 0.635, accuracy: 0.833\n",
      "epoch 7 iter 10, loss: 0.646, accuracy: 0.829\n",
      "epoch 7 iter 20, loss: 0.661, accuracy: 0.827\n",
      "epoch 7 iter 30, loss: 0.708, accuracy: 0.818\n",
      "epoch 7 iter 40, loss: 0.680, accuracy: 0.816\n",
      "epoch 7 iter 50, loss: 0.659, accuracy: 0.823\n",
      "epoch 7 iter 60, loss: 0.697, accuracy: 0.819\n",
      "epoch 7 iter 70, loss: 0.688, accuracy: 0.818\n",
      "epoch 7 iter 80, loss: 0.697, accuracy: 0.818\n",
      "epoch 7 iter 90, loss: 0.654, accuracy: 0.823\n",
      "epoch 7 iter 100, loss: 0.676, accuracy: 0.817\n",
      "epoch 7 iter 110, loss: 0.678, accuracy: 0.816\n",
      "epoch 7 iter 120, loss: 0.660, accuracy: 0.826\n",
      "epoch 7 iter 130, loss: 0.760, accuracy: 0.795\n",
      "epoch 7 iter 140, loss: 0.706, accuracy: 0.814\n",
      "epoch 7 iter 150, loss: 0.717, accuracy: 0.814\n",
      "epoch 7 iter 160, loss: 0.707, accuracy: 0.813\n",
      "epoch 7 iter 170, loss: 0.702, accuracy: 0.815\n",
      "epoch 7 iter 180, loss: 0.668, accuracy: 0.822\n",
      "epoch 7 iter 190, loss: 0.673, accuracy: 0.823\n",
      "epoch 7 iter 200, loss: 0.701, accuracy: 0.824\n",
      "epoch 7 iter 210, loss: 0.652, accuracy: 0.828\n",
      "epoch 7 iter 220, loss: 0.662, accuracy: 0.825\n",
      "epoch 7 iter 230, loss: 0.668, accuracy: 0.821\n",
      "epoch 7 iter 240, loss: 0.663, accuracy: 0.822\n",
      "epoch 7 iter 250, loss: 0.675, accuracy: 0.825\n",
      "epoch 7 iter 260, loss: 0.657, accuracy: 0.822\n",
      "epoch 7 iter 270, loss: 0.673, accuracy: 0.828\n",
      "epoch 7 iter 280, loss: 0.675, accuracy: 0.823\n",
      "epoch 8 iter 0, loss: 0.691, accuracy: 0.826\n",
      "epoch 8 iter 10, loss: 0.683, accuracy: 0.828\n",
      "epoch 8 iter 20, loss: 0.659, accuracy: 0.829\n",
      "epoch 8 iter 30, loss: 0.710, accuracy: 0.822\n",
      "epoch 8 iter 40, loss: 0.676, accuracy: 0.828\n",
      "epoch 8 iter 50, loss: 0.658, accuracy: 0.830\n",
      "epoch 8 iter 60, loss: 0.726, accuracy: 0.809\n",
      "epoch 8 iter 70, loss: 0.691, accuracy: 0.817\n",
      "epoch 8 iter 80, loss: 0.654, accuracy: 0.827\n",
      "epoch 8 iter 90, loss: 0.648, accuracy: 0.831\n",
      "epoch 8 iter 100, loss: 0.661, accuracy: 0.827\n",
      "epoch 8 iter 110, loss: 0.702, accuracy: 0.810\n",
      "epoch 8 iter 120, loss: 0.684, accuracy: 0.820\n",
      "epoch 8 iter 130, loss: 0.687, accuracy: 0.825\n",
      "epoch 8 iter 140, loss: 0.764, accuracy: 0.800\n",
      "epoch 8 iter 150, loss: 0.678, accuracy: 0.826\n",
      "epoch 8 iter 160, loss: 0.701, accuracy: 0.821\n",
      "epoch 8 iter 170, loss: 0.671, accuracy: 0.828\n",
      "epoch 8 iter 180, loss: 0.671, accuracy: 0.828\n",
      "epoch 8 iter 190, loss: 0.680, accuracy: 0.821\n",
      "epoch 8 iter 200, loss: 0.689, accuracy: 0.827\n",
      "epoch 8 iter 210, loss: 0.672, accuracy: 0.826\n",
      "epoch 8 iter 220, loss: 0.651, accuracy: 0.834\n",
      "epoch 8 iter 230, loss: 0.694, accuracy: 0.817\n",
      "epoch 8 iter 240, loss: 0.674, accuracy: 0.825\n",
      "epoch 8 iter 250, loss: 0.670, accuracy: 0.834\n",
      "epoch 8 iter 260, loss: 0.641, accuracy: 0.838\n",
      "epoch 8 iter 270, loss: 0.700, accuracy: 0.822\n",
      "epoch 8 iter 280, loss: 0.649, accuracy: 0.837\n",
      "epoch 9 iter 0, loss: 0.711, accuracy: 0.825\n",
      "epoch 9 iter 10, loss: 0.677, accuracy: 0.832\n",
      "epoch 9 iter 20, loss: 0.653, accuracy: 0.835\n",
      "epoch 9 iter 30, loss: 0.699, accuracy: 0.828\n",
      "epoch 9 iter 40, loss: 0.677, accuracy: 0.829\n",
      "epoch 9 iter 50, loss: 0.721, accuracy: 0.824\n",
      "epoch 9 iter 60, loss: 0.703, accuracy: 0.830\n",
      "epoch 9 iter 70, loss: 0.693, accuracy: 0.823\n",
      "epoch 9 iter 80, loss: 0.668, accuracy: 0.833\n",
      "epoch 9 iter 90, loss: 0.693, accuracy: 0.821\n",
      "epoch 9 iter 100, loss: 0.681, accuracy: 0.828\n",
      "epoch 9 iter 110, loss: 0.713, accuracy: 0.817\n",
      "epoch 9 iter 120, loss: 0.690, accuracy: 0.826\n",
      "epoch 9 iter 130, loss: 0.672, accuracy: 0.831\n",
      "epoch 9 iter 140, loss: 0.689, accuracy: 0.826\n",
      "epoch 9 iter 150, loss: 0.636, accuracy: 0.842\n",
      "epoch 9 iter 160, loss: 0.723, accuracy: 0.818\n",
      "epoch 9 iter 170, loss: 0.686, accuracy: 0.833\n",
      "epoch 9 iter 180, loss: 0.674, accuracy: 0.832\n",
      "epoch 9 iter 190, loss: 0.685, accuracy: 0.829\n",
      "epoch 9 iter 200, loss: 0.780, accuracy: 0.805\n",
      "epoch 9 iter 210, loss: 0.685, accuracy: 0.825\n",
      "epoch 9 iter 220, loss: 0.668, accuracy: 0.834\n",
      "epoch 9 iter 230, loss: 0.745, accuracy: 0.812\n",
      "epoch 9 iter 240, loss: 0.762, accuracy: 0.801\n",
      "epoch 9 iter 250, loss: 0.732, accuracy: 0.816\n",
      "epoch 9 iter 260, loss: 0.681, accuracy: 0.826\n",
      "epoch 9 iter 270, loss: 0.667, accuracy: 0.833\n",
      "epoch 9 iter 280, loss: 0.655, accuracy: 0.844\n",
      "epoch 10 iter 0, loss: 0.670, accuracy: 0.841\n",
      "epoch 10 iter 10, loss: 0.686, accuracy: 0.836\n",
      "epoch 10 iter 20, loss: 0.693, accuracy: 0.829\n",
      "epoch 10 iter 30, loss: 0.693, accuracy: 0.828\n",
      "epoch 10 iter 40, loss: 0.690, accuracy: 0.831\n",
      "epoch 10 iter 50, loss: 0.710, accuracy: 0.826\n",
      "epoch 10 iter 60, loss: 0.753, accuracy: 0.822\n",
      "epoch 10 iter 70, loss: 0.666, accuracy: 0.836\n",
      "epoch 10 iter 80, loss: 0.674, accuracy: 0.837\n",
      "epoch 10 iter 90, loss: 0.715, accuracy: 0.824\n",
      "epoch 10 iter 100, loss: 0.693, accuracy: 0.834\n",
      "epoch 10 iter 110, loss: 0.692, accuracy: 0.827\n",
      "epoch 10 iter 120, loss: 0.720, accuracy: 0.821\n",
      "epoch 10 iter 130, loss: 0.712, accuracy: 0.829\n",
      "epoch 10 iter 140, loss: 0.707, accuracy: 0.833\n",
      "epoch 10 iter 150, loss: 0.695, accuracy: 0.833\n",
      "epoch 10 iter 160, loss: 0.729, accuracy: 0.817\n",
      "epoch 10 iter 170, loss: 0.707, accuracy: 0.833\n",
      "epoch 10 iter 180, loss: 0.712, accuracy: 0.823\n",
      "epoch 10 iter 190, loss: 0.721, accuracy: 0.832\n",
      "epoch 10 iter 200, loss: 0.700, accuracy: 0.836\n",
      "epoch 10 iter 210, loss: 0.741, accuracy: 0.825\n",
      "epoch 10 iter 220, loss: 0.691, accuracy: 0.838\n",
      "epoch 10 iter 230, loss: 0.852, accuracy: 0.797\n",
      "epoch 10 iter 240, loss: 0.686, accuracy: 0.838\n",
      "epoch 10 iter 250, loss: 0.757, accuracy: 0.816\n",
      "epoch 10 iter 260, loss: 0.706, accuracy: 0.830\n",
      "epoch 10 iter 270, loss: 0.743, accuracy: 0.820\n",
      "epoch 10 iter 280, loss: 0.717, accuracy: 0.838\n",
      "epoch 11 iter 0, loss: 0.729, accuracy: 0.828\n",
      "epoch 11 iter 10, loss: 0.701, accuracy: 0.840\n",
      "epoch 11 iter 20, loss: 0.728, accuracy: 0.828\n",
      "epoch 11 iter 30, loss: 0.718, accuracy: 0.835\n",
      "epoch 11 iter 40, loss: 0.784, accuracy: 0.821\n",
      "epoch 11 iter 50, loss: 0.713, accuracy: 0.832\n",
      "epoch 11 iter 60, loss: 0.817, accuracy: 0.821\n",
      "epoch 11 iter 70, loss: 0.723, accuracy: 0.832\n",
      "epoch 11 iter 80, loss: 0.706, accuracy: 0.832\n",
      "epoch 11 iter 90, loss: 0.744, accuracy: 0.829\n",
      "epoch 11 iter 100, loss: 0.725, accuracy: 0.830\n",
      "epoch 11 iter 110, loss: 0.723, accuracy: 0.829\n",
      "epoch 11 iter 120, loss: 0.737, accuracy: 0.827\n",
      "epoch 11 iter 130, loss: 0.800, accuracy: 0.820\n",
      "epoch 11 iter 140, loss: 0.764, accuracy: 0.828\n",
      "epoch 11 iter 150, loss: 0.705, accuracy: 0.837\n",
      "epoch 11 iter 160, loss: 0.674, accuracy: 0.841\n",
      "epoch 11 iter 170, loss: 0.682, accuracy: 0.837\n",
      "epoch 11 iter 180, loss: 0.700, accuracy: 0.833\n",
      "epoch 11 iter 190, loss: 0.704, accuracy: 0.835\n",
      "epoch 11 iter 200, loss: 0.714, accuracy: 0.836\n",
      "epoch 11 iter 210, loss: 0.748, accuracy: 0.823\n",
      "epoch 11 iter 220, loss: 0.707, accuracy: 0.837\n",
      "epoch 11 iter 230, loss: 0.711, accuracy: 0.836\n",
      "epoch 11 iter 240, loss: 0.702, accuracy: 0.831\n",
      "epoch 11 iter 250, loss: 0.708, accuracy: 0.833\n",
      "epoch 11 iter 260, loss: 0.783, accuracy: 0.816\n",
      "epoch 11 iter 270, loss: 0.753, accuracy: 0.829\n",
      "epoch 11 iter 280, loss: 0.739, accuracy: 0.831\n",
      "epoch 12 iter 0, loss: 0.771, accuracy: 0.822\n",
      "epoch 12 iter 10, loss: 0.750, accuracy: 0.828\n",
      "epoch 12 iter 20, loss: 0.742, accuracy: 0.833\n",
      "epoch 12 iter 30, loss: 0.732, accuracy: 0.831\n",
      "epoch 12 iter 40, loss: 0.751, accuracy: 0.834\n",
      "epoch 12 iter 50, loss: 0.753, accuracy: 0.824\n",
      "epoch 12 iter 60, loss: 0.719, accuracy: 0.838\n",
      "epoch 12 iter 70, loss: 0.770, accuracy: 0.818\n",
      "epoch 12 iter 80, loss: 0.749, accuracy: 0.831\n",
      "epoch 12 iter 90, loss: 0.755, accuracy: 0.820\n",
      "epoch 12 iter 100, loss: 0.751, accuracy: 0.829\n",
      "epoch 12 iter 110, loss: 0.757, accuracy: 0.828\n",
      "epoch 12 iter 120, loss: 0.781, accuracy: 0.817\n",
      "epoch 12 iter 130, loss: 0.778, accuracy: 0.825\n",
      "epoch 12 iter 140, loss: 0.771, accuracy: 0.833\n",
      "epoch 12 iter 150, loss: 0.720, accuracy: 0.839\n",
      "epoch 12 iter 160, loss: 0.715, accuracy: 0.829\n",
      "epoch 12 iter 170, loss: 0.736, accuracy: 0.826\n",
      "epoch 12 iter 180, loss: 0.731, accuracy: 0.837\n",
      "epoch 12 iter 190, loss: 0.687, accuracy: 0.839\n",
      "epoch 12 iter 200, loss: 0.764, accuracy: 0.833\n",
      "epoch 12 iter 210, loss: 0.728, accuracy: 0.830\n",
      "epoch 12 iter 220, loss: 0.701, accuracy: 0.842\n",
      "epoch 12 iter 230, loss: 0.723, accuracy: 0.841\n",
      "epoch 12 iter 240, loss: 0.726, accuracy: 0.835\n",
      "epoch 12 iter 250, loss: 0.744, accuracy: 0.837\n",
      "epoch 12 iter 260, loss: 0.777, accuracy: 0.829\n",
      "epoch 12 iter 270, loss: 0.765, accuracy: 0.836\n",
      "epoch 12 iter 280, loss: 0.803, accuracy: 0.825\n",
      "epoch 13 iter 0, loss: 0.764, accuracy: 0.831\n",
      "epoch 13 iter 10, loss: 0.803, accuracy: 0.829\n",
      "epoch 13 iter 20, loss: 0.746, accuracy: 0.840\n",
      "epoch 13 iter 30, loss: 0.741, accuracy: 0.831\n",
      "epoch 13 iter 40, loss: 0.759, accuracy: 0.832\n",
      "epoch 13 iter 50, loss: 0.792, accuracy: 0.818\n",
      "epoch 13 iter 60, loss: 0.767, accuracy: 0.834\n",
      "epoch 13 iter 70, loss: 0.779, accuracy: 0.829\n",
      "epoch 13 iter 80, loss: 0.826, accuracy: 0.830\n",
      "epoch 13 iter 90, loss: 0.775, accuracy: 0.835\n",
      "epoch 13 iter 100, loss: 0.757, accuracy: 0.837\n",
      "epoch 13 iter 110, loss: 0.765, accuracy: 0.836\n",
      "epoch 13 iter 120, loss: 0.841, accuracy: 0.809\n",
      "epoch 13 iter 130, loss: 0.730, accuracy: 0.839\n",
      "epoch 13 iter 140, loss: 0.807, accuracy: 0.828\n",
      "epoch 13 iter 150, loss: 0.726, accuracy: 0.841\n",
      "epoch 13 iter 160, loss: 0.728, accuracy: 0.839\n",
      "epoch 13 iter 170, loss: 0.768, accuracy: 0.826\n",
      "epoch 13 iter 180, loss: 0.738, accuracy: 0.843\n",
      "epoch 13 iter 190, loss: 0.736, accuracy: 0.837\n",
      "epoch 13 iter 200, loss: 0.740, accuracy: 0.842\n",
      "epoch 13 iter 210, loss: 0.774, accuracy: 0.834\n",
      "epoch 13 iter 220, loss: 0.777, accuracy: 0.832\n",
      "epoch 13 iter 230, loss: 0.817, accuracy: 0.823\n",
      "epoch 13 iter 240, loss: 0.744, accuracy: 0.838\n",
      "epoch 13 iter 250, loss: 0.753, accuracy: 0.836\n",
      "epoch 13 iter 260, loss: 0.795, accuracy: 0.831\n",
      "epoch 13 iter 270, loss: 0.822, accuracy: 0.826\n",
      "epoch 13 iter 280, loss: 0.780, accuracy: 0.832\n",
      "epoch 14 iter 0, loss: 0.775, accuracy: 0.841\n",
      "epoch 14 iter 10, loss: 0.760, accuracy: 0.843\n",
      "epoch 14 iter 20, loss: 0.746, accuracy: 0.840\n",
      "epoch 14 iter 30, loss: 0.733, accuracy: 0.842\n",
      "epoch 14 iter 40, loss: 0.887, accuracy: 0.804\n",
      "epoch 14 iter 50, loss: 0.781, accuracy: 0.827\n",
      "epoch 14 iter 60, loss: 0.817, accuracy: 0.827\n",
      "epoch 14 iter 70, loss: 0.768, accuracy: 0.833\n",
      "epoch 14 iter 80, loss: 0.758, accuracy: 0.839\n",
      "epoch 14 iter 90, loss: 0.786, accuracy: 0.840\n",
      "epoch 14 iter 100, loss: 0.748, accuracy: 0.845\n",
      "epoch 14 iter 110, loss: 0.802, accuracy: 0.824\n",
      "epoch 14 iter 120, loss: 0.837, accuracy: 0.814\n",
      "epoch 14 iter 130, loss: 0.761, accuracy: 0.840\n",
      "epoch 14 iter 140, loss: 0.761, accuracy: 0.830\n",
      "epoch 14 iter 150, loss: 0.765, accuracy: 0.842\n",
      "epoch 14 iter 160, loss: 0.725, accuracy: 0.841\n",
      "epoch 14 iter 170, loss: 0.730, accuracy: 0.840\n",
      "epoch 14 iter 180, loss: 0.757, accuracy: 0.844\n",
      "epoch 14 iter 190, loss: 0.798, accuracy: 0.831\n",
      "epoch 14 iter 200, loss: 0.774, accuracy: 0.836\n",
      "epoch 14 iter 210, loss: 0.807, accuracy: 0.834\n",
      "epoch 14 iter 220, loss: 0.761, accuracy: 0.827\n",
      "epoch 14 iter 230, loss: 0.815, accuracy: 0.829\n",
      "epoch 14 iter 240, loss: 0.816, accuracy: 0.825\n",
      "epoch 14 iter 250, loss: 0.755, accuracy: 0.839\n",
      "epoch 14 iter 260, loss: 0.749, accuracy: 0.839\n",
      "epoch 14 iter 270, loss: 0.866, accuracy: 0.825\n",
      "epoch 14 iter 280, loss: 0.741, accuracy: 0.847\n",
      "epoch 15 iter 0, loss: 0.710, accuracy: 0.852\n",
      "epoch 15 iter 10, loss: 0.804, accuracy: 0.839\n",
      "epoch 15 iter 20, loss: 0.805, accuracy: 0.834\n",
      "epoch 15 iter 30, loss: 0.773, accuracy: 0.834\n",
      "epoch 15 iter 40, loss: 0.773, accuracy: 0.836\n",
      "epoch 15 iter 50, loss: 0.776, accuracy: 0.831\n",
      "epoch 15 iter 60, loss: 0.771, accuracy: 0.840\n",
      "epoch 15 iter 70, loss: 0.807, accuracy: 0.837\n",
      "epoch 15 iter 80, loss: 0.761, accuracy: 0.844\n",
      "epoch 15 iter 90, loss: 0.787, accuracy: 0.837\n",
      "epoch 15 iter 100, loss: 0.768, accuracy: 0.844\n",
      "epoch 15 iter 110, loss: 0.755, accuracy: 0.849\n",
      "epoch 15 iter 120, loss: 0.781, accuracy: 0.836\n",
      "epoch 15 iter 130, loss: 0.783, accuracy: 0.829\n",
      "epoch 15 iter 140, loss: 0.791, accuracy: 0.843\n",
      "epoch 15 iter 150, loss: 0.828, accuracy: 0.835\n",
      "epoch 15 iter 160, loss: 0.789, accuracy: 0.827\n",
      "epoch 15 iter 170, loss: 0.815, accuracy: 0.832\n",
      "epoch 15 iter 180, loss: 0.785, accuracy: 0.836\n",
      "epoch 15 iter 190, loss: 0.795, accuracy: 0.843\n",
      "epoch 15 iter 200, loss: 0.746, accuracy: 0.842\n",
      "epoch 15 iter 210, loss: 0.775, accuracy: 0.840\n",
      "epoch 15 iter 220, loss: 0.747, accuracy: 0.837\n",
      "epoch 15 iter 230, loss: 0.790, accuracy: 0.847\n",
      "epoch 15 iter 240, loss: 0.801, accuracy: 0.836\n",
      "epoch 15 iter 250, loss: 0.787, accuracy: 0.842\n",
      "epoch 15 iter 260, loss: 0.822, accuracy: 0.833\n",
      "epoch 15 iter 270, loss: 0.914, accuracy: 0.831\n",
      "epoch 15 iter 280, loss: 0.847, accuracy: 0.835\n",
      "epoch 16 iter 0, loss: 0.772, accuracy: 0.845\n",
      "epoch 16 iter 10, loss: 0.897, accuracy: 0.826\n",
      "epoch 16 iter 20, loss: 0.845, accuracy: 0.831\n",
      "epoch 16 iter 30, loss: 0.785, accuracy: 0.842\n",
      "epoch 16 iter 40, loss: 0.757, accuracy: 0.850\n",
      "epoch 16 iter 50, loss: 0.816, accuracy: 0.834\n",
      "epoch 16 iter 60, loss: 0.790, accuracy: 0.837\n",
      "epoch 16 iter 70, loss: 0.783, accuracy: 0.850\n",
      "epoch 16 iter 80, loss: 0.810, accuracy: 0.845\n",
      "epoch 16 iter 90, loss: 0.785, accuracy: 0.844\n",
      "epoch 16 iter 100, loss: 0.836, accuracy: 0.832\n",
      "epoch 16 iter 110, loss: 0.834, accuracy: 0.839\n",
      "epoch 16 iter 120, loss: 0.885, accuracy: 0.824\n",
      "epoch 16 iter 130, loss: 0.790, accuracy: 0.841\n",
      "epoch 16 iter 140, loss: 0.822, accuracy: 0.836\n",
      "epoch 16 iter 150, loss: 0.833, accuracy: 0.839\n",
      "epoch 16 iter 160, loss: 0.926, accuracy: 0.817\n",
      "epoch 16 iter 170, loss: 0.862, accuracy: 0.829\n",
      "epoch 16 iter 180, loss: 0.808, accuracy: 0.845\n",
      "epoch 16 iter 190, loss: 0.918, accuracy: 0.831\n",
      "epoch 16 iter 200, loss: 0.779, accuracy: 0.842\n",
      "epoch 16 iter 210, loss: 0.834, accuracy: 0.835\n",
      "epoch 16 iter 220, loss: 0.797, accuracy: 0.827\n",
      "epoch 16 iter 230, loss: 0.797, accuracy: 0.842\n",
      "epoch 16 iter 240, loss: 0.808, accuracy: 0.843\n",
      "epoch 16 iter 250, loss: 0.863, accuracy: 0.832\n",
      "epoch 16 iter 260, loss: 0.843, accuracy: 0.841\n",
      "epoch 16 iter 270, loss: 0.888, accuracy: 0.834\n",
      "epoch 16 iter 280, loss: 0.858, accuracy: 0.842\n",
      "epoch 17 iter 0, loss: 0.815, accuracy: 0.852\n",
      "epoch 17 iter 10, loss: 1.029, accuracy: 0.818\n",
      "epoch 17 iter 20, loss: 0.916, accuracy: 0.821\n",
      "epoch 17 iter 30, loss: 0.893, accuracy: 0.827\n",
      "epoch 17 iter 40, loss: 0.867, accuracy: 0.828\n",
      "epoch 17 iter 50, loss: 0.812, accuracy: 0.839\n",
      "epoch 17 iter 60, loss: 0.772, accuracy: 0.848\n",
      "epoch 17 iter 70, loss: 0.794, accuracy: 0.850\n",
      "epoch 17 iter 80, loss: 0.812, accuracy: 0.843\n",
      "epoch 17 iter 90, loss: 0.825, accuracy: 0.831\n",
      "epoch 17 iter 100, loss: 0.874, accuracy: 0.835\n",
      "epoch 17 iter 110, loss: 0.865, accuracy: 0.830\n",
      "epoch 17 iter 120, loss: 0.878, accuracy: 0.835\n",
      "epoch 17 iter 130, loss: 0.850, accuracy: 0.830\n",
      "epoch 17 iter 140, loss: 1.045, accuracy: 0.812\n",
      "epoch 17 iter 150, loss: 0.831, accuracy: 0.844\n",
      "epoch 17 iter 160, loss: 0.922, accuracy: 0.816\n",
      "epoch 17 iter 170, loss: 0.734, accuracy: 0.850\n",
      "epoch 17 iter 180, loss: 0.774, accuracy: 0.852\n",
      "epoch 17 iter 190, loss: 0.853, accuracy: 0.840\n",
      "epoch 17 iter 200, loss: 0.763, accuracy: 0.850\n",
      "epoch 17 iter 210, loss: 0.811, accuracy: 0.841\n",
      "epoch 17 iter 220, loss: 0.831, accuracy: 0.827\n",
      "epoch 17 iter 230, loss: 0.830, accuracy: 0.838\n",
      "epoch 17 iter 240, loss: 0.891, accuracy: 0.839\n",
      "epoch 17 iter 250, loss: 0.917, accuracy: 0.831\n",
      "epoch 17 iter 260, loss: 0.913, accuracy: 0.833\n",
      "epoch 17 iter 270, loss: 0.883, accuracy: 0.845\n",
      "epoch 17 iter 280, loss: 1.003, accuracy: 0.833\n",
      "epoch 18 iter 0, loss: 0.836, accuracy: 0.846\n",
      "epoch 18 iter 10, loss: 1.020, accuracy: 0.834\n",
      "epoch 18 iter 20, loss: 0.853, accuracy: 0.840\n",
      "epoch 18 iter 30, loss: 0.838, accuracy: 0.842\n",
      "epoch 18 iter 40, loss: 0.898, accuracy: 0.824\n",
      "epoch 18 iter 50, loss: 0.966, accuracy: 0.820\n",
      "epoch 18 iter 60, loss: 0.870, accuracy: 0.828\n",
      "epoch 18 iter 70, loss: 0.843, accuracy: 0.842\n",
      "epoch 18 iter 80, loss: 0.860, accuracy: 0.844\n",
      "epoch 18 iter 90, loss: 0.865, accuracy: 0.836\n",
      "epoch 18 iter 100, loss: 0.857, accuracy: 0.846\n",
      "epoch 18 iter 110, loss: 0.911, accuracy: 0.824\n",
      "epoch 18 iter 120, loss: 0.807, accuracy: 0.853\n",
      "epoch 18 iter 130, loss: 0.859, accuracy: 0.839\n",
      "epoch 18 iter 140, loss: 0.955, accuracy: 0.823\n",
      "epoch 18 iter 150, loss: 0.829, accuracy: 0.851\n",
      "epoch 18 iter 160, loss: 0.939, accuracy: 0.820\n",
      "epoch 18 iter 170, loss: 0.800, accuracy: 0.841\n",
      "epoch 18 iter 180, loss: 0.832, accuracy: 0.852\n",
      "epoch 18 iter 190, loss: 0.934, accuracy: 0.828\n",
      "epoch 18 iter 200, loss: 0.825, accuracy: 0.851\n",
      "epoch 18 iter 210, loss: 0.803, accuracy: 0.850\n",
      "epoch 18 iter 220, loss: 0.845, accuracy: 0.837\n",
      "epoch 18 iter 230, loss: 0.940, accuracy: 0.821\n",
      "epoch 18 iter 240, loss: 0.963, accuracy: 0.827\n",
      "epoch 18 iter 250, loss: 0.990, accuracy: 0.820\n",
      "epoch 18 iter 260, loss: 0.954, accuracy: 0.829\n",
      "epoch 18 iter 270, loss: 0.856, accuracy: 0.842\n",
      "epoch 18 iter 280, loss: 1.012, accuracy: 0.836\n",
      "epoch 19 iter 0, loss: 0.901, accuracy: 0.840\n",
      "epoch 19 iter 10, loss: 0.877, accuracy: 0.850\n",
      "epoch 19 iter 20, loss: 0.919, accuracy: 0.844\n",
      "epoch 19 iter 30, loss: 0.889, accuracy: 0.832\n",
      "epoch 19 iter 40, loss: 0.858, accuracy: 0.844\n",
      "epoch 19 iter 50, loss: 0.834, accuracy: 0.846\n",
      "epoch 19 iter 60, loss: 0.886, accuracy: 0.824\n",
      "epoch 19 iter 70, loss: 0.835, accuracy: 0.847\n",
      "epoch 19 iter 80, loss: 0.845, accuracy: 0.846\n",
      "epoch 19 iter 90, loss: 0.868, accuracy: 0.842\n",
      "epoch 19 iter 100, loss: 0.924, accuracy: 0.842\n",
      "epoch 19 iter 110, loss: 0.965, accuracy: 0.828\n",
      "epoch 19 iter 120, loss: 0.846, accuracy: 0.838\n",
      "epoch 19 iter 130, loss: 0.844, accuracy: 0.845\n",
      "epoch 19 iter 140, loss: 0.914, accuracy: 0.840\n",
      "epoch 19 iter 150, loss: 0.955, accuracy: 0.829\n",
      "epoch 19 iter 160, loss: 0.917, accuracy: 0.843\n",
      "epoch 19 iter 170, loss: 0.845, accuracy: 0.837\n",
      "epoch 19 iter 180, loss: 0.847, accuracy: 0.848\n",
      "epoch 19 iter 190, loss: 0.913, accuracy: 0.840\n",
      "epoch 19 iter 200, loss: 0.875, accuracy: 0.850\n",
      "epoch 19 iter 210, loss: 0.875, accuracy: 0.848\n",
      "epoch 19 iter 220, loss: 0.838, accuracy: 0.846\n",
      "epoch 19 iter 230, loss: 0.895, accuracy: 0.844\n",
      "epoch 19 iter 240, loss: 0.923, accuracy: 0.842\n",
      "epoch 19 iter 250, loss: 0.881, accuracy: 0.835\n",
      "epoch 19 iter 260, loss: 0.942, accuracy: 0.841\n",
      "epoch 19 iter 270, loss: 0.955, accuracy: 0.837\n",
      "epoch 19 iter 280, loss: 0.976, accuracy: 0.847\n",
      "epoch 20 iter 0, loss: 0.923, accuracy: 0.841\n",
      "epoch 20 iter 10, loss: 0.932, accuracy: 0.852\n",
      "epoch 20 iter 20, loss: 0.960, accuracy: 0.846\n",
      "epoch 20 iter 30, loss: 1.006, accuracy: 0.826\n",
      "epoch 20 iter 40, loss: 0.995, accuracy: 0.836\n",
      "epoch 20 iter 50, loss: 0.937, accuracy: 0.844\n",
      "epoch 20 iter 60, loss: 0.935, accuracy: 0.823\n",
      "epoch 20 iter 70, loss: 0.993, accuracy: 0.831\n",
      "epoch 20 iter 80, loss: 0.914, accuracy: 0.845\n",
      "epoch 20 iter 90, loss: 0.880, accuracy: 0.850\n",
      "epoch 20 iter 100, loss: 1.025, accuracy: 0.843\n",
      "epoch 20 iter 110, loss: 0.942, accuracy: 0.846\n",
      "epoch 20 iter 120, loss: 0.872, accuracy: 0.842\n",
      "epoch 20 iter 130, loss: 1.023, accuracy: 0.831\n",
      "epoch 20 iter 140, loss: 1.021, accuracy: 0.834\n",
      "epoch 20 iter 150, loss: 0.957, accuracy: 0.842\n",
      "epoch 20 iter 160, loss: 0.970, accuracy: 0.844\n",
      "epoch 20 iter 170, loss: 0.893, accuracy: 0.851\n",
      "epoch 20 iter 180, loss: 1.007, accuracy: 0.825\n",
      "epoch 20 iter 190, loss: 0.929, accuracy: 0.846\n",
      "epoch 20 iter 200, loss: 0.968, accuracy: 0.839\n",
      "epoch 20 iter 210, loss: 1.001, accuracy: 0.834\n",
      "epoch 20 iter 220, loss: 0.904, accuracy: 0.848\n",
      "epoch 20 iter 230, loss: 0.913, accuracy: 0.851\n",
      "epoch 20 iter 240, loss: 0.950, accuracy: 0.848\n",
      "epoch 20 iter 250, loss: 0.957, accuracy: 0.830\n",
      "epoch 20 iter 260, loss: 0.998, accuracy: 0.838\n",
      "epoch 20 iter 270, loss: 1.083, accuracy: 0.823\n",
      "epoch 20 iter 280, loss: 1.011, accuracy: 0.843\n",
      "epoch 21 iter 0, loss: 1.037, accuracy: 0.841\n",
      "epoch 21 iter 10, loss: 1.031, accuracy: 0.844\n",
      "epoch 21 iter 20, loss: 0.964, accuracy: 0.851\n",
      "epoch 21 iter 30, loss: 0.973, accuracy: 0.839\n",
      "epoch 21 iter 40, loss: 0.901, accuracy: 0.844\n",
      "epoch 21 iter 50, loss: 0.951, accuracy: 0.847\n",
      "epoch 21 iter 60, loss: 0.926, accuracy: 0.833\n",
      "epoch 21 iter 70, loss: 1.029, accuracy: 0.832\n",
      "epoch 21 iter 80, loss: 0.930, accuracy: 0.847\n",
      "epoch 21 iter 90, loss: 0.910, accuracy: 0.851\n",
      "epoch 21 iter 100, loss: 1.070, accuracy: 0.833\n",
      "epoch 21 iter 110, loss: 1.012, accuracy: 0.842\n",
      "epoch 21 iter 120, loss: 0.929, accuracy: 0.846\n",
      "epoch 21 iter 130, loss: 1.182, accuracy: 0.813\n",
      "epoch 21 iter 140, loss: 0.952, accuracy: 0.840\n",
      "epoch 21 iter 150, loss: 1.008, accuracy: 0.845\n",
      "epoch 21 iter 160, loss: 1.065, accuracy: 0.845\n",
      "epoch 21 iter 170, loss: 1.004, accuracy: 0.845\n",
      "epoch 21 iter 180, loss: 1.041, accuracy: 0.833\n",
      "epoch 21 iter 190, loss: 0.933, accuracy: 0.851\n",
      "epoch 21 iter 200, loss: 1.005, accuracy: 0.841\n",
      "epoch 21 iter 210, loss: 1.044, accuracy: 0.835\n",
      "epoch 21 iter 220, loss: 0.972, accuracy: 0.847\n",
      "epoch 21 iter 230, loss: 1.040, accuracy: 0.840\n",
      "epoch 21 iter 240, loss: 1.002, accuracy: 0.843\n",
      "epoch 21 iter 250, loss: 0.995, accuracy: 0.851\n",
      "epoch 21 iter 260, loss: 1.123, accuracy: 0.831\n",
      "epoch 21 iter 270, loss: 1.080, accuracy: 0.840\n",
      "epoch 21 iter 280, loss: 1.098, accuracy: 0.837\n",
      "epoch 22 iter 0, loss: 1.291, accuracy: 0.828\n",
      "epoch 22 iter 10, loss: 1.072, accuracy: 0.838\n",
      "epoch 22 iter 20, loss: 1.100, accuracy: 0.828\n",
      "epoch 22 iter 30, loss: 1.057, accuracy: 0.830\n",
      "epoch 22 iter 40, loss: 1.087, accuracy: 0.829\n",
      "epoch 22 iter 50, loss: 1.066, accuracy: 0.835\n",
      "epoch 22 iter 60, loss: 0.964, accuracy: 0.846\n",
      "epoch 22 iter 70, loss: 0.960, accuracy: 0.851\n",
      "epoch 22 iter 80, loss: 0.964, accuracy: 0.848\n",
      "epoch 22 iter 90, loss: 1.029, accuracy: 0.842\n",
      "epoch 22 iter 100, loss: 1.097, accuracy: 0.838\n",
      "epoch 22 iter 110, loss: 1.036, accuracy: 0.846\n",
      "epoch 22 iter 120, loss: 1.038, accuracy: 0.840\n",
      "epoch 22 iter 130, loss: 0.999, accuracy: 0.848\n",
      "epoch 22 iter 140, loss: 1.041, accuracy: 0.833\n",
      "epoch 22 iter 150, loss: 1.201, accuracy: 0.817\n",
      "epoch 22 iter 160, loss: 1.104, accuracy: 0.834\n",
      "epoch 22 iter 170, loss: 0.999, accuracy: 0.845\n",
      "epoch 22 iter 180, loss: 1.089, accuracy: 0.830\n",
      "epoch 22 iter 190, loss: 0.983, accuracy: 0.847\n",
      "epoch 22 iter 200, loss: 1.103, accuracy: 0.841\n",
      "epoch 22 iter 210, loss: 0.990, accuracy: 0.844\n",
      "epoch 22 iter 220, loss: 0.951, accuracy: 0.846\n",
      "epoch 22 iter 230, loss: 0.972, accuracy: 0.850\n",
      "epoch 22 iter 240, loss: 0.945, accuracy: 0.855\n",
      "epoch 22 iter 250, loss: 1.006, accuracy: 0.854\n",
      "epoch 22 iter 260, loss: 1.141, accuracy: 0.829\n",
      "epoch 22 iter 270, loss: 1.236, accuracy: 0.827\n",
      "epoch 22 iter 280, loss: 1.063, accuracy: 0.831\n",
      "epoch 23 iter 0, loss: 1.304, accuracy: 0.830\n",
      "epoch 23 iter 10, loss: 1.062, accuracy: 0.847\n",
      "epoch 23 iter 20, loss: 1.007, accuracy: 0.842\n",
      "epoch 23 iter 30, loss: 1.026, accuracy: 0.848\n",
      "epoch 23 iter 40, loss: 1.013, accuracy: 0.847\n",
      "epoch 23 iter 50, loss: 1.053, accuracy: 0.846\n",
      "epoch 23 iter 60, loss: 1.012, accuracy: 0.840\n",
      "epoch 23 iter 70, loss: 0.954, accuracy: 0.848\n",
      "epoch 23 iter 80, loss: 0.990, accuracy: 0.844\n",
      "epoch 23 iter 90, loss: 1.135, accuracy: 0.825\n",
      "epoch 23 iter 100, loss: 0.959, accuracy: 0.847\n",
      "epoch 23 iter 110, loss: 1.024, accuracy: 0.854\n",
      "epoch 23 iter 120, loss: 1.122, accuracy: 0.831\n",
      "epoch 23 iter 130, loss: 0.982, accuracy: 0.855\n",
      "epoch 23 iter 140, loss: 0.993, accuracy: 0.855\n",
      "epoch 23 iter 150, loss: 1.097, accuracy: 0.833\n",
      "epoch 23 iter 160, loss: 1.093, accuracy: 0.844\n",
      "epoch 23 iter 170, loss: 1.103, accuracy: 0.840\n",
      "epoch 23 iter 180, loss: 1.071, accuracy: 0.832\n",
      "epoch 23 iter 190, loss: 1.029, accuracy: 0.850\n",
      "epoch 23 iter 200, loss: 1.136, accuracy: 0.845\n",
      "epoch 23 iter 210, loss: 1.091, accuracy: 0.851\n",
      "epoch 23 iter 220, loss: 1.033, accuracy: 0.842\n",
      "epoch 23 iter 230, loss: 1.023, accuracy: 0.850\n",
      "epoch 23 iter 240, loss: 0.988, accuracy: 0.857\n",
      "epoch 23 iter 250, loss: 1.062, accuracy: 0.850\n",
      "epoch 23 iter 260, loss: 1.083, accuracy: 0.844\n",
      "epoch 23 iter 270, loss: 1.339, accuracy: 0.815\n",
      "epoch 23 iter 280, loss: 1.258, accuracy: 0.835\n",
      "epoch 24 iter 0, loss: 1.228, accuracy: 0.838\n",
      "epoch 24 iter 10, loss: 1.124, accuracy: 0.837\n",
      "epoch 24 iter 20, loss: 1.120, accuracy: 0.847\n",
      "epoch 24 iter 30, loss: 1.230, accuracy: 0.829\n",
      "epoch 24 iter 40, loss: 1.141, accuracy: 0.842\n",
      "epoch 24 iter 50, loss: 1.150, accuracy: 0.842\n",
      "epoch 24 iter 60, loss: 1.111, accuracy: 0.836\n",
      "epoch 24 iter 70, loss: 1.076, accuracy: 0.849\n",
      "epoch 24 iter 80, loss: 1.083, accuracy: 0.848\n",
      "epoch 24 iter 90, loss: 1.206, accuracy: 0.829\n",
      "epoch 24 iter 100, loss: 1.092, accuracy: 0.841\n",
      "epoch 24 iter 110, loss: 1.122, accuracy: 0.851\n",
      "epoch 24 iter 120, loss: 1.167, accuracy: 0.837\n",
      "epoch 24 iter 130, loss: 1.072, accuracy: 0.855\n",
      "epoch 24 iter 140, loss: 1.085, accuracy: 0.853\n",
      "epoch 24 iter 150, loss: 1.173, accuracy: 0.831\n",
      "epoch 24 iter 160, loss: 1.181, accuracy: 0.831\n",
      "epoch 24 iter 170, loss: 1.179, accuracy: 0.838\n",
      "epoch 24 iter 180, loss: 1.088, accuracy: 0.843\n",
      "epoch 24 iter 190, loss: 1.067, accuracy: 0.842\n",
      "epoch 24 iter 200, loss: 1.158, accuracy: 0.841\n",
      "epoch 24 iter 210, loss: 1.243, accuracy: 0.836\n",
      "epoch 24 iter 220, loss: 1.199, accuracy: 0.838\n",
      "epoch 24 iter 230, loss: 1.059, accuracy: 0.846\n",
      "epoch 24 iter 240, loss: 1.040, accuracy: 0.852\n",
      "epoch 24 iter 250, loss: 1.212, accuracy: 0.829\n",
      "epoch 24 iter 260, loss: 1.145, accuracy: 0.838\n",
      "epoch 24 iter 270, loss: 1.236, accuracy: 0.838\n",
      "epoch 24 iter 280, loss: 1.366, accuracy: 0.824\n",
      "epoch 25 iter 0, loss: 1.369, accuracy: 0.836\n",
      "epoch 25 iter 10, loss: 1.178, accuracy: 0.841\n",
      "epoch 25 iter 20, loss: 1.113, accuracy: 0.851\n",
      "epoch 25 iter 30, loss: 1.125, accuracy: 0.849\n",
      "epoch 25 iter 40, loss: 1.098, accuracy: 0.847\n",
      "epoch 25 iter 50, loss: 1.147, accuracy: 0.845\n",
      "epoch 25 iter 60, loss: 1.216, accuracy: 0.835\n",
      "epoch 25 iter 70, loss: 1.126, accuracy: 0.843\n",
      "epoch 25 iter 80, loss: 1.099, accuracy: 0.853\n",
      "epoch 25 iter 90, loss: 1.118, accuracy: 0.857\n",
      "epoch 25 iter 100, loss: 1.112, accuracy: 0.850\n",
      "epoch 25 iter 110, loss: 1.251, accuracy: 0.840\n",
      "epoch 25 iter 120, loss: 1.216, accuracy: 0.838\n",
      "epoch 25 iter 130, loss: 1.204, accuracy: 0.852\n",
      "epoch 25 iter 140, loss: 1.240, accuracy: 0.850\n",
      "epoch 25 iter 150, loss: 1.193, accuracy: 0.848\n",
      "epoch 25 iter 160, loss: 1.301, accuracy: 0.817\n",
      "epoch 25 iter 170, loss: 1.141, accuracy: 0.846\n",
      "epoch 25 iter 180, loss: 1.131, accuracy: 0.853\n",
      "epoch 25 iter 190, loss: 1.148, accuracy: 0.847\n",
      "epoch 25 iter 200, loss: 1.257, accuracy: 0.832\n",
      "epoch 25 iter 210, loss: 1.257, accuracy: 0.836\n",
      "epoch 25 iter 220, loss: 1.247, accuracy: 0.841\n",
      "epoch 25 iter 230, loss: 1.150, accuracy: 0.843\n",
      "epoch 25 iter 240, loss: 1.141, accuracy: 0.850\n",
      "epoch 25 iter 250, loss: 1.128, accuracy: 0.845\n",
      "epoch 25 iter 260, loss: 1.143, accuracy: 0.842\n",
      "epoch 25 iter 270, loss: 1.186, accuracy: 0.844\n",
      "epoch 25 iter 280, loss: 1.287, accuracy: 0.837\n",
      "epoch 26 iter 0, loss: 1.369, accuracy: 0.835\n",
      "epoch 26 iter 10, loss: 1.329, accuracy: 0.839\n",
      "epoch 26 iter 20, loss: 1.212, accuracy: 0.853\n",
      "epoch 26 iter 30, loss: 1.209, accuracy: 0.850\n",
      "epoch 26 iter 40, loss: 1.223, accuracy: 0.841\n",
      "epoch 26 iter 50, loss: 1.177, accuracy: 0.849\n",
      "epoch 26 iter 60, loss: 1.196, accuracy: 0.840\n",
      "epoch 26 iter 70, loss: 1.140, accuracy: 0.840\n",
      "epoch 26 iter 80, loss: 1.117, accuracy: 0.851\n",
      "epoch 26 iter 90, loss: 1.105, accuracy: 0.854\n",
      "epoch 26 iter 100, loss: 1.178, accuracy: 0.848\n",
      "epoch 26 iter 110, loss: 1.275, accuracy: 0.829\n",
      "epoch 26 iter 120, loss: 1.182, accuracy: 0.837\n",
      "epoch 26 iter 130, loss: 1.219, accuracy: 0.844\n",
      "epoch 26 iter 140, loss: 1.314, accuracy: 0.842\n",
      "epoch 26 iter 150, loss: 1.297, accuracy: 0.841\n",
      "epoch 26 iter 160, loss: 1.317, accuracy: 0.819\n",
      "epoch 26 iter 170, loss: 1.168, accuracy: 0.847\n",
      "epoch 26 iter 180, loss: 1.165, accuracy: 0.848\n",
      "epoch 26 iter 190, loss: 1.142, accuracy: 0.848\n",
      "epoch 26 iter 200, loss: 1.219, accuracy: 0.839\n",
      "epoch 26 iter 210, loss: 1.155, accuracy: 0.846\n",
      "epoch 26 iter 220, loss: 1.280, accuracy: 0.833\n",
      "epoch 26 iter 230, loss: 1.140, accuracy: 0.839\n",
      "epoch 26 iter 240, loss: 1.116, accuracy: 0.851\n",
      "epoch 26 iter 250, loss: 1.199, accuracy: 0.847\n",
      "epoch 26 iter 260, loss: 1.195, accuracy: 0.846\n",
      "epoch 26 iter 270, loss: 1.279, accuracy: 0.843\n",
      "epoch 26 iter 280, loss: 1.202, accuracy: 0.843\n",
      "epoch 27 iter 0, loss: 1.340, accuracy: 0.840\n",
      "epoch 27 iter 10, loss: 1.298, accuracy: 0.844\n",
      "epoch 27 iter 20, loss: 1.268, accuracy: 0.857\n",
      "epoch 27 iter 30, loss: 1.236, accuracy: 0.851\n",
      "epoch 27 iter 40, loss: 1.253, accuracy: 0.842\n",
      "epoch 27 iter 50, loss: 1.287, accuracy: 0.850\n",
      "epoch 27 iter 60, loss: 1.255, accuracy: 0.844\n",
      "epoch 27 iter 70, loss: 1.227, accuracy: 0.844\n",
      "epoch 27 iter 80, loss: 1.254, accuracy: 0.850\n",
      "epoch 27 iter 90, loss: 1.167, accuracy: 0.848\n",
      "epoch 27 iter 100, loss: 1.292, accuracy: 0.842\n",
      "epoch 27 iter 110, loss: 1.291, accuracy: 0.829\n",
      "epoch 27 iter 120, loss: 1.276, accuracy: 0.844\n",
      "epoch 27 iter 130, loss: 1.256, accuracy: 0.838\n",
      "epoch 27 iter 140, loss: 1.366, accuracy: 0.848\n",
      "epoch 27 iter 150, loss: 1.260, accuracy: 0.855\n",
      "epoch 27 iter 160, loss: 1.441, accuracy: 0.831\n",
      "epoch 27 iter 170, loss: 1.245, accuracy: 0.857\n",
      "epoch 27 iter 180, loss: 1.314, accuracy: 0.844\n",
      "epoch 27 iter 190, loss: 1.248, accuracy: 0.840\n",
      "epoch 27 iter 200, loss: 1.276, accuracy: 0.848\n",
      "epoch 27 iter 210, loss: 1.305, accuracy: 0.845\n",
      "epoch 27 iter 220, loss: 1.398, accuracy: 0.843\n",
      "epoch 27 iter 230, loss: 1.270, accuracy: 0.838\n",
      "epoch 27 iter 240, loss: 1.205, accuracy: 0.853\n",
      "epoch 27 iter 250, loss: 1.262, accuracy: 0.853\n",
      "epoch 27 iter 260, loss: 1.254, accuracy: 0.845\n",
      "epoch 27 iter 270, loss: 1.342, accuracy: 0.845\n",
      "epoch 27 iter 280, loss: 1.460, accuracy: 0.837\n",
      "epoch 28 iter 0, loss: 1.643, accuracy: 0.819\n",
      "epoch 28 iter 10, loss: 1.463, accuracy: 0.839\n",
      "epoch 28 iter 20, loss: 1.313, accuracy: 0.853\n",
      "epoch 28 iter 30, loss: 1.315, accuracy: 0.847\n",
      "epoch 28 iter 40, loss: 1.341, accuracy: 0.839\n",
      "epoch 28 iter 50, loss: 1.319, accuracy: 0.848\n",
      "epoch 28 iter 60, loss: 1.286, accuracy: 0.848\n",
      "epoch 28 iter 70, loss: 1.231, accuracy: 0.838\n",
      "epoch 28 iter 80, loss: 1.395, accuracy: 0.842\n",
      "epoch 28 iter 90, loss: 1.248, accuracy: 0.847\n",
      "epoch 28 iter 100, loss: 1.322, accuracy: 0.844\n",
      "epoch 28 iter 110, loss: 1.313, accuracy: 0.842\n",
      "epoch 28 iter 120, loss: 1.368, accuracy: 0.833\n",
      "epoch 28 iter 130, loss: 1.412, accuracy: 0.819\n",
      "epoch 28 iter 140, loss: 1.339, accuracy: 0.849\n",
      "epoch 28 iter 150, loss: 1.303, accuracy: 0.847\n",
      "epoch 28 iter 160, loss: 1.414, accuracy: 0.822\n",
      "epoch 28 iter 170, loss: 1.293, accuracy: 0.843\n",
      "epoch 28 iter 180, loss: 1.387, accuracy: 0.842\n",
      "epoch 28 iter 190, loss: 1.269, accuracy: 0.854\n",
      "epoch 28 iter 200, loss: 1.291, accuracy: 0.855\n",
      "epoch 28 iter 210, loss: 1.323, accuracy: 0.850\n",
      "epoch 28 iter 220, loss: 1.359, accuracy: 0.849\n",
      "epoch 28 iter 230, loss: 1.319, accuracy: 0.848\n",
      "epoch 28 iter 240, loss: 1.303, accuracy: 0.847\n",
      "epoch 28 iter 250, loss: 1.292, accuracy: 0.855\n",
      "epoch 28 iter 260, loss: 1.338, accuracy: 0.846\n",
      "epoch 28 iter 270, loss: 1.383, accuracy: 0.846\n",
      "epoch 28 iter 280, loss: 1.428, accuracy: 0.838\n",
      "epoch 29 iter 0, loss: 1.651, accuracy: 0.826\n",
      "epoch 29 iter 10, loss: 1.469, accuracy: 0.836\n",
      "epoch 29 iter 20, loss: 1.369, accuracy: 0.830\n",
      "epoch 29 iter 30, loss: 1.438, accuracy: 0.840\n",
      "epoch 29 iter 40, loss: 1.377, accuracy: 0.837\n",
      "epoch 29 iter 50, loss: 1.389, accuracy: 0.846\n",
      "epoch 29 iter 60, loss: 1.367, accuracy: 0.849\n",
      "epoch 29 iter 70, loss: 1.270, accuracy: 0.839\n",
      "epoch 29 iter 80, loss: 1.243, accuracy: 0.856\n",
      "epoch 29 iter 90, loss: 1.330, accuracy: 0.854\n",
      "epoch 29 iter 100, loss: 1.339, accuracy: 0.848\n",
      "epoch 29 iter 110, loss: 1.302, accuracy: 0.848\n",
      "epoch 29 iter 120, loss: 1.353, accuracy: 0.843\n",
      "epoch 29 iter 130, loss: 1.398, accuracy: 0.828\n",
      "epoch 29 iter 140, loss: 1.328, accuracy: 0.849\n",
      "epoch 29 iter 150, loss: 1.324, accuracy: 0.854\n",
      "epoch 29 iter 160, loss: 1.493, accuracy: 0.815\n",
      "epoch 29 iter 170, loss: 1.304, accuracy: 0.840\n",
      "epoch 29 iter 180, loss: 1.520, accuracy: 0.831\n",
      "epoch 29 iter 190, loss: 1.293, accuracy: 0.854\n",
      "epoch 29 iter 200, loss: 1.419, accuracy: 0.844\n",
      "epoch 29 iter 210, loss: 1.315, accuracy: 0.854\n",
      "epoch 29 iter 220, loss: 1.418, accuracy: 0.848\n",
      "epoch 29 iter 230, loss: 1.362, accuracy: 0.840\n",
      "epoch 29 iter 240, loss: 1.458, accuracy: 0.826\n",
      "epoch 29 iter 250, loss: 1.306, accuracy: 0.859\n",
      "epoch 29 iter 260, loss: 1.332, accuracy: 0.848\n",
      "epoch 29 iter 270, loss: 1.260, accuracy: 0.854\n",
      "epoch 29 iter 280, loss: 1.315, accuracy: 0.857\n",
      "epoch 30 iter 0, loss: 1.533, accuracy: 0.838\n",
      "epoch 30 iter 10, loss: 1.458, accuracy: 0.839\n",
      "epoch 30 iter 20, loss: 1.391, accuracy: 0.853\n",
      "epoch 30 iter 30, loss: 1.490, accuracy: 0.834\n",
      "epoch 30 iter 40, loss: 1.308, accuracy: 0.857\n",
      "epoch 30 iter 50, loss: 1.451, accuracy: 0.851\n",
      "epoch 30 iter 60, loss: 1.420, accuracy: 0.854\n",
      "epoch 30 iter 70, loss: 1.452, accuracy: 0.835\n",
      "epoch 30 iter 80, loss: 1.343, accuracy: 0.852\n",
      "epoch 30 iter 90, loss: 1.381, accuracy: 0.852\n",
      "epoch 30 iter 100, loss: 1.436, accuracy: 0.854\n",
      "epoch 30 iter 110, loss: 1.400, accuracy: 0.851\n",
      "epoch 30 iter 120, loss: 1.407, accuracy: 0.849\n",
      "epoch 30 iter 130, loss: 1.358, accuracy: 0.838\n",
      "epoch 30 iter 140, loss: 1.352, accuracy: 0.846\n",
      "epoch 30 iter 150, loss: 1.400, accuracy: 0.855\n",
      "epoch 30 iter 160, loss: 1.452, accuracy: 0.830\n",
      "epoch 30 iter 170, loss: 1.373, accuracy: 0.836\n",
      "epoch 30 iter 180, loss: 1.405, accuracy: 0.843\n",
      "epoch 30 iter 190, loss: 1.332, accuracy: 0.854\n",
      "epoch 30 iter 200, loss: 1.341, accuracy: 0.859\n",
      "epoch 30 iter 210, loss: 1.411, accuracy: 0.848\n",
      "epoch 30 iter 220, loss: 1.553, accuracy: 0.834\n",
      "epoch 30 iter 230, loss: 1.304, accuracy: 0.845\n",
      "epoch 30 iter 240, loss: 1.477, accuracy: 0.843\n",
      "epoch 30 iter 250, loss: 1.314, accuracy: 0.859\n",
      "epoch 30 iter 260, loss: 1.493, accuracy: 0.843\n",
      "epoch 30 iter 270, loss: 1.485, accuracy: 0.837\n",
      "epoch 30 iter 280, loss: 1.515, accuracy: 0.847\n",
      "epoch 31 iter 0, loss: 1.648, accuracy: 0.842\n",
      "epoch 31 iter 10, loss: 1.507, accuracy: 0.846\n",
      "epoch 31 iter 20, loss: 1.655, accuracy: 0.839\n",
      "epoch 31 iter 30, loss: 1.551, accuracy: 0.832\n",
      "epoch 31 iter 40, loss: 1.467, accuracy: 0.841\n",
      "epoch 31 iter 50, loss: 1.578, accuracy: 0.839\n",
      "epoch 31 iter 60, loss: 1.389, accuracy: 0.846\n",
      "epoch 31 iter 70, loss: 1.456, accuracy: 0.836\n",
      "epoch 31 iter 80, loss: 1.515, accuracy: 0.849\n",
      "epoch 31 iter 90, loss: 1.445, accuracy: 0.847\n",
      "epoch 31 iter 100, loss: 1.493, accuracy: 0.854\n",
      "epoch 31 iter 110, loss: 1.503, accuracy: 0.852\n",
      "epoch 31 iter 120, loss: 1.541, accuracy: 0.849\n",
      "epoch 31 iter 130, loss: 1.427, accuracy: 0.840\n",
      "epoch 31 iter 140, loss: 1.586, accuracy: 0.822\n",
      "epoch 31 iter 150, loss: 1.466, accuracy: 0.843\n",
      "epoch 31 iter 160, loss: 1.516, accuracy: 0.828\n",
      "epoch 31 iter 170, loss: 1.480, accuracy: 0.829\n",
      "epoch 31 iter 180, loss: 1.417, accuracy: 0.851\n",
      "epoch 31 iter 190, loss: 1.435, accuracy: 0.850\n",
      "epoch 31 iter 200, loss: 1.357, accuracy: 0.856\n",
      "epoch 31 iter 210, loss: 1.503, accuracy: 0.852\n",
      "epoch 31 iter 220, loss: 1.524, accuracy: 0.846\n",
      "epoch 31 iter 230, loss: 1.373, accuracy: 0.850\n",
      "epoch 31 iter 240, loss: 1.503, accuracy: 0.834\n",
      "epoch 31 iter 250, loss: 1.249, accuracy: 0.851\n",
      "epoch 31 iter 260, loss: 1.554, accuracy: 0.844\n",
      "epoch 31 iter 270, loss: 1.483, accuracy: 0.851\n",
      "epoch 31 iter 280, loss: 1.462, accuracy: 0.854\n",
      "epoch 32 iter 0, loss: 1.544, accuracy: 0.847\n",
      "epoch 32 iter 10, loss: 1.557, accuracy: 0.851\n",
      "epoch 32 iter 20, loss: 1.676, accuracy: 0.841\n",
      "epoch 32 iter 30, loss: 1.451, accuracy: 0.849\n",
      "epoch 32 iter 40, loss: 1.589, accuracy: 0.837\n",
      "epoch 32 iter 50, loss: 1.556, accuracy: 0.842\n",
      "epoch 32 iter 60, loss: 1.478, accuracy: 0.853\n",
      "epoch 32 iter 70, loss: 1.484, accuracy: 0.834\n",
      "epoch 32 iter 80, loss: 1.501, accuracy: 0.853\n",
      "epoch 32 iter 90, loss: 1.504, accuracy: 0.856\n",
      "epoch 32 iter 100, loss: 1.513, accuracy: 0.851\n",
      "epoch 32 iter 110, loss: 1.607, accuracy: 0.854\n",
      "epoch 32 iter 120, loss: 1.608, accuracy: 0.851\n",
      "epoch 32 iter 130, loss: 1.601, accuracy: 0.837\n",
      "epoch 32 iter 140, loss: 1.677, accuracy: 0.830\n",
      "epoch 32 iter 150, loss: 1.611, accuracy: 0.846\n",
      "epoch 32 iter 160, loss: 1.841, accuracy: 0.826\n",
      "epoch 32 iter 170, loss: 1.763, accuracy: 0.820\n",
      "epoch 32 iter 180, loss: 1.450, accuracy: 0.848\n",
      "epoch 32 iter 190, loss: 1.583, accuracy: 0.846\n",
      "epoch 32 iter 200, loss: 1.499, accuracy: 0.850\n",
      "epoch 32 iter 210, loss: 1.500, accuracy: 0.855\n",
      "epoch 32 iter 220, loss: 1.636, accuracy: 0.847\n",
      "epoch 32 iter 230, loss: 1.437, accuracy: 0.849\n",
      "epoch 32 iter 240, loss: 1.628, accuracy: 0.832\n",
      "epoch 32 iter 250, loss: 1.414, accuracy: 0.850\n",
      "epoch 32 iter 260, loss: 1.555, accuracy: 0.847\n",
      "epoch 32 iter 270, loss: 1.551, accuracy: 0.856\n",
      "epoch 32 iter 280, loss: 1.597, accuracy: 0.850\n",
      "epoch 33 iter 0, loss: 1.676, accuracy: 0.848\n",
      "epoch 33 iter 10, loss: 1.739, accuracy: 0.847\n",
      "epoch 33 iter 20, loss: 1.745, accuracy: 0.845\n",
      "epoch 33 iter 30, loss: 1.491, accuracy: 0.848\n",
      "epoch 33 iter 40, loss: 1.570, accuracy: 0.835\n",
      "epoch 33 iter 50, loss: 1.513, accuracy: 0.833\n",
      "epoch 33 iter 60, loss: 1.621, accuracy: 0.845\n",
      "epoch 33 iter 70, loss: 1.750, accuracy: 0.831\n",
      "epoch 33 iter 80, loss: 1.615, accuracy: 0.840\n",
      "epoch 33 iter 90, loss: 1.562, accuracy: 0.855\n",
      "epoch 33 iter 100, loss: 1.516, accuracy: 0.860\n",
      "epoch 33 iter 110, loss: 1.590, accuracy: 0.855\n",
      "epoch 33 iter 120, loss: 1.621, accuracy: 0.848\n",
      "epoch 33 iter 130, loss: 1.576, accuracy: 0.842\n",
      "epoch 33 iter 140, loss: 1.625, accuracy: 0.832\n",
      "epoch 33 iter 150, loss: 1.718, accuracy: 0.839\n",
      "epoch 33 iter 160, loss: 1.734, accuracy: 0.838\n",
      "epoch 33 iter 170, loss: 1.632, accuracy: 0.832\n",
      "epoch 33 iter 180, loss: 1.635, accuracy: 0.839\n",
      "epoch 33 iter 190, loss: 1.579, accuracy: 0.853\n",
      "epoch 33 iter 200, loss: 1.555, accuracy: 0.852\n",
      "epoch 33 iter 210, loss: 1.689, accuracy: 0.849\n",
      "epoch 33 iter 220, loss: 1.601, accuracy: 0.857\n",
      "epoch 33 iter 230, loss: 1.602, accuracy: 0.856\n",
      "epoch 33 iter 240, loss: 1.594, accuracy: 0.849\n",
      "epoch 33 iter 250, loss: 1.424, accuracy: 0.853\n",
      "epoch 33 iter 260, loss: 1.551, accuracy: 0.853\n",
      "epoch 33 iter 270, loss: 1.534, accuracy: 0.853\n",
      "epoch 33 iter 280, loss: 1.612, accuracy: 0.852\n",
      "epoch 34 iter 0, loss: 1.620, accuracy: 0.854\n",
      "epoch 34 iter 10, loss: 1.764, accuracy: 0.841\n",
      "epoch 34 iter 20, loss: 1.598, accuracy: 0.849\n",
      "epoch 34 iter 30, loss: 1.534, accuracy: 0.854\n",
      "epoch 34 iter 40, loss: 1.651, accuracy: 0.851\n",
      "epoch 34 iter 50, loss: 1.702, accuracy: 0.838\n",
      "epoch 34 iter 60, loss: 1.605, accuracy: 0.846\n",
      "epoch 34 iter 70, loss: 1.608, accuracy: 0.849\n",
      "epoch 34 iter 80, loss: 1.749, accuracy: 0.841\n",
      "epoch 34 iter 90, loss: 1.640, accuracy: 0.849\n",
      "epoch 34 iter 100, loss: 1.651, accuracy: 0.850\n",
      "epoch 34 iter 110, loss: 1.673, accuracy: 0.854\n",
      "epoch 34 iter 120, loss: 1.654, accuracy: 0.856\n",
      "epoch 34 iter 130, loss: 1.647, accuracy: 0.852\n",
      "epoch 34 iter 140, loss: 1.734, accuracy: 0.842\n",
      "epoch 34 iter 150, loss: 1.764, accuracy: 0.841\n",
      "epoch 34 iter 160, loss: 1.803, accuracy: 0.836\n",
      "epoch 34 iter 170, loss: 1.729, accuracy: 0.833\n",
      "epoch 34 iter 180, loss: 1.689, accuracy: 0.846\n",
      "epoch 34 iter 190, loss: 1.599, accuracy: 0.852\n",
      "epoch 34 iter 200, loss: 1.569, accuracy: 0.862\n",
      "epoch 34 iter 210, loss: 1.684, accuracy: 0.859\n",
      "epoch 34 iter 220, loss: 1.663, accuracy: 0.850\n",
      "epoch 34 iter 230, loss: 1.718, accuracy: 0.854\n",
      "epoch 34 iter 240, loss: 1.627, accuracy: 0.846\n",
      "epoch 34 iter 250, loss: 1.543, accuracy: 0.840\n",
      "epoch 34 iter 260, loss: 1.710, accuracy: 0.843\n",
      "epoch 34 iter 270, loss: 1.609, accuracy: 0.851\n",
      "epoch 34 iter 280, loss: 1.714, accuracy: 0.845\n",
      "epoch 35 iter 0, loss: 1.766, accuracy: 0.851\n",
      "epoch 35 iter 10, loss: 1.856, accuracy: 0.846\n",
      "epoch 35 iter 20, loss: 1.829, accuracy: 0.843\n",
      "epoch 35 iter 30, loss: 1.638, accuracy: 0.853\n",
      "epoch 35 iter 40, loss: 1.648, accuracy: 0.855\n",
      "epoch 35 iter 50, loss: 1.767, accuracy: 0.837\n",
      "epoch 35 iter 60, loss: 1.651, accuracy: 0.842\n",
      "epoch 35 iter 70, loss: 1.705, accuracy: 0.848\n",
      "epoch 35 iter 80, loss: 1.665, accuracy: 0.850\n",
      "epoch 35 iter 90, loss: 1.814, accuracy: 0.839\n",
      "epoch 35 iter 100, loss: 1.726, accuracy: 0.841\n",
      "epoch 35 iter 110, loss: 1.725, accuracy: 0.847\n",
      "epoch 35 iter 120, loss: 1.767, accuracy: 0.848\n",
      "epoch 35 iter 130, loss: 1.683, accuracy: 0.851\n",
      "epoch 35 iter 140, loss: 1.664, accuracy: 0.853\n",
      "epoch 35 iter 150, loss: 1.761, accuracy: 0.835\n",
      "epoch 35 iter 160, loss: 1.793, accuracy: 0.840\n",
      "epoch 35 iter 170, loss: 1.752, accuracy: 0.838\n",
      "epoch 35 iter 180, loss: 1.862, accuracy: 0.834\n",
      "epoch 35 iter 190, loss: 1.674, accuracy: 0.845\n",
      "epoch 35 iter 200, loss: 1.670, accuracy: 0.846\n",
      "epoch 35 iter 210, loss: 1.667, accuracy: 0.852\n",
      "epoch 35 iter 220, loss: 1.795, accuracy: 0.850\n",
      "epoch 35 iter 230, loss: 1.638, accuracy: 0.852\n",
      "epoch 35 iter 240, loss: 1.646, accuracy: 0.855\n",
      "epoch 35 iter 250, loss: 1.639, accuracy: 0.844\n",
      "epoch 35 iter 260, loss: 1.635, accuracy: 0.849\n",
      "epoch 35 iter 270, loss: 1.659, accuracy: 0.852\n",
      "epoch 35 iter 280, loss: 1.689, accuracy: 0.847\n",
      "epoch 36 iter 0, loss: 1.784, accuracy: 0.848\n",
      "epoch 36 iter 10, loss: 1.791, accuracy: 0.849\n",
      "epoch 36 iter 20, loss: 1.880, accuracy: 0.845\n",
      "epoch 36 iter 30, loss: 1.741, accuracy: 0.854\n",
      "epoch 36 iter 40, loss: 1.763, accuracy: 0.844\n",
      "epoch 36 iter 50, loss: 1.770, accuracy: 0.845\n",
      "epoch 36 iter 60, loss: 1.663, accuracy: 0.847\n",
      "epoch 36 iter 70, loss: 1.840, accuracy: 0.845\n",
      "epoch 36 iter 80, loss: 1.627, accuracy: 0.846\n",
      "epoch 36 iter 90, loss: 1.735, accuracy: 0.847\n",
      "epoch 36 iter 100, loss: 1.875, accuracy: 0.835\n",
      "epoch 36 iter 110, loss: 1.867, accuracy: 0.844\n",
      "epoch 36 iter 120, loss: 1.829, accuracy: 0.848\n",
      "epoch 36 iter 130, loss: 1.853, accuracy: 0.843\n",
      "epoch 36 iter 140, loss: 1.839, accuracy: 0.844\n",
      "epoch 36 iter 150, loss: 1.865, accuracy: 0.840\n",
      "epoch 36 iter 160, loss: 1.925, accuracy: 0.835\n",
      "epoch 36 iter 170, loss: 1.862, accuracy: 0.830\n",
      "epoch 36 iter 180, loss: 1.893, accuracy: 0.842\n",
      "epoch 36 iter 190, loss: 1.717, accuracy: 0.849\n",
      "epoch 36 iter 200, loss: 1.734, accuracy: 0.846\n",
      "epoch 36 iter 210, loss: 1.713, accuracy: 0.852\n",
      "epoch 36 iter 220, loss: 1.968, accuracy: 0.842\n",
      "epoch 36 iter 230, loss: 1.678, accuracy: 0.856\n",
      "epoch 36 iter 240, loss: 1.688, accuracy: 0.855\n",
      "epoch 36 iter 250, loss: 1.677, accuracy: 0.854\n",
      "epoch 36 iter 260, loss: 1.678, accuracy: 0.858\n",
      "epoch 36 iter 270, loss: 1.808, accuracy: 0.854\n",
      "epoch 36 iter 280, loss: 1.724, accuracy: 0.846\n",
      "epoch 37 iter 0, loss: 1.766, accuracy: 0.853\n",
      "epoch 37 iter 10, loss: 1.873, accuracy: 0.849\n",
      "epoch 37 iter 20, loss: 1.842, accuracy: 0.837\n",
      "epoch 37 iter 30, loss: 1.846, accuracy: 0.852\n",
      "epoch 37 iter 40, loss: 1.806, accuracy: 0.850\n",
      "epoch 37 iter 50, loss: 1.819, accuracy: 0.845\n",
      "epoch 37 iter 60, loss: 1.790, accuracy: 0.849\n",
      "epoch 37 iter 70, loss: 1.842, accuracy: 0.846\n",
      "epoch 37 iter 80, loss: 1.815, accuracy: 0.838\n",
      "epoch 37 iter 90, loss: 1.996, accuracy: 0.837\n",
      "epoch 37 iter 100, loss: 2.012, accuracy: 0.848\n",
      "epoch 37 iter 110, loss: 1.815, accuracy: 0.852\n",
      "epoch 37 iter 120, loss: 2.008, accuracy: 0.843\n",
      "epoch 37 iter 130, loss: 1.835, accuracy: 0.846\n",
      "epoch 37 iter 140, loss: 1.868, accuracy: 0.846\n",
      "epoch 37 iter 150, loss: 2.001, accuracy: 0.848\n",
      "epoch 37 iter 160, loss: 1.861, accuracy: 0.857\n",
      "epoch 37 iter 170, loss: 1.884, accuracy: 0.825\n",
      "epoch 37 iter 180, loss: 1.920, accuracy: 0.839\n",
      "epoch 37 iter 190, loss: 1.838, accuracy: 0.850\n",
      "epoch 37 iter 200, loss: 1.827, accuracy: 0.839\n",
      "epoch 37 iter 210, loss: 1.746, accuracy: 0.859\n",
      "epoch 37 iter 220, loss: 1.879, accuracy: 0.849\n",
      "epoch 37 iter 230, loss: 1.837, accuracy: 0.846\n",
      "epoch 37 iter 240, loss: 1.898, accuracy: 0.851\n",
      "epoch 37 iter 250, loss: 1.761, accuracy: 0.855\n",
      "epoch 37 iter 260, loss: 1.956, accuracy: 0.851\n",
      "epoch 37 iter 270, loss: 1.898, accuracy: 0.848\n",
      "epoch 37 iter 280, loss: 1.958, accuracy: 0.853\n",
      "epoch 38 iter 0, loss: 2.097, accuracy: 0.843\n",
      "epoch 38 iter 10, loss: 1.936, accuracy: 0.852\n",
      "epoch 38 iter 20, loss: 1.946, accuracy: 0.841\n",
      "epoch 38 iter 30, loss: 1.972, accuracy: 0.837\n",
      "epoch 38 iter 40, loss: 2.048, accuracy: 0.836\n",
      "epoch 38 iter 50, loss: 1.851, accuracy: 0.850\n",
      "epoch 38 iter 60, loss: 1.838, accuracy: 0.841\n",
      "epoch 38 iter 70, loss: 1.853, accuracy: 0.838\n",
      "epoch 38 iter 80, loss: 1.873, accuracy: 0.841\n",
      "epoch 38 iter 90, loss: 1.800, accuracy: 0.843\n",
      "epoch 38 iter 100, loss: 1.918, accuracy: 0.853\n",
      "epoch 38 iter 110, loss: 1.864, accuracy: 0.854\n",
      "epoch 38 iter 120, loss: 1.875, accuracy: 0.844\n",
      "epoch 38 iter 130, loss: 1.726, accuracy: 0.851\n",
      "epoch 38 iter 140, loss: 1.839, accuracy: 0.854\n",
      "epoch 38 iter 150, loss: 1.920, accuracy: 0.848\n",
      "epoch 38 iter 160, loss: 1.962, accuracy: 0.848\n",
      "epoch 38 iter 170, loss: 2.044, accuracy: 0.808\n",
      "epoch 38 iter 180, loss: 1.821, accuracy: 0.846\n",
      "epoch 38 iter 190, loss: 2.008, accuracy: 0.833\n",
      "epoch 38 iter 200, loss: 1.820, accuracy: 0.849\n",
      "epoch 38 iter 210, loss: 1.849, accuracy: 0.846\n",
      "epoch 38 iter 220, loss: 1.941, accuracy: 0.844\n",
      "epoch 38 iter 230, loss: 2.062, accuracy: 0.841\n",
      "epoch 38 iter 240, loss: 1.869, accuracy: 0.849\n",
      "epoch 38 iter 250, loss: 1.837, accuracy: 0.854\n",
      "epoch 38 iter 260, loss: 1.801, accuracy: 0.850\n",
      "epoch 38 iter 270, loss: 1.932, accuracy: 0.848\n",
      "epoch 38 iter 280, loss: 1.788, accuracy: 0.854\n",
      "epoch 39 iter 0, loss: 1.993, accuracy: 0.851\n",
      "epoch 39 iter 10, loss: 1.886, accuracy: 0.860\n",
      "epoch 39 iter 20, loss: 2.025, accuracy: 0.846\n",
      "epoch 39 iter 30, loss: 1.940, accuracy: 0.840\n",
      "epoch 39 iter 40, loss: 2.006, accuracy: 0.848\n",
      "epoch 39 iter 50, loss: 1.840, accuracy: 0.860\n",
      "epoch 39 iter 60, loss: 1.803, accuracy: 0.854\n",
      "epoch 39 iter 70, loss: 1.833, accuracy: 0.858\n",
      "epoch 39 iter 80, loss: 1.825, accuracy: 0.847\n",
      "epoch 39 iter 90, loss: 1.761, accuracy: 0.848\n",
      "epoch 39 iter 100, loss: 1.904, accuracy: 0.847\n",
      "epoch 39 iter 110, loss: 1.819, accuracy: 0.854\n",
      "epoch 39 iter 120, loss: 1.978, accuracy: 0.851\n",
      "epoch 39 iter 130, loss: 1.855, accuracy: 0.855\n",
      "epoch 39 iter 140, loss: 1.874, accuracy: 0.852\n",
      "epoch 39 iter 150, loss: 1.826, accuracy: 0.861\n",
      "epoch 39 iter 160, loss: 1.808, accuracy: 0.860\n",
      "epoch 39 iter 170, loss: 2.028, accuracy: 0.828\n",
      "epoch 39 iter 180, loss: 1.790, accuracy: 0.855\n",
      "epoch 39 iter 190, loss: 2.198, accuracy: 0.830\n",
      "epoch 39 iter 200, loss: 1.905, accuracy: 0.849\n",
      "epoch 39 iter 210, loss: 1.897, accuracy: 0.842\n",
      "epoch 39 iter 220, loss: 2.046, accuracy: 0.844\n",
      "epoch 39 iter 230, loss: 2.044, accuracy: 0.852\n",
      "epoch 39 iter 240, loss: 1.766, accuracy: 0.862\n",
      "epoch 39 iter 250, loss: 1.895, accuracy: 0.852\n",
      "epoch 39 iter 260, loss: 1.808, accuracy: 0.851\n",
      "epoch 39 iter 270, loss: 1.952, accuracy: 0.850\n",
      "epoch 39 iter 280, loss: 1.759, accuracy: 0.854\n",
      "epoch 40 iter 0, loss: 1.899, accuracy: 0.856\n",
      "epoch 40 iter 10, loss: 1.995, accuracy: 0.860\n",
      "epoch 40 iter 20, loss: 1.995, accuracy: 0.850\n",
      "epoch 40 iter 30, loss: 1.997, accuracy: 0.854\n",
      "epoch 40 iter 40, loss: 1.952, accuracy: 0.849\n",
      "epoch 40 iter 50, loss: 2.047, accuracy: 0.857\n",
      "epoch 40 iter 60, loss: 2.017, accuracy: 0.843\n",
      "epoch 40 iter 70, loss: 1.858, accuracy: 0.854\n",
      "epoch 40 iter 80, loss: 1.911, accuracy: 0.858\n",
      "epoch 40 iter 90, loss: 1.937, accuracy: 0.853\n",
      "epoch 40 iter 100, loss: 1.902, accuracy: 0.855\n",
      "epoch 40 iter 110, loss: 1.908, accuracy: 0.855\n",
      "epoch 40 iter 120, loss: 1.930, accuracy: 0.859\n",
      "epoch 40 iter 130, loss: 2.053, accuracy: 0.851\n",
      "epoch 40 iter 140, loss: 2.053, accuracy: 0.848\n",
      "epoch 40 iter 150, loss: 2.011, accuracy: 0.854\n",
      "epoch 40 iter 160, loss: 1.926, accuracy: 0.856\n",
      "epoch 40 iter 170, loss: 1.936, accuracy: 0.842\n",
      "epoch 40 iter 180, loss: 1.851, accuracy: 0.852\n",
      "epoch 40 iter 190, loss: 2.074, accuracy: 0.842\n",
      "epoch 40 iter 200, loss: 2.096, accuracy: 0.847\n",
      "epoch 40 iter 210, loss: 1.917, accuracy: 0.855\n",
      "epoch 40 iter 220, loss: 1.907, accuracy: 0.851\n",
      "epoch 40 iter 230, loss: 1.980, accuracy: 0.852\n",
      "epoch 40 iter 240, loss: 1.927, accuracy: 0.859\n",
      "epoch 40 iter 250, loss: 1.933, accuracy: 0.848\n",
      "epoch 40 iter 260, loss: 1.877, accuracy: 0.856\n",
      "epoch 40 iter 270, loss: 2.147, accuracy: 0.844\n",
      "epoch 40 iter 280, loss: 1.892, accuracy: 0.850\n",
      "epoch 41 iter 0, loss: 2.083, accuracy: 0.845\n",
      "epoch 41 iter 10, loss: 2.039, accuracy: 0.856\n",
      "epoch 41 iter 20, loss: 1.997, accuracy: 0.853\n",
      "epoch 41 iter 30, loss: 2.065, accuracy: 0.851\n",
      "epoch 41 iter 40, loss: 1.938, accuracy: 0.854\n",
      "epoch 41 iter 50, loss: 2.010, accuracy: 0.853\n",
      "epoch 41 iter 60, loss: 1.898, accuracy: 0.848\n",
      "epoch 41 iter 70, loss: 1.984, accuracy: 0.854\n",
      "epoch 41 iter 80, loss: 2.010, accuracy: 0.853\n",
      "epoch 41 iter 90, loss: 2.132, accuracy: 0.847\n",
      "epoch 41 iter 100, loss: 1.842, accuracy: 0.856\n",
      "epoch 41 iter 110, loss: 2.043, accuracy: 0.848\n",
      "epoch 41 iter 120, loss: 2.082, accuracy: 0.856\n",
      "epoch 41 iter 130, loss: 2.007, accuracy: 0.853\n",
      "epoch 41 iter 140, loss: 1.944, accuracy: 0.849\n",
      "epoch 41 iter 150, loss: 2.078, accuracy: 0.851\n",
      "epoch 41 iter 160, loss: 1.948, accuracy: 0.854\n",
      "epoch 41 iter 170, loss: 2.012, accuracy: 0.849\n",
      "epoch 41 iter 180, loss: 2.006, accuracy: 0.849\n",
      "epoch 41 iter 190, loss: 2.081, accuracy: 0.843\n",
      "epoch 41 iter 200, loss: 2.010, accuracy: 0.848\n",
      "epoch 41 iter 210, loss: 2.267, accuracy: 0.847\n",
      "epoch 41 iter 220, loss: 2.029, accuracy: 0.857\n",
      "epoch 41 iter 230, loss: 1.994, accuracy: 0.854\n",
      "epoch 41 iter 240, loss: 2.010, accuracy: 0.861\n",
      "epoch 41 iter 250, loss: 2.058, accuracy: 0.845\n",
      "epoch 41 iter 260, loss: 1.906, accuracy: 0.852\n",
      "epoch 41 iter 270, loss: 1.954, accuracy: 0.856\n",
      "epoch 41 iter 280, loss: 1.984, accuracy: 0.854\n",
      "epoch 42 iter 0, loss: 2.200, accuracy: 0.854\n",
      "epoch 42 iter 10, loss: 2.179, accuracy: 0.852\n",
      "epoch 42 iter 20, loss: 2.032, accuracy: 0.851\n",
      "epoch 42 iter 30, loss: 2.140, accuracy: 0.846\n",
      "epoch 42 iter 40, loss: 1.986, accuracy: 0.852\n",
      "epoch 42 iter 50, loss: 2.017, accuracy: 0.857\n",
      "epoch 42 iter 60, loss: 2.013, accuracy: 0.849\n",
      "epoch 42 iter 70, loss: 2.050, accuracy: 0.854\n",
      "epoch 42 iter 80, loss: 1.963, accuracy: 0.862\n",
      "epoch 42 iter 90, loss: 1.863, accuracy: 0.863\n",
      "epoch 42 iter 100, loss: 1.957, accuracy: 0.866\n",
      "epoch 42 iter 110, loss: 2.017, accuracy: 0.858\n",
      "epoch 42 iter 120, loss: 2.167, accuracy: 0.860\n",
      "epoch 42 iter 130, loss: 2.136, accuracy: 0.858\n",
      "epoch 42 iter 140, loss: 2.100, accuracy: 0.848\n",
      "epoch 42 iter 150, loss: 2.234, accuracy: 0.849\n",
      "epoch 42 iter 160, loss: 2.101, accuracy: 0.855\n",
      "epoch 42 iter 170, loss: 2.255, accuracy: 0.843\n",
      "epoch 42 iter 180, loss: 1.942, accuracy: 0.857\n",
      "epoch 42 iter 190, loss: 2.076, accuracy: 0.855\n",
      "epoch 42 iter 200, loss: 2.173, accuracy: 0.848\n",
      "epoch 42 iter 210, loss: 2.074, accuracy: 0.852\n",
      "epoch 42 iter 220, loss: 2.079, accuracy: 0.854\n",
      "epoch 42 iter 230, loss: 2.050, accuracy: 0.851\n",
      "epoch 42 iter 240, loss: 1.887, accuracy: 0.863\n",
      "epoch 42 iter 250, loss: 2.021, accuracy: 0.854\n",
      "epoch 42 iter 260, loss: 1.969, accuracy: 0.855\n",
      "epoch 42 iter 270, loss: 2.257, accuracy: 0.845\n",
      "epoch 42 iter 280, loss: 1.999, accuracy: 0.845\n",
      "epoch 43 iter 0, loss: 2.115, accuracy: 0.850\n",
      "epoch 43 iter 10, loss: 2.139, accuracy: 0.850\n",
      "epoch 43 iter 20, loss: 2.046, accuracy: 0.851\n",
      "epoch 43 iter 30, loss: 2.237, accuracy: 0.851\n",
      "epoch 43 iter 40, loss: 2.072, accuracy: 0.847\n",
      "epoch 43 iter 50, loss: 2.089, accuracy: 0.845\n",
      "epoch 43 iter 60, loss: 2.022, accuracy: 0.853\n",
      "epoch 43 iter 70, loss: 2.161, accuracy: 0.848\n",
      "epoch 43 iter 80, loss: 2.067, accuracy: 0.860\n",
      "epoch 43 iter 90, loss: 1.982, accuracy: 0.858\n",
      "epoch 43 iter 100, loss: 2.245, accuracy: 0.844\n",
      "epoch 43 iter 110, loss: 2.253, accuracy: 0.859\n",
      "epoch 43 iter 120, loss: 2.137, accuracy: 0.857\n",
      "epoch 43 iter 130, loss: 2.072, accuracy: 0.857\n",
      "epoch 43 iter 140, loss: 2.101, accuracy: 0.853\n",
      "epoch 43 iter 150, loss: 2.394, accuracy: 0.847\n",
      "epoch 43 iter 160, loss: 2.079, accuracy: 0.855\n",
      "epoch 43 iter 170, loss: 2.061, accuracy: 0.843\n",
      "epoch 43 iter 180, loss: 1.897, accuracy: 0.855\n",
      "epoch 43 iter 190, loss: 2.112, accuracy: 0.849\n",
      "epoch 43 iter 200, loss: 2.154, accuracy: 0.850\n",
      "epoch 43 iter 210, loss: 2.077, accuracy: 0.857\n",
      "epoch 43 iter 220, loss: 2.064, accuracy: 0.859\n",
      "epoch 43 iter 230, loss: 2.099, accuracy: 0.856\n",
      "epoch 43 iter 240, loss: 1.987, accuracy: 0.865\n",
      "epoch 43 iter 250, loss: 2.090, accuracy: 0.856\n",
      "epoch 43 iter 260, loss: 1.934, accuracy: 0.850\n",
      "epoch 43 iter 270, loss: 2.214, accuracy: 0.844\n",
      "epoch 43 iter 280, loss: 2.049, accuracy: 0.858\n",
      "epoch 44 iter 0, loss: 2.135, accuracy: 0.858\n",
      "epoch 44 iter 10, loss: 2.301, accuracy: 0.855\n",
      "epoch 44 iter 20, loss: 2.210, accuracy: 0.847\n",
      "epoch 44 iter 30, loss: 2.427, accuracy: 0.849\n",
      "epoch 44 iter 40, loss: 2.167, accuracy: 0.848\n",
      "epoch 44 iter 50, loss: 2.137, accuracy: 0.854\n",
      "epoch 44 iter 60, loss: 2.188, accuracy: 0.852\n",
      "epoch 44 iter 70, loss: 2.133, accuracy: 0.852\n",
      "epoch 44 iter 80, loss: 2.195, accuracy: 0.857\n",
      "epoch 44 iter 90, loss: 2.101, accuracy: 0.854\n",
      "epoch 44 iter 100, loss: 2.325, accuracy: 0.844\n",
      "epoch 44 iter 110, loss: 2.148, accuracy: 0.861\n",
      "epoch 44 iter 120, loss: 2.193, accuracy: 0.859\n",
      "epoch 44 iter 130, loss: 2.134, accuracy: 0.863\n",
      "epoch 44 iter 140, loss: 2.223, accuracy: 0.857\n",
      "epoch 44 iter 150, loss: 2.404, accuracy: 0.850\n",
      "epoch 44 iter 160, loss: 2.263, accuracy: 0.861\n",
      "epoch 44 iter 170, loss: 2.311, accuracy: 0.849\n",
      "epoch 44 iter 180, loss: 2.092, accuracy: 0.863\n",
      "epoch 44 iter 190, loss: 2.090, accuracy: 0.860\n",
      "epoch 44 iter 200, loss: 2.160, accuracy: 0.854\n",
      "epoch 44 iter 210, loss: 2.064, accuracy: 0.860\n",
      "epoch 44 iter 220, loss: 2.173, accuracy: 0.855\n",
      "epoch 44 iter 230, loss: 2.111, accuracy: 0.854\n",
      "epoch 44 iter 240, loss: 2.150, accuracy: 0.864\n",
      "epoch 44 iter 250, loss: 2.042, accuracy: 0.860\n",
      "epoch 44 iter 260, loss: 1.987, accuracy: 0.864\n",
      "epoch 44 iter 270, loss: 2.192, accuracy: 0.852\n",
      "epoch 44 iter 280, loss: 2.060, accuracy: 0.857\n",
      "epoch 45 iter 0, loss: 2.091, accuracy: 0.861\n",
      "epoch 45 iter 10, loss: 2.385, accuracy: 0.845\n",
      "epoch 45 iter 20, loss: 2.364, accuracy: 0.842\n",
      "epoch 45 iter 30, loss: 2.436, accuracy: 0.844\n",
      "epoch 45 iter 40, loss: 2.067, accuracy: 0.852\n",
      "epoch 45 iter 50, loss: 2.195, accuracy: 0.853\n",
      "epoch 45 iter 60, loss: 2.240, accuracy: 0.849\n",
      "epoch 45 iter 70, loss: 2.164, accuracy: 0.850\n",
      "epoch 45 iter 80, loss: 2.255, accuracy: 0.856\n",
      "epoch 45 iter 90, loss: 2.304, accuracy: 0.852\n",
      "epoch 45 iter 100, loss: 2.252, accuracy: 0.851\n",
      "epoch 45 iter 110, loss: 2.262, accuracy: 0.853\n",
      "epoch 45 iter 120, loss: 2.250, accuracy: 0.857\n",
      "epoch 45 iter 130, loss: 2.158, accuracy: 0.854\n",
      "epoch 45 iter 140, loss: 2.472, accuracy: 0.846\n",
      "epoch 45 iter 150, loss: 2.467, accuracy: 0.854\n",
      "epoch 45 iter 160, loss: 2.275, accuracy: 0.851\n",
      "epoch 45 iter 170, loss: 2.324, accuracy: 0.845\n",
      "epoch 45 iter 180, loss: 2.180, accuracy: 0.853\n",
      "epoch 45 iter 190, loss: 2.166, accuracy: 0.858\n",
      "epoch 45 iter 200, loss: 2.143, accuracy: 0.857\n",
      "epoch 45 iter 210, loss: 2.230, accuracy: 0.859\n",
      "epoch 45 iter 220, loss: 2.238, accuracy: 0.856\n",
      "epoch 45 iter 230, loss: 2.342, accuracy: 0.852\n",
      "epoch 45 iter 240, loss: 2.198, accuracy: 0.859\n",
      "epoch 45 iter 250, loss: 2.226, accuracy: 0.852\n",
      "epoch 45 iter 260, loss: 2.191, accuracy: 0.855\n",
      "epoch 45 iter 270, loss: 2.511, accuracy: 0.845\n",
      "epoch 45 iter 280, loss: 2.220, accuracy: 0.856\n",
      "epoch 46 iter 0, loss: 2.286, accuracy: 0.847\n",
      "epoch 46 iter 10, loss: 2.762, accuracy: 0.840\n",
      "epoch 46 iter 20, loss: 2.378, accuracy: 0.856\n",
      "epoch 46 iter 30, loss: 2.529, accuracy: 0.840\n",
      "epoch 46 iter 40, loss: 2.448, accuracy: 0.841\n",
      "epoch 46 iter 50, loss: 2.503, accuracy: 0.847\n",
      "epoch 46 iter 60, loss: 2.376, accuracy: 0.852\n",
      "epoch 46 iter 70, loss: 2.288, accuracy: 0.844\n",
      "epoch 46 iter 80, loss: 2.327, accuracy: 0.849\n",
      "epoch 46 iter 90, loss: 2.288, accuracy: 0.852\n",
      "epoch 46 iter 100, loss: 2.558, accuracy: 0.839\n",
      "epoch 46 iter 110, loss: 2.334, accuracy: 0.850\n",
      "epoch 46 iter 120, loss: 2.404, accuracy: 0.854\n",
      "epoch 46 iter 130, loss: 2.357, accuracy: 0.854\n",
      "epoch 46 iter 140, loss: 2.254, accuracy: 0.852\n",
      "epoch 46 iter 150, loss: 2.522, accuracy: 0.848\n",
      "epoch 46 iter 160, loss: 2.535, accuracy: 0.854\n",
      "epoch 46 iter 170, loss: 2.440, accuracy: 0.852\n",
      "epoch 46 iter 180, loss: 2.393, accuracy: 0.855\n",
      "epoch 46 iter 190, loss: 2.302, accuracy: 0.853\n",
      "epoch 46 iter 200, loss: 2.355, accuracy: 0.851\n",
      "epoch 46 iter 210, loss: 2.254, accuracy: 0.861\n",
      "epoch 46 iter 220, loss: 2.388, accuracy: 0.847\n",
      "epoch 46 iter 230, loss: 2.336, accuracy: 0.854\n",
      "epoch 46 iter 240, loss: 2.322, accuracy: 0.859\n",
      "epoch 46 iter 250, loss: 2.306, accuracy: 0.857\n",
      "epoch 46 iter 260, loss: 2.216, accuracy: 0.857\n",
      "epoch 46 iter 270, loss: 2.357, accuracy: 0.852\n",
      "epoch 46 iter 280, loss: 2.189, accuracy: 0.859\n",
      "epoch 47 iter 0, loss: 2.162, accuracy: 0.860\n",
      "epoch 47 iter 10, loss: 2.432, accuracy: 0.849\n",
      "epoch 47 iter 20, loss: 2.340, accuracy: 0.838\n",
      "epoch 47 iter 30, loss: 2.701, accuracy: 0.838\n",
      "epoch 47 iter 40, loss: 2.390, accuracy: 0.846\n",
      "epoch 47 iter 50, loss: 2.472, accuracy: 0.854\n",
      "epoch 47 iter 60, loss: 2.384, accuracy: 0.852\n",
      "epoch 47 iter 70, loss: 2.409, accuracy: 0.852\n",
      "epoch 47 iter 80, loss: 2.319, accuracy: 0.856\n",
      "epoch 47 iter 90, loss: 2.477, accuracy: 0.851\n",
      "epoch 47 iter 100, loss: 2.433, accuracy: 0.858\n",
      "epoch 47 iter 110, loss: 2.418, accuracy: 0.852\n",
      "epoch 47 iter 120, loss: 2.321, accuracy: 0.856\n",
      "epoch 47 iter 130, loss: 2.325, accuracy: 0.860\n",
      "epoch 47 iter 140, loss: 2.330, accuracy: 0.857\n",
      "epoch 47 iter 150, loss: 2.502, accuracy: 0.856\n",
      "epoch 47 iter 160, loss: 2.518, accuracy: 0.852\n",
      "epoch 47 iter 170, loss: 2.525, accuracy: 0.850\n",
      "epoch 47 iter 180, loss: 2.345, accuracy: 0.856\n",
      "epoch 47 iter 190, loss: 2.254, accuracy: 0.860\n",
      "epoch 47 iter 200, loss: 2.371, accuracy: 0.852\n",
      "epoch 47 iter 210, loss: 2.300, accuracy: 0.860\n",
      "epoch 47 iter 220, loss: 2.391, accuracy: 0.856\n",
      "epoch 47 iter 230, loss: 2.435, accuracy: 0.855\n",
      "epoch 47 iter 240, loss: 2.330, accuracy: 0.858\n",
      "epoch 47 iter 250, loss: 2.377, accuracy: 0.856\n",
      "epoch 47 iter 260, loss: 2.354, accuracy: 0.860\n",
      "epoch 47 iter 270, loss: 2.525, accuracy: 0.853\n",
      "epoch 47 iter 280, loss: 2.410, accuracy: 0.864\n",
      "epoch 48 iter 0, loss: 2.438, accuracy: 0.851\n",
      "epoch 48 iter 10, loss: 2.545, accuracy: 0.840\n",
      "epoch 48 iter 20, loss: 2.317, accuracy: 0.852\n",
      "epoch 48 iter 30, loss: 2.770, accuracy: 0.841\n",
      "epoch 48 iter 40, loss: 2.512, accuracy: 0.847\n",
      "epoch 48 iter 50, loss: 2.456, accuracy: 0.848\n",
      "epoch 48 iter 60, loss: 2.434, accuracy: 0.850\n",
      "epoch 48 iter 70, loss: 2.267, accuracy: 0.845\n",
      "epoch 48 iter 80, loss: 2.458, accuracy: 0.857\n",
      "epoch 48 iter 90, loss: 2.434, accuracy: 0.855\n",
      "epoch 48 iter 100, loss: 2.269, accuracy: 0.858\n",
      "epoch 48 iter 110, loss: 2.377, accuracy: 0.857\n",
      "epoch 48 iter 120, loss: 2.353, accuracy: 0.857\n",
      "epoch 48 iter 130, loss: 2.296, accuracy: 0.855\n",
      "epoch 48 iter 140, loss: 2.308, accuracy: 0.858\n",
      "epoch 48 iter 150, loss: 2.416, accuracy: 0.858\n",
      "epoch 48 iter 160, loss: 2.425, accuracy: 0.861\n",
      "epoch 48 iter 170, loss: 2.418, accuracy: 0.857\n",
      "epoch 48 iter 180, loss: 2.530, accuracy: 0.847\n",
      "epoch 48 iter 190, loss: 2.330, accuracy: 0.855\n",
      "epoch 48 iter 200, loss: 2.410, accuracy: 0.855\n",
      "epoch 48 iter 210, loss: 2.305, accuracy: 0.861\n",
      "epoch 48 iter 220, loss: 2.353, accuracy: 0.850\n",
      "epoch 48 iter 230, loss: 2.431, accuracy: 0.857\n",
      "epoch 48 iter 240, loss: 2.308, accuracy: 0.859\n",
      "epoch 48 iter 250, loss: 2.487, accuracy: 0.852\n",
      "epoch 48 iter 260, loss: 2.236, accuracy: 0.862\n",
      "epoch 48 iter 270, loss: 2.490, accuracy: 0.855\n",
      "epoch 48 iter 280, loss: 2.395, accuracy: 0.861\n",
      "epoch 49 iter 0, loss: 2.334, accuracy: 0.859\n",
      "epoch 49 iter 10, loss: 2.628, accuracy: 0.845\n",
      "epoch 49 iter 20, loss: 2.280, accuracy: 0.845\n",
      "epoch 49 iter 30, loss: 2.695, accuracy: 0.846\n",
      "epoch 49 iter 40, loss: 2.546, accuracy: 0.843\n",
      "epoch 49 iter 50, loss: 2.591, accuracy: 0.842\n",
      "epoch 49 iter 60, loss: 2.498, accuracy: 0.854\n",
      "epoch 49 iter 70, loss: 2.349, accuracy: 0.843\n",
      "epoch 49 iter 80, loss: 2.442, accuracy: 0.846\n",
      "epoch 49 iter 90, loss: 2.485, accuracy: 0.847\n",
      "epoch 49 iter 100, loss: 2.672, accuracy: 0.845\n",
      "epoch 49 iter 110, loss: 2.431, accuracy: 0.849\n",
      "epoch 49 iter 120, loss: 2.453, accuracy: 0.853\n",
      "epoch 49 iter 130, loss: 2.345, accuracy: 0.853\n",
      "epoch 49 iter 140, loss: 2.565, accuracy: 0.848\n",
      "epoch 49 iter 150, loss: 2.667, accuracy: 0.849\n",
      "epoch 49 iter 160, loss: 2.504, accuracy: 0.857\n",
      "epoch 49 iter 170, loss: 2.458, accuracy: 0.855\n",
      "epoch 49 iter 180, loss: 2.502, accuracy: 0.854\n",
      "epoch 49 iter 190, loss: 2.312, accuracy: 0.865\n",
      "epoch 49 iter 200, loss: 2.570, accuracy: 0.845\n",
      "epoch 49 iter 210, loss: 2.342, accuracy: 0.858\n",
      "epoch 49 iter 220, loss: 2.285, accuracy: 0.860\n",
      "epoch 49 iter 230, loss: 2.399, accuracy: 0.854\n",
      "epoch 49 iter 240, loss: 2.486, accuracy: 0.857\n",
      "epoch 49 iter 250, loss: 2.529, accuracy: 0.850\n",
      "epoch 49 iter 260, loss: 2.353, accuracy: 0.855\n",
      "epoch 49 iter 270, loss: 2.422, accuracy: 0.855\n",
      "epoch 49 iter 280, loss: 2.329, accuracy: 0.862\n"
     ]
    }
   ],
   "source": [
    "def cnn_modification(x_):\n",
    "\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv1')\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2, name = 'pool1')  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv2')\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=3, name = 'pool2')  # convolution stride\n",
    "        \n",
    "    pool_flat = tf.contrib.layers.flatten(pool2, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "\n",
    "modified_model_dict = apply_classification_loss(cnn_modification)\n",
    "train_model(modified_model_dict, dataset_generators, epoch_n=50, print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Saving and Reloading Model Weights\n",
    "(25 points)\n",
    "\n",
    "In this section you learn to save the weights of a trained model, and to load the weights of a saved model. This is really useful when we would like to load an already trained model in order to continue training or to fine-tune it. Often times we save snapshots of the trained model as training progresses in case the training is interrupted, or in case we would like to fall back to an earlier model, this is called snapshot saving.\n",
    "\n",
    "### Q2.1 Defining another network\n",
    "Define a network with a slightly different structure in `def cnn_expanded(x_)` below. `cnn_expanded` is an expanded version of `cnn_model`. \n",
    "It should have: \n",
    "- a different size of kernel for the last convolutional layer, \n",
    "- followed by one additional convolutional layer, and \n",
    "- followed by one additional pooling layer.\n",
    "\n",
    "The last fully-connected layer will stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the new model (see cnn_map(x_) above for an example)\n",
    "def cnn_expanded(x_):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            filters=32,  # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv1')\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2, name = 'pool1')  # convolution stride\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[10, 10],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv2')\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2, name = 'pool1')  # convolution stride\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "            inputs=pool2,\n",
    "            filters=32, # number of filters\n",
    "            kernel_size=[5, 5],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv3')\n",
    "    \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2, name = 'pool3')  # convolution stride\n",
    "   \n",
    "    \n",
    "    pool_flat = tf.contrib.layers.flatten(pool3, scope='pool2flat')\n",
    "    dense = tf.layers.dense(inputs=pool_flat, units=500, activation=tf.nn.relu)\n",
    "    logits = tf.layers.dense(inputs=dense, units=10)\n",
    "    return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2 Saving and Loading Weights\n",
    "`new_train_model()` below has two additional parameters `save_model=False, load_model=False` than `train_model` defined previously. Modify `new_train_model()` such that it would \n",
    "- save weights after the training is complete if `save_model` is `True`, and\n",
    "- load weights on start-up before training if `load_model` is `True`.\n",
    "\n",
    "*Hint:*  `tf.train.Saver()`.\n",
    "\n",
    "Note: if you are unable to load weights into `cnn_expanded` network, use `cnn_map` in order to continue the assingment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "  \n",
    "In cnn_expanded I changed the kernel_size =  [10, 10] for the second convolutional layer (conv2), added one additional convolutional layer, and an additional pooling layer. The architecture is shown above.   \n",
    "  \n",
    "For the new_train_model, if save_model=True I save the weight of the firts convolutional layer (conv1) in my-model.meta file. If load_model=True I load the conv1 weights, while randomly initializing the other layer weights. \n",
    "\n",
    "As shwon below: \n",
    "\n",
    "If load_model=False:  \n",
    "Accuracy(after 10 epochs): 0.809  \n",
    "Accuracy(after 100 epochs): 0.844\n",
    "\n",
    "If load_model=True:\n",
    "Accuracy(after 10 epochs): 0.830\n",
    "\n",
    "This shows that loading the saved weights makes the results converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Modify this:\n",
    "def new_train_model(model_dict, dataset_generators, epoch_n, print_every,\n",
    "                    save_model=False, load_model=False):\n",
    "    \n",
    "    if load_model == False:\n",
    "        with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for epoch_i in range(epoch_n):\n",
    "                for iter_i, data_batch in enumerate(dataset_generators['train']):\n",
    "                    train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
    "                    sess.run(model_dict['train_op'], feed_dict=train_feed_dict)\n",
    "\n",
    "                    if iter_i % print_every == 0:\n",
    "                        collect_arr = []\n",
    "                        for test_batch in dataset_generators['test']:\n",
    "                            test_feed_dict = dict(zip(model_dict['inputs'], test_batch))\n",
    "                            to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
    "                            collect_arr.append(sess.run(to_compute, test_feed_dict))\n",
    "                        averages = np.mean(collect_arr, axis=0)\n",
    "                        fmt = (epoch_i, iter_i, ) + tuple(averages)\n",
    "                        print('iteration {:d} {:d}\\t loss: {:.3f}, '\n",
    "                              'accuracy: {:.3f}'.format(*fmt))\n",
    "            if save_model == True:\n",
    "                saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'conv1'))\n",
    "                save_path = saver.save(sess, 'my-model')\n",
    "                print(\"Model saved in file: %s\" % save_path)\n",
    "    else:\n",
    "        print('True')\n",
    "        with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            new_saver = tf.train.import_meta_graph('my-model.meta')\n",
    "            new_saver.restore(sess, tf.train.latest_checkpoint('./'))\n",
    "            \n",
    "            for epoch_i in range(epoch_n):\n",
    "                for iter_i, data_batch in enumerate(dataset_generators['train']):\n",
    "                    train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
    "                    sess.run(model_dict['train_op'], feed_dict=train_feed_dict)\n",
    "\n",
    "                    if iter_i % print_every == 0:\n",
    "                        collect_arr = []\n",
    "                        for test_batch in dataset_generators['test']:\n",
    "                            test_feed_dict = dict(zip(model_dict['inputs'], test_batch))\n",
    "                            to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
    "                            collect_arr.append(sess.run(to_compute, test_feed_dict))\n",
    "                        averages = np.mean(collect_arr, axis=0)\n",
    "                        fmt = (epoch_i, iter_i, ) + tuple(averages)\n",
    "                        print('iteration {:d} {:d}\\t loss: {:.3f}, '\n",
    "                              'accuracy: {:.3f}'.format(*fmt))\n",
    "        \n",
    " \n",
    "\n",
    "    \n",
    "\n",
    "def test_saving():\n",
    "    model_dict = apply_classification_loss(cnn_map)\n",
    "    new_train_model(model_dict, dataset_generators, epoch_n=100, print_every=10, save_model=True)\n",
    "    cnn_expanded_dict = apply_classification_loss(cnn_expanded)\n",
    "    new_train_model(cnn_expanded_dict, dataset_generators, epoch_n=10, print_every=10, load_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 0\t loss: 95.395, accuracy: 0.196\n",
      "iteration 0 10\t loss: 2.372, accuracy: 0.098\n",
      "iteration 0 20\t loss: 2.267, accuracy: 0.195\n",
      "iteration 0 30\t loss: 2.248, accuracy: 0.196\n",
      "iteration 0 40\t loss: 2.244, accuracy: 0.196\n",
      "iteration 0 50\t loss: 2.242, accuracy: 0.196\n",
      "iteration 0 60\t loss: 2.250, accuracy: 0.195\n",
      "iteration 0 70\t loss: 2.247, accuracy: 0.195\n",
      "iteration 0 80\t loss: 2.241, accuracy: 0.196\n",
      "iteration 0 90\t loss: 2.236, accuracy: 0.196\n",
      "iteration 0 100\t loss: 2.232, accuracy: 0.196\n",
      "iteration 0 110\t loss: 2.233, accuracy: 0.196\n",
      "iteration 0 120\t loss: 2.230, accuracy: 0.196\n",
      "iteration 0 130\t loss: 2.232, accuracy: 0.196\n",
      "iteration 0 140\t loss: 2.230, accuracy: 0.196\n",
      "iteration 0 150\t loss: 2.228, accuracy: 0.196\n",
      "iteration 0 160\t loss: 2.226, accuracy: 0.196\n",
      "iteration 0 170\t loss: 2.225, accuracy: 0.196\n",
      "iteration 0 180\t loss: 2.225, accuracy: 0.196\n",
      "iteration 0 190\t loss: 2.225, accuracy: 0.196\n",
      "iteration 0 200\t loss: 2.224, accuracy: 0.196\n",
      "iteration 0 210\t loss: 2.227, accuracy: 0.196\n",
      "iteration 0 220\t loss: 2.223, accuracy: 0.196\n",
      "iteration 0 230\t loss: 2.223, accuracy: 0.196\n",
      "iteration 0 240\t loss: 2.223, accuracy: 0.196\n",
      "iteration 0 250\t loss: 2.224, accuracy: 0.196\n",
      "iteration 0 260\t loss: 2.224, accuracy: 0.196\n",
      "iteration 0 270\t loss: 2.223, accuracy: 0.196\n",
      "iteration 0 280\t loss: 2.226, accuracy: 0.196\n",
      "iteration 1 0\t loss: 2.232, accuracy: 0.196\n",
      "iteration 1 10\t loss: 2.227, accuracy: 0.196\n",
      "iteration 1 20\t loss: 2.224, accuracy: 0.196\n",
      "iteration 1 30\t loss: 2.222, accuracy: 0.196\n",
      "iteration 1 40\t loss: 2.219, accuracy: 0.196\n",
      "iteration 1 50\t loss: 2.221, accuracy: 0.196\n",
      "iteration 1 60\t loss: 2.224, accuracy: 0.196\n",
      "iteration 1 70\t loss: 2.224, accuracy: 0.196\n",
      "iteration 1 80\t loss: 2.225, accuracy: 0.196\n",
      "iteration 1 90\t loss: 2.222, accuracy: 0.196\n",
      "iteration 1 100\t loss: 2.223, accuracy: 0.196\n",
      "iteration 1 110\t loss: 2.222, accuracy: 0.196\n",
      "iteration 1 120\t loss: 2.221, accuracy: 0.195\n",
      "iteration 1 130\t loss: 2.224, accuracy: 0.196\n",
      "iteration 1 140\t loss: 2.221, accuracy: 0.196\n",
      "iteration 1 150\t loss: 2.223, accuracy: 0.196\n",
      "iteration 1 160\t loss: 2.224, accuracy: 0.196\n",
      "iteration 1 170\t loss: 2.222, accuracy: 0.196\n",
      "iteration 1 180\t loss: 2.222, accuracy: 0.196\n",
      "iteration 1 190\t loss: 2.220, accuracy: 0.196\n",
      "iteration 1 200\t loss: 2.218, accuracy: 0.196\n",
      "iteration 1 210\t loss: 2.219, accuracy: 0.196\n",
      "iteration 1 220\t loss: 2.225, accuracy: 0.196\n",
      "iteration 1 230\t loss: 2.223, accuracy: 0.196\n",
      "iteration 1 240\t loss: 2.220, accuracy: 0.196\n",
      "iteration 1 250\t loss: 2.219, accuracy: 0.196\n",
      "iteration 1 260\t loss: 2.219, accuracy: 0.196\n",
      "iteration 1 270\t loss: 2.219, accuracy: 0.196\n",
      "iteration 1 280\t loss: 2.218, accuracy: 0.196\n",
      "iteration 2 0\t loss: 2.221, accuracy: 0.196\n",
      "iteration 2 10\t loss: 2.219, accuracy: 0.196\n",
      "iteration 2 20\t loss: 2.223, accuracy: 0.196\n",
      "iteration 2 30\t loss: 2.219, accuracy: 0.196\n",
      "iteration 2 40\t loss: 2.218, accuracy: 0.196\n",
      "iteration 2 50\t loss: 2.220, accuracy: 0.196\n",
      "iteration 2 60\t loss: 2.226, accuracy: 0.196\n",
      "iteration 2 70\t loss: 2.223, accuracy: 0.196\n",
      "iteration 2 80\t loss: 2.221, accuracy: 0.196\n",
      "iteration 2 90\t loss: 2.218, accuracy: 0.196\n",
      "iteration 2 100\t loss: 2.218, accuracy: 0.196\n",
      "iteration 2 110\t loss: 2.219, accuracy: 0.196\n",
      "iteration 2 120\t loss: 2.215, accuracy: 0.196\n",
      "iteration 2 130\t loss: 2.214, accuracy: 0.196\n",
      "iteration 2 140\t loss: 2.218, accuracy: 0.196\n",
      "iteration 2 150\t loss: 2.228, accuracy: 0.196\n",
      "iteration 2 160\t loss: 2.225, accuracy: 0.196\n",
      "iteration 2 170\t loss: 2.229, accuracy: 0.191\n",
      "iteration 2 180\t loss: 2.217, accuracy: 0.196\n",
      "iteration 2 190\t loss: 2.223, accuracy: 0.196\n",
      "iteration 2 200\t loss: 2.222, accuracy: 0.196\n",
      "iteration 2 210\t loss: 2.223, accuracy: 0.196\n",
      "iteration 2 220\t loss: 2.218, accuracy: 0.196\n",
      "iteration 2 230\t loss: 2.217, accuracy: 0.196\n",
      "iteration 2 240\t loss: 2.218, accuracy: 0.196\n",
      "iteration 2 250\t loss: 2.219, accuracy: 0.196\n",
      "iteration 2 260\t loss: 2.216, accuracy: 0.196\n",
      "iteration 2 270\t loss: 2.217, accuracy: 0.196\n",
      "iteration 2 280\t loss: 2.216, accuracy: 0.196\n",
      "iteration 3 0\t loss: 2.219, accuracy: 0.196\n",
      "iteration 3 10\t loss: 2.219, accuracy: 0.196\n",
      "iteration 3 20\t loss: 2.218, accuracy: 0.196\n",
      "iteration 3 30\t loss: 2.219, accuracy: 0.196\n",
      "iteration 3 40\t loss: 2.217, accuracy: 0.196\n",
      "iteration 3 50\t loss: 2.217, accuracy: 0.196\n",
      "iteration 3 60\t loss: 2.219, accuracy: 0.196\n",
      "iteration 3 70\t loss: 2.220, accuracy: 0.196\n",
      "iteration 3 80\t loss: 2.219, accuracy: 0.196\n",
      "iteration 3 90\t loss: 2.216, accuracy: 0.196\n",
      "iteration 3 100\t loss: 2.214, accuracy: 0.196\n",
      "iteration 3 110\t loss: 2.222, accuracy: 0.196\n",
      "iteration 3 120\t loss: 2.222, accuracy: 0.196\n",
      "iteration 3 130\t loss: 2.234, accuracy: 0.196\n",
      "iteration 3 140\t loss: 2.213, accuracy: 0.196\n",
      "iteration 3 150\t loss: 2.227, accuracy: 0.196\n",
      "iteration 3 160\t loss: 2.216, accuracy: 0.196\n",
      "iteration 3 170\t loss: 2.217, accuracy: 0.196\n",
      "iteration 3 180\t loss: 2.219, accuracy: 0.196\n",
      "iteration 3 190\t loss: 2.224, accuracy: 0.196\n",
      "iteration 3 200\t loss: 2.220, accuracy: 0.196\n",
      "iteration 3 210\t loss: 2.223, accuracy: 0.196\n",
      "iteration 3 220\t loss: 2.223, accuracy: 0.196\n",
      "iteration 3 230\t loss: 2.227, accuracy: 0.196\n",
      "iteration 3 240\t loss: 2.215, accuracy: 0.196\n",
      "iteration 3 250\t loss: 2.226, accuracy: 0.196\n",
      "iteration 3 260\t loss: 2.226, accuracy: 0.196\n",
      "iteration 3 270\t loss: 2.225, accuracy: 0.196\n",
      "iteration 3 280\t loss: 2.226, accuracy: 0.195\n",
      "iteration 4 0\t loss: 2.224, accuracy: 0.196\n",
      "iteration 4 10\t loss: 2.225, accuracy: 0.196\n",
      "iteration 4 20\t loss: 2.225, accuracy: 0.196\n",
      "iteration 4 30\t loss: 2.225, accuracy: 0.196\n",
      "iteration 4 40\t loss: 2.224, accuracy: 0.196\n",
      "iteration 4 50\t loss: 2.223, accuracy: 0.196\n",
      "iteration 4 60\t loss: 2.224, accuracy: 0.196\n",
      "iteration 4 70\t loss: 2.222, accuracy: 0.196\n",
      "iteration 4 80\t loss: 2.224, accuracy: 0.196\n",
      "iteration 4 90\t loss: 2.222, accuracy: 0.196\n",
      "iteration 4 100\t loss: 2.223, accuracy: 0.196\n",
      "iteration 4 110\t loss: 2.226, accuracy: 0.196\n",
      "iteration 4 120\t loss: 2.226, accuracy: 0.196\n",
      "iteration 4 130\t loss: 2.218, accuracy: 0.196\n",
      "iteration 4 140\t loss: 2.220, accuracy: 0.196\n",
      "iteration 4 150\t loss: 2.225, accuracy: 0.195\n",
      "iteration 4 160\t loss: 2.216, accuracy: 0.196\n",
      "iteration 4 170\t loss: 2.221, accuracy: 0.196\n",
      "iteration 4 180\t loss: 2.231, accuracy: 0.196\n",
      "iteration 4 190\t loss: 2.229, accuracy: 0.196\n",
      "iteration 4 200\t loss: 2.225, accuracy: 0.196\n",
      "iteration 4 210\t loss: 2.224, accuracy: 0.196\n",
      "iteration 4 220\t loss: 2.224, accuracy: 0.196\n",
      "iteration 4 230\t loss: 2.223, accuracy: 0.196\n",
      "iteration 4 240\t loss: 2.223, accuracy: 0.196\n",
      "iteration 4 250\t loss: 2.223, accuracy: 0.196\n",
      "iteration 4 260\t loss: 2.222, accuracy: 0.196\n",
      "iteration 4 270\t loss: 2.221, accuracy: 0.196\n",
      "iteration 4 280\t loss: 2.220, accuracy: 0.196\n",
      "iteration 5 0\t loss: 2.226, accuracy: 0.196\n",
      "iteration 5 10\t loss: 2.226, accuracy: 0.196\n",
      "iteration 5 20\t loss: 2.226, accuracy: 0.196\n",
      "iteration 5 30\t loss: 2.225, accuracy: 0.196\n",
      "iteration 5 40\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 50\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 60\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 70\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 80\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 90\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 100\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 110\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 120\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 130\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 140\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 150\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 160\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 170\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 180\t loss: 2.225, accuracy: 0.196\n",
      "iteration 5 190\t loss: 2.226, accuracy: 0.196\n",
      "iteration 5 200\t loss: 2.225, accuracy: 0.196\n",
      "iteration 5 210\t loss: 2.224, accuracy: 0.196\n",
      "iteration 5 220\t loss: 2.223, accuracy: 0.196\n",
      "iteration 5 230\t loss: 2.220, accuracy: 0.196\n",
      "iteration 5 240\t loss: 2.223, accuracy: 0.195\n",
      "iteration 5 250\t loss: 2.224, accuracy: 0.195\n",
      "iteration 5 260\t loss: 2.223, accuracy: 0.194\n",
      "iteration 5 270\t loss: 2.224, accuracy: 0.192\n",
      "iteration 5 280\t loss: 2.222, accuracy: 0.196\n",
      "iteration 6 0\t loss: 2.219, accuracy: 0.196\n",
      "iteration 6 10\t loss: 2.221, accuracy: 0.196\n",
      "iteration 6 20\t loss: 2.224, accuracy: 0.195\n",
      "iteration 6 30\t loss: 2.223, accuracy: 0.196\n",
      "iteration 6 40\t loss: 2.216, accuracy: 0.197\n",
      "iteration 6 50\t loss: 2.220, accuracy: 0.198\n",
      "iteration 6 60\t loss: 2.218, accuracy: 0.198\n",
      "iteration 6 70\t loss: 2.214, accuracy: 0.200\n",
      "iteration 6 80\t loss: 2.213, accuracy: 0.202\n",
      "iteration 6 90\t loss: 2.210, accuracy: 0.203\n",
      "iteration 6 100\t loss: 2.210, accuracy: 0.205\n",
      "iteration 6 110\t loss: 2.212, accuracy: 0.204\n",
      "iteration 6 120\t loss: 2.211, accuracy: 0.204\n",
      "iteration 6 130\t loss: 2.226, accuracy: 0.204\n",
      "iteration 6 140\t loss: 2.217, accuracy: 0.208\n",
      "iteration 6 150\t loss: 2.223, accuracy: 0.213\n",
      "iteration 6 160\t loss: 2.202, accuracy: 0.217\n",
      "iteration 6 170\t loss: 2.200, accuracy: 0.218\n",
      "iteration 6 180\t loss: 2.211, accuracy: 0.211\n",
      "iteration 6 190\t loss: 2.182, accuracy: 0.223\n",
      "iteration 6 200\t loss: 2.177, accuracy: 0.229\n",
      "iteration 6 210\t loss: 2.174, accuracy: 0.229\n",
      "iteration 6 220\t loss: 2.175, accuracy: 0.237\n",
      "iteration 6 230\t loss: 2.180, accuracy: 0.234\n",
      "iteration 6 240\t loss: 2.163, accuracy: 0.232\n",
      "iteration 6 250\t loss: 2.150, accuracy: 0.242\n",
      "iteration 6 260\t loss: 2.115, accuracy: 0.253\n",
      "iteration 6 270\t loss: 2.141, accuracy: 0.234\n",
      "iteration 6 280\t loss: 2.094, accuracy: 0.256\n",
      "iteration 7 0\t loss: 2.107, accuracy: 0.256\n",
      "iteration 7 10\t loss: 2.114, accuracy: 0.240\n",
      "iteration 7 20\t loss: 2.108, accuracy: 0.257\n",
      "iteration 7 30\t loss: 2.031, accuracy: 0.314\n",
      "iteration 7 40\t loss: 1.892, accuracy: 0.358\n",
      "iteration 7 50\t loss: 1.786, accuracy: 0.390\n",
      "iteration 7 60\t loss: 1.643, accuracy: 0.458\n",
      "iteration 7 70\t loss: 1.514, accuracy: 0.499\n",
      "iteration 7 80\t loss: 1.403, accuracy: 0.551\n",
      "iteration 7 90\t loss: 1.334, accuracy: 0.572\n",
      "iteration 7 100\t loss: 1.289, accuracy: 0.589\n",
      "iteration 7 110\t loss: 1.301, accuracy: 0.588\n",
      "iteration 7 120\t loss: 1.203, accuracy: 0.620\n",
      "iteration 7 130\t loss: 1.208, accuracy: 0.621\n",
      "iteration 7 140\t loss: 1.148, accuracy: 0.643\n",
      "iteration 7 150\t loss: 1.149, accuracy: 0.649\n",
      "iteration 7 160\t loss: 1.127, accuracy: 0.652\n",
      "iteration 7 170\t loss: 1.117, accuracy: 0.659\n",
      "iteration 7 180\t loss: 1.116, accuracy: 0.660\n",
      "iteration 7 190\t loss: 1.115, accuracy: 0.660\n",
      "iteration 7 200\t loss: 1.080, accuracy: 0.671\n",
      "iteration 7 210\t loss: 1.015, accuracy: 0.691\n",
      "iteration 7 220\t loss: 1.009, accuracy: 0.696\n",
      "iteration 7 230\t loss: 1.006, accuracy: 0.696\n",
      "iteration 7 240\t loss: 1.015, accuracy: 0.695\n",
      "iteration 7 250\t loss: 0.953, accuracy: 0.714\n",
      "iteration 7 260\t loss: 0.946, accuracy: 0.720\n",
      "iteration 7 270\t loss: 0.928, accuracy: 0.725\n",
      "iteration 7 280\t loss: 0.937, accuracy: 0.723\n",
      "iteration 8 0\t loss: 0.936, accuracy: 0.723\n",
      "iteration 8 10\t loss: 0.969, accuracy: 0.712\n",
      "iteration 8 20\t loss: 0.946, accuracy: 0.717\n",
      "iteration 8 30\t loss: 0.916, accuracy: 0.728\n",
      "iteration 8 40\t loss: 0.902, accuracy: 0.732\n",
      "iteration 8 50\t loss: 0.881, accuracy: 0.742\n",
      "iteration 8 60\t loss: 0.881, accuracy: 0.740\n",
      "iteration 8 70\t loss: 0.886, accuracy: 0.742\n",
      "iteration 8 80\t loss: 0.843, accuracy: 0.751\n",
      "iteration 8 90\t loss: 0.836, accuracy: 0.754\n",
      "iteration 8 100\t loss: 0.831, accuracy: 0.759\n",
      "iteration 8 110\t loss: 0.849, accuracy: 0.752\n",
      "iteration 8 120\t loss: 0.845, accuracy: 0.753\n",
      "iteration 8 130\t loss: 0.804, accuracy: 0.769\n",
      "iteration 8 140\t loss: 0.797, accuracy: 0.771\n",
      "iteration 8 150\t loss: 0.800, accuracy: 0.773\n",
      "iteration 8 160\t loss: 0.813, accuracy: 0.764\n",
      "iteration 8 170\t loss: 0.821, accuracy: 0.763\n",
      "iteration 8 180\t loss: 0.797, accuracy: 0.771\n",
      "iteration 8 190\t loss: 0.773, accuracy: 0.778\n",
      "iteration 8 200\t loss: 0.766, accuracy: 0.780\n",
      "iteration 8 210\t loss: 0.786, accuracy: 0.771\n",
      "iteration 8 220\t loss: 0.755, accuracy: 0.787\n",
      "iteration 8 230\t loss: 0.767, accuracy: 0.781\n",
      "iteration 8 240\t loss: 0.782, accuracy: 0.775\n",
      "iteration 8 250\t loss: 0.781, accuracy: 0.775\n",
      "iteration 8 260\t loss: 0.746, accuracy: 0.792\n",
      "iteration 8 270\t loss: 0.788, accuracy: 0.775\n",
      "iteration 8 280\t loss: 0.796, accuracy: 0.771\n",
      "iteration 9 0\t loss: 0.790, accuracy: 0.782\n",
      "iteration 9 10\t loss: 0.761, accuracy: 0.784\n",
      "iteration 9 20\t loss: 0.781, accuracy: 0.778\n",
      "iteration 9 30\t loss: 0.748, accuracy: 0.792\n",
      "iteration 9 40\t loss: 0.726, accuracy: 0.798\n",
      "iteration 9 50\t loss: 0.737, accuracy: 0.792\n",
      "iteration 9 60\t loss: 0.753, accuracy: 0.789\n",
      "iteration 9 70\t loss: 0.732, accuracy: 0.798\n",
      "iteration 9 80\t loss: 0.709, accuracy: 0.802\n",
      "iteration 9 90\t loss: 0.711, accuracy: 0.797\n",
      "iteration 9 100\t loss: 0.722, accuracy: 0.796\n",
      "iteration 9 110\t loss: 0.727, accuracy: 0.793\n",
      "iteration 9 120\t loss: 0.753, accuracy: 0.792\n",
      "iteration 9 130\t loss: 0.707, accuracy: 0.804\n",
      "iteration 9 140\t loss: 0.717, accuracy: 0.802\n",
      "iteration 9 150\t loss: 0.709, accuracy: 0.803\n",
      "iteration 9 160\t loss: 0.760, accuracy: 0.788\n",
      "iteration 9 170\t loss: 0.707, accuracy: 0.805\n",
      "iteration 9 180\t loss: 0.715, accuracy: 0.804\n",
      "iteration 9 190\t loss: 0.717, accuracy: 0.803\n",
      "iteration 9 200\t loss: 0.732, accuracy: 0.799\n",
      "iteration 9 210\t loss: 0.696, accuracy: 0.803\n",
      "iteration 9 220\t loss: 0.711, accuracy: 0.801\n",
      "iteration 9 230\t loss: 0.674, accuracy: 0.813\n",
      "iteration 9 240\t loss: 0.709, accuracy: 0.799\n",
      "iteration 9 250\t loss: 0.688, accuracy: 0.807\n",
      "iteration 9 260\t loss: 0.680, accuracy: 0.813\n",
      "iteration 9 270\t loss: 0.701, accuracy: 0.811\n",
      "iteration 9 280\t loss: 0.712, accuracy: 0.809\n",
      "iteration 10 0\t loss: 0.717, accuracy: 0.810\n",
      "iteration 10 10\t loss: 0.750, accuracy: 0.788\n",
      "iteration 10 20\t loss: 0.713, accuracy: 0.808\n",
      "iteration 10 30\t loss: 0.711, accuracy: 0.809\n",
      "iteration 10 40\t loss: 0.703, accuracy: 0.807\n",
      "iteration 10 50\t loss: 0.668, accuracy: 0.819\n",
      "iteration 10 60\t loss: 0.732, accuracy: 0.799\n",
      "iteration 10 70\t loss: 0.691, accuracy: 0.814\n",
      "iteration 10 80\t loss: 0.693, accuracy: 0.811\n",
      "iteration 10 90\t loss: 0.684, accuracy: 0.816\n",
      "iteration 10 100\t loss: 0.689, accuracy: 0.810\n",
      "iteration 10 110\t loss: 0.697, accuracy: 0.806\n",
      "iteration 10 120\t loss: 0.713, accuracy: 0.804\n",
      "iteration 10 130\t loss: 0.680, accuracy: 0.816\n",
      "iteration 10 140\t loss: 0.692, accuracy: 0.815\n",
      "iteration 10 150\t loss: 0.705, accuracy: 0.810\n",
      "iteration 10 160\t loss: 0.772, accuracy: 0.799\n",
      "iteration 10 170\t loss: 0.699, accuracy: 0.810\n",
      "iteration 10 180\t loss: 0.692, accuracy: 0.816\n",
      "iteration 10 190\t loss: 0.723, accuracy: 0.804\n",
      "iteration 10 200\t loss: 0.709, accuracy: 0.813\n",
      "iteration 10 210\t loss: 0.687, accuracy: 0.812\n",
      "iteration 10 220\t loss: 0.709, accuracy: 0.810\n",
      "iteration 10 230\t loss: 0.681, accuracy: 0.813\n",
      "iteration 10 240\t loss: 0.668, accuracy: 0.820\n",
      "iteration 10 250\t loss: 0.679, accuracy: 0.816\n",
      "iteration 10 260\t loss: 0.658, accuracy: 0.824\n",
      "iteration 10 270\t loss: 0.735, accuracy: 0.809\n",
      "iteration 10 280\t loss: 0.709, accuracy: 0.815\n",
      "iteration 11 0\t loss: 0.692, accuracy: 0.818\n",
      "iteration 11 10\t loss: 0.718, accuracy: 0.811\n",
      "iteration 11 20\t loss: 0.743, accuracy: 0.808\n",
      "iteration 11 30\t loss: 0.712, accuracy: 0.815\n",
      "iteration 11 40\t loss: 0.700, accuracy: 0.817\n",
      "iteration 11 50\t loss: 0.696, accuracy: 0.819\n",
      "iteration 11 60\t loss: 0.713, accuracy: 0.811\n",
      "iteration 11 70\t loss: 0.700, accuracy: 0.814\n",
      "iteration 11 80\t loss: 0.677, accuracy: 0.820\n",
      "iteration 11 90\t loss: 0.697, accuracy: 0.822\n",
      "iteration 11 100\t loss: 0.697, accuracy: 0.815\n",
      "iteration 11 110\t loss: 0.715, accuracy: 0.808\n",
      "iteration 11 120\t loss: 0.723, accuracy: 0.808\n",
      "iteration 11 130\t loss: 0.736, accuracy: 0.813\n",
      "iteration 11 140\t loss: 0.711, accuracy: 0.826\n",
      "iteration 11 150\t loss: 0.720, accuracy: 0.817\n",
      "iteration 11 160\t loss: 0.822, accuracy: 0.800\n",
      "iteration 11 170\t loss: 0.754, accuracy: 0.806\n",
      "iteration 11 180\t loss: 0.749, accuracy: 0.814\n",
      "iteration 11 190\t loss: 0.689, accuracy: 0.821\n",
      "iteration 11 200\t loss: 0.711, accuracy: 0.817\n",
      "iteration 11 210\t loss: 0.706, accuracy: 0.812\n",
      "iteration 11 220\t loss: 0.720, accuracy: 0.820\n",
      "iteration 11 230\t loss: 0.678, accuracy: 0.822\n",
      "iteration 11 240\t loss: 0.695, accuracy: 0.824\n",
      "iteration 11 250\t loss: 0.676, accuracy: 0.825\n",
      "iteration 11 260\t loss: 0.704, accuracy: 0.822\n",
      "iteration 11 270\t loss: 0.725, accuracy: 0.820\n",
      "iteration 11 280\t loss: 0.728, accuracy: 0.822\n",
      "iteration 12 0\t loss: 0.716, accuracy: 0.821\n",
      "iteration 12 10\t loss: 0.774, accuracy: 0.811\n",
      "iteration 12 20\t loss: 0.786, accuracy: 0.804\n",
      "iteration 12 30\t loss: 0.731, accuracy: 0.816\n",
      "iteration 12 40\t loss: 0.763, accuracy: 0.812\n",
      "iteration 12 50\t loss: 0.738, accuracy: 0.813\n",
      "iteration 12 60\t loss: 0.728, accuracy: 0.812\n",
      "iteration 12 70\t loss: 0.722, accuracy: 0.813\n",
      "iteration 12 80\t loss: 0.694, accuracy: 0.824\n",
      "iteration 12 90\t loss: 0.723, accuracy: 0.830\n",
      "iteration 12 100\t loss: 0.712, accuracy: 0.817\n",
      "iteration 12 110\t loss: 0.740, accuracy: 0.812\n",
      "iteration 12 120\t loss: 0.710, accuracy: 0.819\n",
      "iteration 12 130\t loss: 0.740, accuracy: 0.821\n",
      "iteration 12 140\t loss: 0.795, accuracy: 0.806\n",
      "iteration 12 150\t loss: 0.833, accuracy: 0.797\n",
      "iteration 12 160\t loss: 0.823, accuracy: 0.808\n",
      "iteration 12 170\t loss: 0.781, accuracy: 0.809\n",
      "iteration 12 180\t loss: 0.819, accuracy: 0.808\n",
      "iteration 12 190\t loss: 0.772, accuracy: 0.818\n",
      "iteration 12 200\t loss: 0.802, accuracy: 0.813\n",
      "iteration 12 210\t loss: 0.731, accuracy: 0.816\n",
      "iteration 12 220\t loss: 0.758, accuracy: 0.814\n",
      "iteration 12 230\t loss: 0.717, accuracy: 0.815\n",
      "iteration 12 240\t loss: 0.726, accuracy: 0.825\n",
      "iteration 12 250\t loss: 0.739, accuracy: 0.818\n",
      "iteration 12 260\t loss: 0.738, accuracy: 0.822\n",
      "iteration 12 270\t loss: 0.766, accuracy: 0.822\n",
      "iteration 12 280\t loss: 0.733, accuracy: 0.826\n",
      "iteration 13 0\t loss: 0.726, accuracy: 0.827\n",
      "iteration 13 10\t loss: 0.840, accuracy: 0.814\n",
      "iteration 13 20\t loss: 0.797, accuracy: 0.809\n",
      "iteration 13 30\t loss: 0.775, accuracy: 0.812\n",
      "iteration 13 40\t loss: 0.916, accuracy: 0.803\n",
      "iteration 13 50\t loss: 0.786, accuracy: 0.816\n",
      "iteration 13 60\t loss: 0.767, accuracy: 0.813\n",
      "iteration 13 70\t loss: 0.805, accuracy: 0.800\n",
      "iteration 13 80\t loss: 0.775, accuracy: 0.813\n",
      "iteration 13 90\t loss: 0.739, accuracy: 0.826\n",
      "iteration 13 100\t loss: 0.773, accuracy: 0.808\n",
      "iteration 13 110\t loss: 0.804, accuracy: 0.806\n",
      "iteration 13 120\t loss: 0.760, accuracy: 0.811\n",
      "iteration 13 130\t loss: 0.768, accuracy: 0.823\n",
      "iteration 13 140\t loss: 0.859, accuracy: 0.805\n",
      "iteration 13 150\t loss: 0.838, accuracy: 0.806\n",
      "iteration 13 160\t loss: 0.835, accuracy: 0.807\n",
      "iteration 13 170\t loss: 0.789, accuracy: 0.826\n",
      "iteration 13 180\t loss: 0.895, accuracy: 0.808\n",
      "iteration 13 190\t loss: 0.836, accuracy: 0.816\n",
      "iteration 13 200\t loss: 0.818, accuracy: 0.817\n",
      "iteration 13 210\t loss: 0.795, accuracy: 0.816\n",
      "iteration 13 220\t loss: 0.796, accuracy: 0.815\n",
      "iteration 13 230\t loss: 0.753, accuracy: 0.816\n",
      "iteration 13 240\t loss: 0.744, accuracy: 0.829\n",
      "iteration 13 250\t loss: 0.786, accuracy: 0.820\n",
      "iteration 13 260\t loss: 0.764, accuracy: 0.826\n",
      "iteration 13 270\t loss: 0.801, accuracy: 0.818\n",
      "iteration 13 280\t loss: 0.833, accuracy: 0.817\n",
      "iteration 14 0\t loss: 0.839, accuracy: 0.825\n",
      "iteration 14 10\t loss: 0.852, accuracy: 0.817\n",
      "iteration 14 20\t loss: 0.859, accuracy: 0.805\n",
      "iteration 14 30\t loss: 0.848, accuracy: 0.812\n",
      "iteration 14 40\t loss: 0.879, accuracy: 0.804\n",
      "iteration 14 50\t loss: 0.823, accuracy: 0.812\n",
      "iteration 14 60\t loss: 0.792, accuracy: 0.819\n",
      "iteration 14 70\t loss: 0.821, accuracy: 0.810\n",
      "iteration 14 80\t loss: 0.812, accuracy: 0.817\n",
      "iteration 14 90\t loss: 0.725, accuracy: 0.827\n",
      "iteration 14 100\t loss: 0.789, accuracy: 0.819\n",
      "iteration 14 110\t loss: 0.800, accuracy: 0.815\n",
      "iteration 14 120\t loss: 0.844, accuracy: 0.800\n",
      "iteration 14 130\t loss: 0.796, accuracy: 0.820\n",
      "iteration 14 140\t loss: 0.847, accuracy: 0.818\n",
      "iteration 14 150\t loss: 0.905, accuracy: 0.819\n",
      "iteration 14 160\t loss: 0.879, accuracy: 0.808\n",
      "iteration 14 170\t loss: 0.830, accuracy: 0.822\n",
      "iteration 14 180\t loss: 0.922, accuracy: 0.802\n",
      "iteration 14 190\t loss: 0.901, accuracy: 0.817\n",
      "iteration 14 200\t loss: 0.848, accuracy: 0.816\n",
      "iteration 14 210\t loss: 0.825, accuracy: 0.820\n",
      "iteration 14 220\t loss: 0.802, accuracy: 0.823\n",
      "iteration 14 230\t loss: 0.764, accuracy: 0.822\n",
      "iteration 14 240\t loss: 0.765, accuracy: 0.830\n",
      "iteration 14 250\t loss: 0.896, accuracy: 0.813\n",
      "iteration 14 260\t loss: 0.869, accuracy: 0.811\n",
      "iteration 14 270\t loss: 0.854, accuracy: 0.814\n",
      "iteration 14 280\t loss: 0.838, accuracy: 0.822\n",
      "iteration 15 0\t loss: 0.870, accuracy: 0.822\n",
      "iteration 15 10\t loss: 0.874, accuracy: 0.826\n",
      "iteration 15 20\t loss: 0.886, accuracy: 0.818\n",
      "iteration 15 30\t loss: 1.044, accuracy: 0.797\n",
      "iteration 15 40\t loss: 0.866, accuracy: 0.816\n",
      "iteration 15 50\t loss: 0.856, accuracy: 0.820\n",
      "iteration 15 60\t loss: 0.896, accuracy: 0.812\n",
      "iteration 15 70\t loss: 0.860, accuracy: 0.817\n",
      "iteration 15 80\t loss: 0.793, accuracy: 0.831\n",
      "iteration 15 90\t loss: 0.754, accuracy: 0.833\n",
      "iteration 15 100\t loss: 0.787, accuracy: 0.825\n",
      "iteration 15 110\t loss: 0.780, accuracy: 0.827\n",
      "iteration 15 120\t loss: 0.871, accuracy: 0.809\n",
      "iteration 15 130\t loss: 0.841, accuracy: 0.820\n",
      "iteration 15 140\t loss: 0.905, accuracy: 0.814\n",
      "iteration 15 150\t loss: 0.859, accuracy: 0.825\n",
      "iteration 15 160\t loss: 0.996, accuracy: 0.806\n",
      "iteration 15 170\t loss: 0.984, accuracy: 0.811\n",
      "iteration 15 180\t loss: 0.936, accuracy: 0.813\n",
      "iteration 15 190\t loss: 0.947, accuracy: 0.813\n",
      "iteration 15 200\t loss: 0.920, accuracy: 0.819\n",
      "iteration 15 210\t loss: 0.886, accuracy: 0.824\n",
      "iteration 15 220\t loss: 0.823, accuracy: 0.826\n",
      "iteration 15 230\t loss: 0.803, accuracy: 0.826\n",
      "iteration 15 240\t loss: 0.796, accuracy: 0.825\n",
      "iteration 15 250\t loss: 0.964, accuracy: 0.803\n",
      "iteration 15 260\t loss: 0.959, accuracy: 0.813\n",
      "iteration 15 270\t loss: 1.003, accuracy: 0.795\n",
      "iteration 15 280\t loss: 0.941, accuracy: 0.817\n",
      "iteration 16 0\t loss: 0.936, accuracy: 0.814\n",
      "iteration 16 10\t loss: 0.948, accuracy: 0.821\n",
      "iteration 16 20\t loss: 0.946, accuracy: 0.821\n",
      "iteration 16 30\t loss: 1.318, accuracy: 0.787\n",
      "iteration 16 40\t loss: 0.955, accuracy: 0.809\n",
      "iteration 16 50\t loss: 0.908, accuracy: 0.810\n",
      "iteration 16 60\t loss: 0.891, accuracy: 0.818\n",
      "iteration 16 70\t loss: 0.922, accuracy: 0.810\n",
      "iteration 16 80\t loss: 0.861, accuracy: 0.821\n",
      "iteration 16 90\t loss: 0.801, accuracy: 0.830\n",
      "iteration 16 100\t loss: 0.851, accuracy: 0.824\n",
      "iteration 16 110\t loss: 0.858, accuracy: 0.820\n",
      "iteration 16 120\t loss: 0.907, accuracy: 0.814\n",
      "iteration 16 130\t loss: 0.977, accuracy: 0.811\n",
      "iteration 16 140\t loss: 0.968, accuracy: 0.817\n",
      "iteration 16 150\t loss: 0.884, accuracy: 0.828\n",
      "iteration 16 160\t loss: 1.129, accuracy: 0.785\n",
      "iteration 16 170\t loss: 0.926, accuracy: 0.827\n",
      "iteration 16 180\t loss: 0.901, accuracy: 0.824\n",
      "iteration 16 190\t loss: 1.001, accuracy: 0.815\n",
      "iteration 16 200\t loss: 0.944, accuracy: 0.824\n",
      "iteration 16 210\t loss: 0.960, accuracy: 0.823\n",
      "iteration 16 220\t loss: 0.941, accuracy: 0.819\n",
      "iteration 16 230\t loss: 0.850, accuracy: 0.820\n",
      "iteration 16 240\t loss: 0.884, accuracy: 0.830\n",
      "iteration 16 250\t loss: 0.913, accuracy: 0.820\n",
      "iteration 16 260\t loss: 0.985, accuracy: 0.822\n",
      "iteration 16 270\t loss: 1.017, accuracy: 0.802\n",
      "iteration 16 280\t loss: 0.894, accuracy: 0.822\n",
      "iteration 17 0\t loss: 0.945, accuracy: 0.827\n",
      "iteration 17 10\t loss: 0.965, accuracy: 0.822\n",
      "iteration 17 20\t loss: 1.048, accuracy: 0.812\n",
      "iteration 17 30\t loss: 1.475, accuracy: 0.777\n",
      "iteration 17 40\t loss: 1.048, accuracy: 0.801\n",
      "iteration 17 50\t loss: 0.973, accuracy: 0.812\n",
      "iteration 17 60\t loss: 0.949, accuracy: 0.818\n",
      "iteration 17 70\t loss: 0.962, accuracy: 0.815\n",
      "iteration 17 80\t loss: 0.953, accuracy: 0.818\n",
      "iteration 17 90\t loss: 0.854, accuracy: 0.826\n",
      "iteration 17 100\t loss: 0.862, accuracy: 0.823\n",
      "iteration 17 110\t loss: 0.902, accuracy: 0.820\n",
      "iteration 17 120\t loss: 0.941, accuracy: 0.819\n",
      "iteration 17 130\t loss: 0.925, accuracy: 0.822\n",
      "iteration 17 140\t loss: 0.946, accuracy: 0.821\n",
      "iteration 17 150\t loss: 0.935, accuracy: 0.827\n",
      "iteration 17 160\t loss: 1.069, accuracy: 0.806\n",
      "iteration 17 170\t loss: 0.990, accuracy: 0.825\n",
      "iteration 17 180\t loss: 1.011, accuracy: 0.826\n",
      "iteration 17 190\t loss: 1.096, accuracy: 0.816\n",
      "iteration 17 200\t loss: 0.984, accuracy: 0.823\n",
      "iteration 17 210\t loss: 1.029, accuracy: 0.822\n",
      "iteration 17 220\t loss: 0.975, accuracy: 0.814\n",
      "iteration 17 230\t loss: 0.903, accuracy: 0.821\n",
      "iteration 17 240\t loss: 0.945, accuracy: 0.826\n",
      "iteration 17 250\t loss: 0.962, accuracy: 0.821\n",
      "iteration 17 260\t loss: 0.971, accuracy: 0.822\n",
      "iteration 17 270\t loss: 1.058, accuracy: 0.817\n",
      "iteration 17 280\t loss: 1.002, accuracy: 0.818\n",
      "iteration 18 0\t loss: 1.027, accuracy: 0.823\n",
      "iteration 18 10\t loss: 1.114, accuracy: 0.821\n",
      "iteration 18 20\t loss: 1.231, accuracy: 0.797\n",
      "iteration 18 30\t loss: 1.175, accuracy: 0.815\n",
      "iteration 18 40\t loss: 1.101, accuracy: 0.785\n",
      "iteration 18 50\t loss: 1.180, accuracy: 0.797\n",
      "iteration 18 60\t loss: 1.047, accuracy: 0.816\n",
      "iteration 18 70\t loss: 0.998, accuracy: 0.823\n",
      "iteration 18 80\t loss: 1.018, accuracy: 0.813\n",
      "iteration 18 90\t loss: 0.918, accuracy: 0.827\n",
      "iteration 18 100\t loss: 0.973, accuracy: 0.819\n",
      "iteration 18 110\t loss: 0.990, accuracy: 0.819\n",
      "iteration 18 120\t loss: 1.101, accuracy: 0.806\n",
      "iteration 18 130\t loss: 0.992, accuracy: 0.820\n",
      "iteration 18 140\t loss: 1.062, accuracy: 0.816\n",
      "iteration 18 150\t loss: 1.037, accuracy: 0.816\n",
      "iteration 18 160\t loss: 1.130, accuracy: 0.800\n",
      "iteration 18 170\t loss: 1.072, accuracy: 0.821\n",
      "iteration 18 180\t loss: 1.042, accuracy: 0.814\n",
      "iteration 18 190\t loss: 1.237, accuracy: 0.805\n",
      "iteration 18 200\t loss: 1.116, accuracy: 0.819\n",
      "iteration 18 210\t loss: 1.070, accuracy: 0.829\n",
      "iteration 18 220\t loss: 1.042, accuracy: 0.818\n",
      "iteration 18 230\t loss: 1.005, accuracy: 0.821\n",
      "iteration 18 240\t loss: 1.022, accuracy: 0.826\n",
      "iteration 18 250\t loss: 1.047, accuracy: 0.812\n",
      "iteration 18 260\t loss: 1.094, accuracy: 0.816\n",
      "iteration 18 270\t loss: 1.122, accuracy: 0.819\n",
      "iteration 18 280\t loss: 1.136, accuracy: 0.803\n",
      "iteration 19 0\t loss: 1.048, accuracy: 0.818\n",
      "iteration 19 10\t loss: 1.145, accuracy: 0.823\n",
      "iteration 19 20\t loss: 1.365, accuracy: 0.794\n",
      "iteration 19 30\t loss: 1.265, accuracy: 0.799\n",
      "iteration 19 40\t loss: 1.239, accuracy: 0.799\n",
      "iteration 19 50\t loss: 1.147, accuracy: 0.810\n",
      "iteration 19 60\t loss: 1.147, accuracy: 0.802\n",
      "iteration 19 70\t loss: 1.199, accuracy: 0.796\n",
      "iteration 19 80\t loss: 1.006, accuracy: 0.816\n",
      "iteration 19 90\t loss: 1.012, accuracy: 0.828\n",
      "iteration 19 100\t loss: 1.037, accuracy: 0.827\n",
      "iteration 19 110\t loss: 1.010, accuracy: 0.825\n",
      "iteration 19 120\t loss: 1.174, accuracy: 0.803\n",
      "iteration 19 130\t loss: 1.079, accuracy: 0.815\n",
      "iteration 19 140\t loss: 1.130, accuracy: 0.817\n",
      "iteration 19 150\t loss: 1.047, accuracy: 0.827\n",
      "iteration 19 160\t loss: 1.125, accuracy: 0.816\n",
      "iteration 19 170\t loss: 1.231, accuracy: 0.798\n",
      "iteration 19 180\t loss: 1.138, accuracy: 0.817\n",
      "iteration 19 190\t loss: 1.329, accuracy: 0.802\n",
      "iteration 19 200\t loss: 1.173, accuracy: 0.814\n",
      "iteration 19 210\t loss: 1.151, accuracy: 0.822\n",
      "iteration 19 220\t loss: 1.059, accuracy: 0.822\n",
      "iteration 19 230\t loss: 1.057, accuracy: 0.828\n",
      "iteration 19 240\t loss: 1.053, accuracy: 0.823\n",
      "iteration 19 250\t loss: 1.101, accuracy: 0.812\n",
      "iteration 19 260\t loss: 1.093, accuracy: 0.815\n",
      "iteration 19 270\t loss: 1.172, accuracy: 0.815\n",
      "iteration 19 280\t loss: 1.125, accuracy: 0.817\n",
      "iteration 20 0\t loss: 1.033, accuracy: 0.829\n",
      "iteration 20 10\t loss: 1.091, accuracy: 0.826\n",
      "iteration 20 20\t loss: 1.398, accuracy: 0.802\n",
      "iteration 20 30\t loss: 1.252, accuracy: 0.794\n",
      "iteration 20 40\t loss: 1.325, accuracy: 0.805\n",
      "iteration 20 50\t loss: 1.430, accuracy: 0.800\n",
      "iteration 20 60\t loss: 1.195, accuracy: 0.811\n",
      "iteration 20 70\t loss: 1.303, accuracy: 0.806\n",
      "iteration 20 80\t loss: 1.049, accuracy: 0.824\n",
      "iteration 20 90\t loss: 1.081, accuracy: 0.827\n",
      "iteration 20 100\t loss: 1.083, accuracy: 0.826\n",
      "iteration 20 110\t loss: 1.044, accuracy: 0.825\n",
      "iteration 20 120\t loss: 1.204, accuracy: 0.807\n",
      "iteration 20 130\t loss: 1.118, accuracy: 0.810\n",
      "iteration 20 140\t loss: 1.316, accuracy: 0.815\n",
      "iteration 20 150\t loss: 1.142, accuracy: 0.823\n",
      "iteration 20 160\t loss: 1.191, accuracy: 0.813\n",
      "iteration 20 170\t loss: 1.338, accuracy: 0.795\n",
      "iteration 20 180\t loss: 1.190, accuracy: 0.820\n",
      "iteration 20 190\t loss: 1.352, accuracy: 0.805\n",
      "iteration 20 200\t loss: 1.203, accuracy: 0.813\n",
      "iteration 20 210\t loss: 1.361, accuracy: 0.811\n",
      "iteration 20 220\t loss: 1.108, accuracy: 0.817\n",
      "iteration 20 230\t loss: 1.149, accuracy: 0.828\n",
      "iteration 20 240\t loss: 1.080, accuracy: 0.824\n",
      "iteration 20 250\t loss: 1.173, accuracy: 0.820\n",
      "iteration 20 260\t loss: 1.285, accuracy: 0.811\n",
      "iteration 20 270\t loss: 1.199, accuracy: 0.820\n",
      "iteration 20 280\t loss: 1.429, accuracy: 0.803\n",
      "iteration 21 0\t loss: 1.177, accuracy: 0.809\n",
      "iteration 21 10\t loss: 1.223, accuracy: 0.822\n",
      "iteration 21 20\t loss: 1.532, accuracy: 0.793\n",
      "iteration 21 30\t loss: 1.338, accuracy: 0.805\n",
      "iteration 21 40\t loss: 1.362, accuracy: 0.811\n",
      "iteration 21 50\t loss: 1.259, accuracy: 0.808\n",
      "iteration 21 60\t loss: 1.428, accuracy: 0.794\n",
      "iteration 21 70\t loss: 1.365, accuracy: 0.804\n",
      "iteration 21 80\t loss: 1.076, accuracy: 0.827\n",
      "iteration 21 90\t loss: 1.119, accuracy: 0.822\n",
      "iteration 21 100\t loss: 1.129, accuracy: 0.822\n",
      "iteration 21 110\t loss: 1.133, accuracy: 0.821\n",
      "iteration 21 120\t loss: 1.324, accuracy: 0.802\n",
      "iteration 21 130\t loss: 1.256, accuracy: 0.812\n",
      "iteration 21 140\t loss: 1.224, accuracy: 0.820\n",
      "iteration 21 150\t loss: 1.167, accuracy: 0.824\n",
      "iteration 21 160\t loss: 1.223, accuracy: 0.818\n",
      "iteration 21 170\t loss: 1.334, accuracy: 0.800\n",
      "iteration 21 180\t loss: 1.225, accuracy: 0.822\n",
      "iteration 21 190\t loss: 1.282, accuracy: 0.817\n",
      "iteration 21 200\t loss: 1.372, accuracy: 0.816\n",
      "iteration 21 210\t loss: 1.312, accuracy: 0.816\n",
      "iteration 21 220\t loss: 1.216, accuracy: 0.812\n",
      "iteration 21 230\t loss: 1.214, accuracy: 0.827\n",
      "iteration 21 240\t loss: 1.161, accuracy: 0.823\n",
      "iteration 21 250\t loss: 1.323, accuracy: 0.816\n",
      "iteration 21 260\t loss: 1.182, accuracy: 0.818\n",
      "iteration 21 270\t loss: 1.187, accuracy: 0.828\n",
      "iteration 21 280\t loss: 1.344, accuracy: 0.821\n",
      "iteration 22 0\t loss: 1.313, accuracy: 0.822\n",
      "iteration 22 10\t loss: 1.268, accuracy: 0.817\n",
      "iteration 22 20\t loss: 1.777, accuracy: 0.777\n",
      "iteration 22 30\t loss: 1.364, accuracy: 0.810\n",
      "iteration 22 40\t loss: 1.586, accuracy: 0.803\n",
      "iteration 22 50\t loss: 1.363, accuracy: 0.810\n",
      "iteration 22 60\t loss: 1.376, accuracy: 0.809\n",
      "iteration 22 70\t loss: 1.494, accuracy: 0.803\n",
      "iteration 22 80\t loss: 1.175, accuracy: 0.821\n",
      "iteration 22 90\t loss: 1.062, accuracy: 0.828\n",
      "iteration 22 100\t loss: 1.136, accuracy: 0.822\n",
      "iteration 22 110\t loss: 1.131, accuracy: 0.823\n",
      "iteration 22 120\t loss: 1.361, accuracy: 0.804\n",
      "iteration 22 130\t loss: 1.273, accuracy: 0.808\n",
      "iteration 22 140\t loss: 1.259, accuracy: 0.824\n",
      "iteration 22 150\t loss: 1.272, accuracy: 0.828\n",
      "iteration 22 160\t loss: 1.201, accuracy: 0.824\n",
      "iteration 22 170\t loss: 1.430, accuracy: 0.798\n",
      "iteration 22 180\t loss: 1.419, accuracy: 0.800\n",
      "iteration 22 190\t loss: 1.364, accuracy: 0.816\n",
      "iteration 22 200\t loss: 1.482, accuracy: 0.804\n",
      "iteration 22 210\t loss: 1.289, accuracy: 0.815\n",
      "iteration 22 220\t loss: 1.277, accuracy: 0.822\n",
      "iteration 22 230\t loss: 1.289, accuracy: 0.817\n",
      "iteration 22 240\t loss: 1.181, accuracy: 0.822\n",
      "iteration 22 250\t loss: 1.340, accuracy: 0.817\n",
      "iteration 22 260\t loss: 1.209, accuracy: 0.824\n",
      "iteration 22 270\t loss: 1.318, accuracy: 0.821\n",
      "iteration 22 280\t loss: 1.363, accuracy: 0.821\n",
      "iteration 23 0\t loss: 1.340, accuracy: 0.819\n",
      "iteration 23 10\t loss: 1.327, accuracy: 0.823\n",
      "iteration 23 20\t loss: 1.817, accuracy: 0.788\n",
      "iteration 23 30\t loss: 1.299, accuracy: 0.807\n",
      "iteration 23 40\t loss: 1.551, accuracy: 0.806\n",
      "iteration 23 50\t loss: 1.254, accuracy: 0.824\n",
      "iteration 23 60\t loss: 1.268, accuracy: 0.818\n",
      "iteration 23 70\t loss: 1.427, accuracy: 0.817\n",
      "iteration 23 80\t loss: 1.374, accuracy: 0.811\n",
      "iteration 23 90\t loss: 1.111, accuracy: 0.829\n",
      "iteration 23 100\t loss: 1.285, accuracy: 0.827\n",
      "iteration 23 110\t loss: 1.199, accuracy: 0.830\n",
      "iteration 23 120\t loss: 1.409, accuracy: 0.814\n",
      "iteration 23 130\t loss: 1.349, accuracy: 0.820\n",
      "iteration 23 140\t loss: 1.424, accuracy: 0.820\n",
      "iteration 23 150\t loss: 1.411, accuracy: 0.822\n",
      "iteration 23 160\t loss: 1.340, accuracy: 0.818\n",
      "iteration 23 170\t loss: 1.563, accuracy: 0.793\n",
      "iteration 23 180\t loss: 1.310, accuracy: 0.805\n",
      "iteration 23 190\t loss: 1.450, accuracy: 0.818\n",
      "iteration 23 200\t loss: 1.581, accuracy: 0.812\n",
      "iteration 23 210\t loss: 1.376, accuracy: 0.817\n",
      "iteration 23 220\t loss: 1.304, accuracy: 0.816\n",
      "iteration 23 230\t loss: 1.364, accuracy: 0.819\n",
      "iteration 23 240\t loss: 1.298, accuracy: 0.823\n",
      "iteration 23 250\t loss: 1.342, accuracy: 0.823\n",
      "iteration 23 260\t loss: 1.339, accuracy: 0.809\n",
      "iteration 23 270\t loss: 1.379, accuracy: 0.823\n",
      "iteration 23 280\t loss: 1.394, accuracy: 0.827\n",
      "iteration 24 0\t loss: 1.482, accuracy: 0.817\n",
      "iteration 24 10\t loss: 1.436, accuracy: 0.823\n",
      "iteration 24 20\t loss: 1.855, accuracy: 0.805\n",
      "iteration 24 30\t loss: 1.531, accuracy: 0.801\n",
      "iteration 24 40\t loss: 1.582, accuracy: 0.812\n",
      "iteration 24 50\t loss: 1.521, accuracy: 0.823\n",
      "iteration 24 60\t loss: 1.374, accuracy: 0.821\n",
      "iteration 24 70\t loss: 1.487, accuracy: 0.816\n",
      "iteration 24 80\t loss: 1.476, accuracy: 0.817\n",
      "iteration 24 90\t loss: 1.182, accuracy: 0.826\n",
      "iteration 24 100\t loss: 1.316, accuracy: 0.824\n",
      "iteration 24 110\t loss: 1.267, accuracy: 0.828\n",
      "iteration 24 120\t loss: 1.454, accuracy: 0.818\n",
      "iteration 24 130\t loss: 1.396, accuracy: 0.826\n",
      "iteration 24 140\t loss: 1.441, accuracy: 0.824\n",
      "iteration 24 150\t loss: 1.484, accuracy: 0.827\n",
      "iteration 24 160\t loss: 1.379, accuracy: 0.820\n",
      "iteration 24 170\t loss: 1.597, accuracy: 0.794\n",
      "iteration 24 180\t loss: 1.388, accuracy: 0.807\n",
      "iteration 24 190\t loss: 1.787, accuracy: 0.804\n",
      "iteration 24 200\t loss: 1.699, accuracy: 0.813\n",
      "iteration 24 210\t loss: 1.519, accuracy: 0.820\n",
      "iteration 24 220\t loss: 1.414, accuracy: 0.813\n",
      "iteration 24 230\t loss: 1.360, accuracy: 0.822\n",
      "iteration 24 240\t loss: 1.436, accuracy: 0.821\n",
      "iteration 24 250\t loss: 1.415, accuracy: 0.822\n",
      "iteration 24 260\t loss: 1.531, accuracy: 0.811\n",
      "iteration 24 270\t loss: 1.378, accuracy: 0.811\n",
      "iteration 24 280\t loss: 1.450, accuracy: 0.825\n",
      "iteration 25 0\t loss: 1.522, accuracy: 0.819\n",
      "iteration 25 10\t loss: 1.453, accuracy: 0.821\n",
      "iteration 25 20\t loss: 1.835, accuracy: 0.811\n",
      "iteration 25 30\t loss: 1.760, accuracy: 0.794\n",
      "iteration 25 40\t loss: 1.528, accuracy: 0.809\n",
      "iteration 25 50\t loss: 1.651, accuracy: 0.810\n",
      "iteration 25 60\t loss: 1.517, accuracy: 0.813\n",
      "iteration 25 70\t loss: 1.610, accuracy: 0.812\n",
      "iteration 25 80\t loss: 1.597, accuracy: 0.810\n",
      "iteration 25 90\t loss: 1.244, accuracy: 0.823\n",
      "iteration 25 100\t loss: 1.383, accuracy: 0.827\n",
      "iteration 25 110\t loss: 1.404, accuracy: 0.825\n",
      "iteration 25 120\t loss: 1.529, accuracy: 0.817\n",
      "iteration 25 130\t loss: 1.476, accuracy: 0.823\n",
      "iteration 25 140\t loss: 1.417, accuracy: 0.826\n",
      "iteration 25 150\t loss: 1.592, accuracy: 0.821\n",
      "iteration 25 160\t loss: 1.382, accuracy: 0.827\n",
      "iteration 25 170\t loss: 1.632, accuracy: 0.794\n",
      "iteration 25 180\t loss: 1.400, accuracy: 0.807\n",
      "iteration 25 190\t loss: 1.809, accuracy: 0.809\n",
      "iteration 25 200\t loss: 1.597, accuracy: 0.814\n",
      "iteration 25 210\t loss: 1.731, accuracy: 0.818\n",
      "iteration 25 220\t loss: 1.606, accuracy: 0.805\n",
      "iteration 25 230\t loss: 1.461, accuracy: 0.824\n",
      "iteration 25 240\t loss: 1.549, accuracy: 0.821\n",
      "iteration 25 250\t loss: 1.539, accuracy: 0.828\n",
      "iteration 25 260\t loss: 1.771, accuracy: 0.803\n",
      "iteration 25 270\t loss: 1.458, accuracy: 0.815\n",
      "iteration 25 280\t loss: 1.579, accuracy: 0.817\n",
      "iteration 26 0\t loss: 1.792, accuracy: 0.800\n",
      "iteration 26 10\t loss: 1.479, accuracy: 0.822\n",
      "iteration 26 20\t loss: 1.764, accuracy: 0.815\n",
      "iteration 26 30\t loss: 1.894, accuracy: 0.795\n",
      "iteration 26 40\t loss: 1.781, accuracy: 0.802\n",
      "iteration 26 50\t loss: 1.819, accuracy: 0.808\n",
      "iteration 26 60\t loss: 1.600, accuracy: 0.805\n",
      "iteration 26 70\t loss: 1.679, accuracy: 0.813\n",
      "iteration 26 80\t loss: 1.724, accuracy: 0.814\n",
      "iteration 26 90\t loss: 1.365, accuracy: 0.827\n",
      "iteration 26 100\t loss: 1.389, accuracy: 0.831\n",
      "iteration 26 110\t loss: 1.480, accuracy: 0.834\n",
      "iteration 26 120\t loss: 1.600, accuracy: 0.823\n",
      "iteration 26 130\t loss: 1.707, accuracy: 0.812\n",
      "iteration 26 140\t loss: 1.519, accuracy: 0.815\n",
      "iteration 26 150\t loss: 1.815, accuracy: 0.816\n",
      "iteration 26 160\t loss: 1.512, accuracy: 0.820\n",
      "iteration 26 170\t loss: 1.765, accuracy: 0.789\n",
      "iteration 26 180\t loss: 1.503, accuracy: 0.807\n",
      "iteration 26 190\t loss: 1.898, accuracy: 0.802\n",
      "iteration 26 200\t loss: 1.792, accuracy: 0.809\n",
      "iteration 26 210\t loss: 1.710, accuracy: 0.822\n",
      "iteration 26 220\t loss: 1.631, accuracy: 0.805\n",
      "iteration 26 230\t loss: 1.515, accuracy: 0.813\n",
      "iteration 26 240\t loss: 1.627, accuracy: 0.813\n",
      "iteration 26 250\t loss: 1.546, accuracy: 0.826\n",
      "iteration 26 260\t loss: 1.726, accuracy: 0.810\n",
      "iteration 26 270\t loss: 1.504, accuracy: 0.824\n",
      "iteration 26 280\t loss: 1.546, accuracy: 0.814\n",
      "iteration 27 0\t loss: 1.700, accuracy: 0.810\n",
      "iteration 27 10\t loss: 1.723, accuracy: 0.805\n",
      "iteration 27 20\t loss: 1.694, accuracy: 0.811\n",
      "iteration 27 30\t loss: 2.015, accuracy: 0.794\n",
      "iteration 27 40\t loss: 1.654, accuracy: 0.798\n",
      "iteration 27 50\t loss: 1.987, accuracy: 0.800\n",
      "iteration 27 60\t loss: 1.603, accuracy: 0.804\n",
      "iteration 27 70\t loss: 1.666, accuracy: 0.808\n",
      "iteration 27 80\t loss: 1.874, accuracy: 0.804\n",
      "iteration 27 90\t loss: 1.475, accuracy: 0.823\n",
      "iteration 27 100\t loss: 1.420, accuracy: 0.823\n",
      "iteration 27 110\t loss: 1.479, accuracy: 0.830\n",
      "iteration 27 120\t loss: 1.602, accuracy: 0.815\n",
      "iteration 27 130\t loss: 1.767, accuracy: 0.806\n",
      "iteration 27 140\t loss: 1.592, accuracy: 0.819\n",
      "iteration 27 150\t loss: 1.634, accuracy: 0.820\n",
      "iteration 27 160\t loss: 1.676, accuracy: 0.823\n",
      "iteration 27 170\t loss: 1.827, accuracy: 0.797\n",
      "iteration 27 180\t loss: 1.474, accuracy: 0.813\n",
      "iteration 27 190\t loss: 1.725, accuracy: 0.815\n",
      "iteration 27 200\t loss: 1.777, accuracy: 0.819\n",
      "iteration 27 210\t loss: 1.695, accuracy: 0.822\n",
      "iteration 27 220\t loss: 1.588, accuracy: 0.824\n",
      "iteration 27 230\t loss: 1.524, accuracy: 0.822\n",
      "iteration 27 240\t loss: 1.609, accuracy: 0.820\n",
      "iteration 27 250\t loss: 1.565, accuracy: 0.825\n",
      "iteration 27 260\t loss: 1.661, accuracy: 0.827\n",
      "iteration 27 270\t loss: 1.616, accuracy: 0.825\n",
      "iteration 27 280\t loss: 1.587, accuracy: 0.814\n",
      "iteration 28 0\t loss: 1.608, accuracy: 0.823\n",
      "iteration 28 10\t loss: 1.592, accuracy: 0.826\n",
      "iteration 28 20\t loss: 1.660, accuracy: 0.819\n",
      "iteration 28 30\t loss: 2.232, accuracy: 0.795\n",
      "iteration 28 40\t loss: 1.778, accuracy: 0.793\n",
      "iteration 28 50\t loss: 1.746, accuracy: 0.822\n",
      "iteration 28 60\t loss: 1.693, accuracy: 0.808\n",
      "iteration 28 70\t loss: 1.692, accuracy: 0.816\n",
      "iteration 28 80\t loss: 1.747, accuracy: 0.820\n",
      "iteration 28 90\t loss: 1.639, accuracy: 0.820\n",
      "iteration 28 100\t loss: 1.504, accuracy: 0.819\n",
      "iteration 28 110\t loss: 1.527, accuracy: 0.826\n",
      "iteration 28 120\t loss: 1.554, accuracy: 0.825\n",
      "iteration 28 130\t loss: 1.825, accuracy: 0.816\n",
      "iteration 28 140\t loss: 1.616, accuracy: 0.822\n",
      "iteration 28 150\t loss: 1.727, accuracy: 0.821\n",
      "iteration 28 160\t loss: 1.656, accuracy: 0.827\n",
      "iteration 28 170\t loss: 1.847, accuracy: 0.798\n",
      "iteration 28 180\t loss: 1.615, accuracy: 0.801\n",
      "iteration 28 190\t loss: 1.728, accuracy: 0.814\n",
      "iteration 28 200\t loss: 1.968, accuracy: 0.814\n",
      "iteration 28 210\t loss: 1.784, accuracy: 0.823\n",
      "iteration 28 220\t loss: 1.692, accuracy: 0.824\n",
      "iteration 28 230\t loss: 1.612, accuracy: 0.825\n",
      "iteration 28 240\t loss: 1.604, accuracy: 0.825\n",
      "iteration 28 250\t loss: 1.741, accuracy: 0.820\n",
      "iteration 28 260\t loss: 1.657, accuracy: 0.827\n",
      "iteration 28 270\t loss: 1.655, accuracy: 0.818\n",
      "iteration 28 280\t loss: 1.740, accuracy: 0.822\n",
      "iteration 29 0\t loss: 1.653, accuracy: 0.822\n",
      "iteration 29 10\t loss: 1.765, accuracy: 0.819\n",
      "iteration 29 20\t loss: 1.841, accuracy: 0.809\n",
      "iteration 29 30\t loss: 2.193, accuracy: 0.808\n",
      "iteration 29 40\t loss: 1.958, accuracy: 0.777\n",
      "iteration 29 50\t loss: 1.938, accuracy: 0.814\n",
      "iteration 29 60\t loss: 1.872, accuracy: 0.810\n",
      "iteration 29 70\t loss: 1.791, accuracy: 0.808\n",
      "iteration 29 80\t loss: 1.933, accuracy: 0.815\n",
      "iteration 29 90\t loss: 1.727, accuracy: 0.823\n",
      "iteration 29 100\t loss: 1.518, accuracy: 0.829\n",
      "iteration 29 110\t loss: 1.573, accuracy: 0.831\n",
      "iteration 29 120\t loss: 1.638, accuracy: 0.820\n",
      "iteration 29 130\t loss: 1.945, accuracy: 0.807\n",
      "iteration 29 140\t loss: 1.612, accuracy: 0.820\n",
      "iteration 29 150\t loss: 1.833, accuracy: 0.821\n",
      "iteration 29 160\t loss: 1.749, accuracy: 0.827\n",
      "iteration 29 170\t loss: 1.934, accuracy: 0.799\n",
      "iteration 29 180\t loss: 1.637, accuracy: 0.818\n",
      "iteration 29 190\t loss: 1.792, accuracy: 0.806\n",
      "iteration 29 200\t loss: 2.041, accuracy: 0.805\n",
      "iteration 29 210\t loss: 1.920, accuracy: 0.824\n",
      "iteration 29 220\t loss: 1.699, accuracy: 0.829\n",
      "iteration 29 230\t loss: 1.567, accuracy: 0.824\n",
      "iteration 29 240\t loss: 1.558, accuracy: 0.830\n",
      "iteration 29 250\t loss: 1.741, accuracy: 0.824\n",
      "iteration 29 260\t loss: 1.675, accuracy: 0.830\n",
      "iteration 29 270\t loss: 1.795, accuracy: 0.819\n",
      "iteration 29 280\t loss: 1.641, accuracy: 0.825\n",
      "iteration 30 0\t loss: 1.704, accuracy: 0.825\n",
      "iteration 30 10\t loss: 1.793, accuracy: 0.825\n",
      "iteration 30 20\t loss: 1.681, accuracy: 0.823\n",
      "iteration 30 30\t loss: 2.210, accuracy: 0.797\n",
      "iteration 30 40\t loss: 1.960, accuracy: 0.767\n",
      "iteration 30 50\t loss: 1.831, accuracy: 0.817\n",
      "iteration 30 60\t loss: 1.884, accuracy: 0.819\n",
      "iteration 30 70\t loss: 1.839, accuracy: 0.812\n",
      "iteration 30 80\t loss: 1.815, accuracy: 0.814\n",
      "iteration 30 90\t loss: 1.794, accuracy: 0.817\n",
      "iteration 30 100\t loss: 1.567, accuracy: 0.829\n",
      "iteration 30 110\t loss: 1.693, accuracy: 0.824\n",
      "iteration 30 120\t loss: 1.626, accuracy: 0.827\n",
      "iteration 30 130\t loss: 1.961, accuracy: 0.810\n",
      "iteration 30 140\t loss: 1.736, accuracy: 0.816\n",
      "iteration 30 150\t loss: 1.807, accuracy: 0.824\n",
      "iteration 30 160\t loss: 1.982, accuracy: 0.819\n",
      "iteration 30 170\t loss: 1.961, accuracy: 0.796\n",
      "iteration 30 180\t loss: 1.795, accuracy: 0.805\n",
      "iteration 30 190\t loss: 1.842, accuracy: 0.812\n",
      "iteration 30 200\t loss: 2.170, accuracy: 0.802\n",
      "iteration 30 210\t loss: 1.835, accuracy: 0.825\n",
      "iteration 30 220\t loss: 1.801, accuracy: 0.829\n",
      "iteration 30 230\t loss: 1.731, accuracy: 0.828\n",
      "iteration 30 240\t loss: 1.678, accuracy: 0.834\n",
      "iteration 30 250\t loss: 1.777, accuracy: 0.831\n",
      "iteration 30 260\t loss: 1.721, accuracy: 0.832\n",
      "iteration 30 270\t loss: 1.859, accuracy: 0.818\n",
      "iteration 30 280\t loss: 1.699, accuracy: 0.826\n",
      "iteration 31 0\t loss: 1.828, accuracy: 0.823\n",
      "iteration 31 10\t loss: 1.823, accuracy: 0.831\n",
      "iteration 31 20\t loss: 1.855, accuracy: 0.828\n",
      "iteration 31 30\t loss: 2.221, accuracy: 0.813\n",
      "iteration 31 40\t loss: 1.953, accuracy: 0.798\n",
      "iteration 31 50\t loss: 1.944, accuracy: 0.820\n",
      "iteration 31 60\t loss: 1.810, accuracy: 0.821\n",
      "iteration 31 70\t loss: 1.874, accuracy: 0.812\n",
      "iteration 31 80\t loss: 2.144, accuracy: 0.810\n",
      "iteration 31 90\t loss: 1.952, accuracy: 0.823\n",
      "iteration 31 100\t loss: 1.610, accuracy: 0.829\n",
      "iteration 31 110\t loss: 1.811, accuracy: 0.824\n",
      "iteration 31 120\t loss: 1.772, accuracy: 0.823\n",
      "iteration 31 130\t loss: 2.127, accuracy: 0.806\n",
      "iteration 31 140\t loss: 1.996, accuracy: 0.813\n",
      "iteration 31 150\t loss: 1.918, accuracy: 0.818\n",
      "iteration 31 160\t loss: 2.061, accuracy: 0.825\n",
      "iteration 31 170\t loss: 2.174, accuracy: 0.808\n",
      "iteration 31 180\t loss: 2.050, accuracy: 0.797\n",
      "iteration 31 190\t loss: 1.864, accuracy: 0.811\n",
      "iteration 31 200\t loss: 2.094, accuracy: 0.802\n",
      "iteration 31 210\t loss: 1.870, accuracy: 0.818\n",
      "iteration 31 220\t loss: 2.062, accuracy: 0.818\n",
      "iteration 31 230\t loss: 1.835, accuracy: 0.824\n",
      "iteration 31 240\t loss: 1.858, accuracy: 0.831\n",
      "iteration 31 250\t loss: 2.031, accuracy: 0.825\n",
      "iteration 31 260\t loss: 1.981, accuracy: 0.830\n",
      "iteration 31 270\t loss: 2.122, accuracy: 0.822\n",
      "iteration 31 280\t loss: 1.828, accuracy: 0.829\n",
      "iteration 32 0\t loss: 1.831, accuracy: 0.826\n",
      "iteration 32 10\t loss: 1.857, accuracy: 0.830\n",
      "iteration 32 20\t loss: 1.891, accuracy: 0.830\n",
      "iteration 32 30\t loss: 2.123, accuracy: 0.810\n",
      "iteration 32 40\t loss: 2.092, accuracy: 0.799\n",
      "iteration 32 50\t loss: 1.989, accuracy: 0.819\n",
      "iteration 32 60\t loss: 1.915, accuracy: 0.821\n",
      "iteration 32 70\t loss: 1.911, accuracy: 0.823\n",
      "iteration 32 80\t loss: 2.066, accuracy: 0.815\n",
      "iteration 32 90\t loss: 1.953, accuracy: 0.822\n",
      "iteration 32 100\t loss: 1.765, accuracy: 0.824\n",
      "iteration 32 110\t loss: 1.821, accuracy: 0.824\n",
      "iteration 32 120\t loss: 1.782, accuracy: 0.829\n",
      "iteration 32 130\t loss: 2.144, accuracy: 0.809\n",
      "iteration 32 140\t loss: 1.971, accuracy: 0.814\n",
      "iteration 32 150\t loss: 1.997, accuracy: 0.815\n",
      "iteration 32 160\t loss: 2.153, accuracy: 0.823\n",
      "iteration 32 170\t loss: 2.191, accuracy: 0.808\n",
      "iteration 32 180\t loss: 2.209, accuracy: 0.791\n",
      "iteration 32 190\t loss: 1.829, accuracy: 0.814\n",
      "iteration 32 200\t loss: 2.313, accuracy: 0.807\n",
      "iteration 32 210\t loss: 1.926, accuracy: 0.811\n",
      "iteration 32 220\t loss: 2.076, accuracy: 0.818\n",
      "iteration 32 230\t loss: 1.843, accuracy: 0.826\n",
      "iteration 32 240\t loss: 1.853, accuracy: 0.828\n",
      "iteration 32 250\t loss: 2.116, accuracy: 0.826\n",
      "iteration 32 260\t loss: 2.087, accuracy: 0.828\n",
      "iteration 32 270\t loss: 2.048, accuracy: 0.828\n",
      "iteration 32 280\t loss: 1.857, accuracy: 0.830\n",
      "iteration 33 0\t loss: 1.867, accuracy: 0.829\n",
      "iteration 33 10\t loss: 2.027, accuracy: 0.828\n",
      "iteration 33 20\t loss: 1.996, accuracy: 0.831\n",
      "iteration 33 30\t loss: 2.279, accuracy: 0.818\n",
      "iteration 33 40\t loss: 2.285, accuracy: 0.799\n",
      "iteration 33 50\t loss: 2.197, accuracy: 0.808\n",
      "iteration 33 60\t loss: 2.062, accuracy: 0.815\n",
      "iteration 33 70\t loss: 2.051, accuracy: 0.816\n",
      "iteration 33 80\t loss: 2.286, accuracy: 0.813\n",
      "iteration 33 90\t loss: 2.220, accuracy: 0.814\n",
      "iteration 33 100\t loss: 1.898, accuracy: 0.821\n",
      "iteration 33 110\t loss: 1.867, accuracy: 0.822\n",
      "iteration 33 120\t loss: 1.879, accuracy: 0.827\n",
      "iteration 33 130\t loss: 2.040, accuracy: 0.813\n",
      "iteration 33 140\t loss: 2.045, accuracy: 0.814\n",
      "iteration 33 150\t loss: 2.061, accuracy: 0.811\n",
      "iteration 33 160\t loss: 2.208, accuracy: 0.813\n",
      "iteration 33 170\t loss: 2.259, accuracy: 0.805\n",
      "iteration 33 180\t loss: 2.441, accuracy: 0.789\n",
      "iteration 33 190\t loss: 1.838, accuracy: 0.825\n",
      "iteration 33 200\t loss: 2.340, accuracy: 0.805\n",
      "iteration 33 210\t loss: 1.919, accuracy: 0.811\n",
      "iteration 33 220\t loss: 2.228, accuracy: 0.815\n",
      "iteration 33 230\t loss: 2.024, accuracy: 0.831\n",
      "iteration 33 240\t loss: 1.877, accuracy: 0.825\n",
      "iteration 33 250\t loss: 2.157, accuracy: 0.825\n",
      "iteration 33 260\t loss: 2.221, accuracy: 0.826\n",
      "iteration 33 270\t loss: 2.141, accuracy: 0.830\n",
      "iteration 33 280\t loss: 1.938, accuracy: 0.830\n",
      "iteration 34 0\t loss: 1.815, accuracy: 0.825\n",
      "iteration 34 10\t loss: 1.934, accuracy: 0.831\n",
      "iteration 34 20\t loss: 2.112, accuracy: 0.830\n",
      "iteration 34 30\t loss: 2.193, accuracy: 0.825\n",
      "iteration 34 40\t loss: 2.234, accuracy: 0.817\n",
      "iteration 34 50\t loss: 2.192, accuracy: 0.794\n",
      "iteration 34 60\t loss: 2.264, accuracy: 0.810\n",
      "iteration 34 70\t loss: 1.958, accuracy: 0.819\n",
      "iteration 34 80\t loss: 2.303, accuracy: 0.817\n",
      "iteration 34 90\t loss: 2.017, accuracy: 0.820\n",
      "iteration 34 100\t loss: 1.946, accuracy: 0.820\n",
      "iteration 34 110\t loss: 1.925, accuracy: 0.823\n",
      "iteration 34 120\t loss: 2.002, accuracy: 0.827\n",
      "iteration 34 130\t loss: 2.104, accuracy: 0.820\n",
      "iteration 34 140\t loss: 2.080, accuracy: 0.821\n",
      "iteration 34 150\t loss: 1.985, accuracy: 0.820\n",
      "iteration 34 160\t loss: 2.341, accuracy: 0.817\n",
      "iteration 34 170\t loss: 2.432, accuracy: 0.808\n",
      "iteration 34 180\t loss: 2.333, accuracy: 0.795\n",
      "iteration 34 190\t loss: 2.074, accuracy: 0.821\n",
      "iteration 34 200\t loss: 2.441, accuracy: 0.807\n",
      "iteration 34 210\t loss: 2.211, accuracy: 0.815\n",
      "iteration 34 220\t loss: 2.208, accuracy: 0.817\n",
      "iteration 34 230\t loss: 2.259, accuracy: 0.828\n",
      "iteration 34 240\t loss: 2.143, accuracy: 0.821\n",
      "iteration 34 250\t loss: 2.323, accuracy: 0.823\n",
      "iteration 34 260\t loss: 2.276, accuracy: 0.824\n",
      "iteration 34 270\t loss: 2.375, accuracy: 0.830\n",
      "iteration 34 280\t loss: 2.066, accuracy: 0.832\n",
      "iteration 35 0\t loss: 2.008, accuracy: 0.828\n",
      "iteration 35 10\t loss: 2.087, accuracy: 0.826\n",
      "iteration 35 20\t loss: 2.201, accuracy: 0.831\n",
      "iteration 35 30\t loss: 2.288, accuracy: 0.829\n",
      "iteration 35 40\t loss: 2.296, accuracy: 0.821\n",
      "iteration 35 50\t loss: 2.233, accuracy: 0.817\n",
      "iteration 35 60\t loss: 2.373, accuracy: 0.818\n",
      "iteration 35 70\t loss: 2.082, accuracy: 0.817\n",
      "iteration 35 80\t loss: 2.362, accuracy: 0.819\n",
      "iteration 35 90\t loss: 2.224, accuracy: 0.821\n",
      "iteration 35 100\t loss: 1.915, accuracy: 0.830\n",
      "iteration 35 110\t loss: 1.973, accuracy: 0.827\n",
      "iteration 35 120\t loss: 2.033, accuracy: 0.826\n",
      "iteration 35 130\t loss: 2.111, accuracy: 0.823\n",
      "iteration 35 140\t loss: 2.067, accuracy: 0.832\n",
      "iteration 35 150\t loss: 1.987, accuracy: 0.825\n",
      "iteration 35 160\t loss: 2.143, accuracy: 0.817\n",
      "iteration 35 170\t loss: 2.476, accuracy: 0.812\n",
      "iteration 35 180\t loss: 2.577, accuracy: 0.789\n",
      "iteration 35 190\t loss: 2.148, accuracy: 0.818\n",
      "iteration 35 200\t loss: 2.293, accuracy: 0.810\n",
      "iteration 35 210\t loss: 2.327, accuracy: 0.809\n",
      "iteration 35 220\t loss: 2.205, accuracy: 0.814\n",
      "iteration 35 230\t loss: 2.312, accuracy: 0.823\n",
      "iteration 35 240\t loss: 2.115, accuracy: 0.826\n",
      "iteration 35 250\t loss: 2.226, accuracy: 0.826\n",
      "iteration 35 260\t loss: 2.323, accuracy: 0.828\n",
      "iteration 35 270\t loss: 2.404, accuracy: 0.829\n",
      "iteration 35 280\t loss: 2.324, accuracy: 0.832\n",
      "iteration 36 0\t loss: 2.016, accuracy: 0.831\n",
      "iteration 36 10\t loss: 2.020, accuracy: 0.833\n",
      "iteration 36 20\t loss: 2.430, accuracy: 0.828\n",
      "iteration 36 30\t loss: 2.372, accuracy: 0.829\n",
      "iteration 36 40\t loss: 2.144, accuracy: 0.826\n",
      "iteration 36 50\t loss: 2.253, accuracy: 0.822\n",
      "iteration 36 60\t loss: 2.322, accuracy: 0.826\n",
      "iteration 36 70\t loss: 2.291, accuracy: 0.821\n",
      "iteration 36 80\t loss: 2.307, accuracy: 0.824\n",
      "iteration 36 90\t loss: 2.327, accuracy: 0.823\n",
      "iteration 36 100\t loss: 2.028, accuracy: 0.826\n",
      "iteration 36 110\t loss: 2.084, accuracy: 0.823\n",
      "iteration 36 120\t loss: 2.093, accuracy: 0.817\n",
      "iteration 36 130\t loss: 2.255, accuracy: 0.833\n",
      "iteration 36 140\t loss: 2.272, accuracy: 0.823\n",
      "iteration 36 150\t loss: 2.232, accuracy: 0.823\n",
      "iteration 36 160\t loss: 2.294, accuracy: 0.819\n",
      "iteration 36 170\t loss: 2.438, accuracy: 0.823\n",
      "iteration 36 180\t loss: 2.832, accuracy: 0.789\n",
      "iteration 36 190\t loss: 2.327, accuracy: 0.814\n",
      "iteration 36 200\t loss: 2.540, accuracy: 0.805\n",
      "iteration 36 210\t loss: 2.554, accuracy: 0.818\n",
      "iteration 36 220\t loss: 2.340, accuracy: 0.814\n",
      "iteration 36 230\t loss: 2.331, accuracy: 0.825\n",
      "iteration 36 240\t loss: 2.086, accuracy: 0.826\n",
      "iteration 36 250\t loss: 2.319, accuracy: 0.832\n",
      "iteration 36 260\t loss: 2.531, accuracy: 0.825\n",
      "iteration 36 270\t loss: 2.558, accuracy: 0.825\n",
      "iteration 36 280\t loss: 2.357, accuracy: 0.826\n",
      "iteration 37 0\t loss: 2.198, accuracy: 0.830\n",
      "iteration 37 10\t loss: 2.199, accuracy: 0.834\n",
      "iteration 37 20\t loss: 2.319, accuracy: 0.829\n",
      "iteration 37 30\t loss: 2.396, accuracy: 0.829\n",
      "iteration 37 40\t loss: 2.416, accuracy: 0.827\n",
      "iteration 37 50\t loss: 2.436, accuracy: 0.819\n",
      "iteration 37 60\t loss: 2.256, accuracy: 0.821\n",
      "iteration 37 70\t loss: 2.272, accuracy: 0.819\n",
      "iteration 37 80\t loss: 2.490, accuracy: 0.815\n",
      "iteration 37 90\t loss: 2.685, accuracy: 0.819\n",
      "iteration 37 100\t loss: 2.180, accuracy: 0.824\n",
      "iteration 37 110\t loss: 2.351, accuracy: 0.820\n",
      "iteration 37 120\t loss: 2.186, accuracy: 0.820\n",
      "iteration 37 130\t loss: 2.300, accuracy: 0.831\n",
      "iteration 37 140\t loss: 2.386, accuracy: 0.824\n",
      "iteration 37 150\t loss: 2.234, accuracy: 0.824\n",
      "iteration 37 160\t loss: 2.320, accuracy: 0.824\n",
      "iteration 37 170\t loss: 2.442, accuracy: 0.819\n",
      "iteration 37 180\t loss: 3.023, accuracy: 0.786\n",
      "iteration 37 190\t loss: 2.249, accuracy: 0.810\n",
      "iteration 37 200\t loss: 2.327, accuracy: 0.818\n",
      "iteration 37 210\t loss: 2.638, accuracy: 0.815\n",
      "iteration 37 220\t loss: 2.228, accuracy: 0.827\n",
      "iteration 37 230\t loss: 2.400, accuracy: 0.816\n",
      "iteration 37 240\t loss: 2.152, accuracy: 0.825\n",
      "iteration 37 250\t loss: 2.373, accuracy: 0.828\n",
      "iteration 37 260\t loss: 2.588, accuracy: 0.823\n",
      "iteration 37 270\t loss: 2.537, accuracy: 0.831\n",
      "iteration 37 280\t loss: 2.436, accuracy: 0.831\n",
      "iteration 38 0\t loss: 2.281, accuracy: 0.831\n",
      "iteration 38 10\t loss: 2.218, accuracy: 0.836\n",
      "iteration 38 20\t loss: 2.375, accuracy: 0.836\n",
      "iteration 38 30\t loss: 2.659, accuracy: 0.825\n",
      "iteration 38 40\t loss: 2.507, accuracy: 0.821\n",
      "iteration 38 50\t loss: 2.423, accuracy: 0.827\n",
      "iteration 38 60\t loss: 2.456, accuracy: 0.824\n",
      "iteration 38 70\t loss: 2.236, accuracy: 0.826\n",
      "iteration 38 80\t loss: 2.482, accuracy: 0.821\n",
      "iteration 38 90\t loss: 2.610, accuracy: 0.825\n",
      "iteration 38 100\t loss: 2.257, accuracy: 0.830\n",
      "iteration 38 110\t loss: 2.207, accuracy: 0.826\n",
      "iteration 38 120\t loss: 2.230, accuracy: 0.826\n",
      "iteration 38 130\t loss: 2.318, accuracy: 0.831\n",
      "iteration 38 140\t loss: 2.758, accuracy: 0.822\n",
      "iteration 38 150\t loss: 2.285, accuracy: 0.823\n",
      "iteration 38 160\t loss: 2.474, accuracy: 0.824\n",
      "iteration 38 170\t loss: 2.496, accuracy: 0.827\n",
      "iteration 38 180\t loss: 2.814, accuracy: 0.796\n",
      "iteration 38 190\t loss: 2.608, accuracy: 0.810\n",
      "iteration 38 200\t loss: 2.335, accuracy: 0.810\n",
      "iteration 38 210\t loss: 2.713, accuracy: 0.813\n",
      "iteration 38 220\t loss: 2.382, accuracy: 0.825\n",
      "iteration 38 230\t loss: 2.439, accuracy: 0.828\n",
      "iteration 38 240\t loss: 2.299, accuracy: 0.824\n",
      "iteration 38 250\t loss: 2.329, accuracy: 0.829\n",
      "iteration 38 260\t loss: 2.412, accuracy: 0.821\n",
      "iteration 38 270\t loss: 2.497, accuracy: 0.833\n",
      "iteration 38 280\t loss: 2.325, accuracy: 0.832\n",
      "iteration 39 0\t loss: 2.215, accuracy: 0.833\n",
      "iteration 39 10\t loss: 2.393, accuracy: 0.831\n",
      "iteration 39 20\t loss: 2.448, accuracy: 0.832\n",
      "iteration 39 30\t loss: 2.552, accuracy: 0.827\n",
      "iteration 39 40\t loss: 2.470, accuracy: 0.821\n",
      "iteration 39 50\t loss: 2.690, accuracy: 0.822\n",
      "iteration 39 60\t loss: 2.753, accuracy: 0.819\n",
      "iteration 39 70\t loss: 2.582, accuracy: 0.822\n",
      "iteration 39 80\t loss: 2.631, accuracy: 0.815\n",
      "iteration 39 90\t loss: 2.401, accuracy: 0.825\n",
      "iteration 39 100\t loss: 2.304, accuracy: 0.831\n",
      "iteration 39 110\t loss: 2.291, accuracy: 0.829\n",
      "iteration 39 120\t loss: 2.389, accuracy: 0.827\n",
      "iteration 39 130\t loss: 2.243, accuracy: 0.827\n",
      "iteration 39 140\t loss: 2.660, accuracy: 0.815\n",
      "iteration 39 150\t loss: 2.538, accuracy: 0.819\n",
      "iteration 39 160\t loss: 2.364, accuracy: 0.820\n",
      "iteration 39 170\t loss: 2.571, accuracy: 0.819\n",
      "iteration 39 180\t loss: 2.865, accuracy: 0.780\n",
      "iteration 39 190\t loss: 2.742, accuracy: 0.809\n",
      "iteration 39 200\t loss: 2.571, accuracy: 0.814\n",
      "iteration 39 210\t loss: 2.843, accuracy: 0.806\n",
      "iteration 39 220\t loss: 2.281, accuracy: 0.825\n",
      "iteration 39 230\t loss: 2.338, accuracy: 0.827\n",
      "iteration 39 240\t loss: 2.389, accuracy: 0.825\n",
      "iteration 39 250\t loss: 2.625, accuracy: 0.822\n",
      "iteration 39 260\t loss: 2.518, accuracy: 0.815\n",
      "iteration 39 270\t loss: 2.753, accuracy: 0.825\n",
      "iteration 39 280\t loss: 2.737, accuracy: 0.827\n",
      "iteration 40 0\t loss: 2.351, accuracy: 0.831\n",
      "iteration 40 10\t loss: 2.285, accuracy: 0.826\n",
      "iteration 40 20\t loss: 2.532, accuracy: 0.826\n",
      "iteration 40 30\t loss: 2.728, accuracy: 0.825\n",
      "iteration 40 40\t loss: 2.715, accuracy: 0.827\n",
      "iteration 40 50\t loss: 2.489, accuracy: 0.824\n",
      "iteration 40 60\t loss: 2.667, accuracy: 0.818\n",
      "iteration 40 70\t loss: 2.572, accuracy: 0.824\n",
      "iteration 40 80\t loss: 2.413, accuracy: 0.821\n",
      "iteration 40 90\t loss: 2.504, accuracy: 0.819\n",
      "iteration 40 100\t loss: 2.447, accuracy: 0.823\n",
      "iteration 40 110\t loss: 2.327, accuracy: 0.825\n",
      "iteration 40 120\t loss: 2.512, accuracy: 0.823\n",
      "iteration 40 130\t loss: 2.239, accuracy: 0.824\n",
      "iteration 40 140\t loss: 2.717, accuracy: 0.813\n",
      "iteration 40 150\t loss: 2.657, accuracy: 0.815\n",
      "iteration 40 160\t loss: 2.494, accuracy: 0.820\n",
      "iteration 40 170\t loss: 2.782, accuracy: 0.823\n",
      "iteration 40 180\t loss: 2.977, accuracy: 0.800\n",
      "iteration 40 190\t loss: 2.868, accuracy: 0.808\n",
      "iteration 40 200\t loss: 2.347, accuracy: 0.813\n",
      "iteration 40 210\t loss: 2.894, accuracy: 0.803\n",
      "iteration 40 220\t loss: 2.465, accuracy: 0.819\n",
      "iteration 40 230\t loss: 2.477, accuracy: 0.818\n",
      "iteration 40 240\t loss: 2.407, accuracy: 0.833\n",
      "iteration 40 250\t loss: 2.522, accuracy: 0.828\n",
      "iteration 40 260\t loss: 2.778, accuracy: 0.823\n",
      "iteration 40 270\t loss: 2.606, accuracy: 0.814\n",
      "iteration 40 280\t loss: 2.931, accuracy: 0.822\n",
      "iteration 41 0\t loss: 2.601, accuracy: 0.830\n",
      "iteration 41 10\t loss: 2.620, accuracy: 0.827\n",
      "iteration 41 20\t loss: 2.616, accuracy: 0.830\n",
      "iteration 41 30\t loss: 2.901, accuracy: 0.826\n",
      "iteration 41 40\t loss: 3.056, accuracy: 0.822\n",
      "iteration 41 50\t loss: 2.597, accuracy: 0.823\n",
      "iteration 41 60\t loss: 2.905, accuracy: 0.817\n",
      "iteration 41 70\t loss: 2.717, accuracy: 0.825\n",
      "iteration 41 80\t loss: 2.692, accuracy: 0.822\n",
      "iteration 41 90\t loss: 2.805, accuracy: 0.815\n",
      "iteration 41 100\t loss: 2.450, accuracy: 0.826\n",
      "iteration 41 110\t loss: 2.365, accuracy: 0.822\n",
      "iteration 41 120\t loss: 2.629, accuracy: 0.821\n",
      "iteration 41 130\t loss: 2.394, accuracy: 0.815\n",
      "iteration 41 140\t loss: 3.091, accuracy: 0.805\n",
      "iteration 41 150\t loss: 2.703, accuracy: 0.826\n",
      "iteration 41 160\t loss: 2.566, accuracy: 0.820\n",
      "iteration 41 170\t loss: 3.052, accuracy: 0.812\n",
      "iteration 41 180\t loss: 3.016, accuracy: 0.806\n",
      "iteration 41 190\t loss: 2.818, accuracy: 0.819\n",
      "iteration 41 200\t loss: 2.580, accuracy: 0.812\n",
      "iteration 41 210\t loss: 2.743, accuracy: 0.811\n",
      "iteration 41 220\t loss: 2.660, accuracy: 0.826\n",
      "iteration 41 230\t loss: 2.723, accuracy: 0.819\n",
      "iteration 41 240\t loss: 2.465, accuracy: 0.826\n",
      "iteration 41 250\t loss: 2.610, accuracy: 0.826\n",
      "iteration 41 260\t loss: 2.693, accuracy: 0.831\n",
      "iteration 41 270\t loss: 2.689, accuracy: 0.833\n",
      "iteration 41 280\t loss: 2.833, accuracy: 0.827\n",
      "iteration 42 0\t loss: 2.632, accuracy: 0.831\n",
      "iteration 42 10\t loss: 2.650, accuracy: 0.835\n",
      "iteration 42 20\t loss: 2.760, accuracy: 0.836\n",
      "iteration 42 30\t loss: 3.102, accuracy: 0.824\n",
      "iteration 42 40\t loss: 2.904, accuracy: 0.826\n",
      "iteration 42 50\t loss: 2.528, accuracy: 0.830\n",
      "iteration 42 60\t loss: 2.681, accuracy: 0.828\n",
      "iteration 42 70\t loss: 2.802, accuracy: 0.819\n",
      "iteration 42 80\t loss: 2.781, accuracy: 0.824\n",
      "iteration 42 90\t loss: 2.817, accuracy: 0.823\n",
      "iteration 42 100\t loss: 2.615, accuracy: 0.822\n",
      "iteration 42 110\t loss: 2.454, accuracy: 0.827\n",
      "iteration 42 120\t loss: 2.582, accuracy: 0.826\n",
      "iteration 42 130\t loss: 2.529, accuracy: 0.826\n",
      "iteration 42 140\t loss: 2.663, accuracy: 0.830\n",
      "iteration 42 150\t loss: 2.572, accuracy: 0.831\n",
      "iteration 42 160\t loss: 2.538, accuracy: 0.829\n",
      "iteration 42 170\t loss: 2.915, accuracy: 0.820\n",
      "iteration 42 180\t loss: 3.105, accuracy: 0.795\n",
      "iteration 42 190\t loss: 2.976, accuracy: 0.812\n",
      "iteration 42 200\t loss: 2.446, accuracy: 0.812\n",
      "iteration 42 210\t loss: 2.567, accuracy: 0.818\n",
      "iteration 42 220\t loss: 2.808, accuracy: 0.821\n",
      "iteration 42 230\t loss: 2.516, accuracy: 0.826\n",
      "iteration 42 240\t loss: 2.560, accuracy: 0.833\n",
      "iteration 42 250\t loss: 2.759, accuracy: 0.834\n",
      "iteration 42 260\t loss: 2.823, accuracy: 0.833\n",
      "iteration 42 270\t loss: 2.794, accuracy: 0.827\n",
      "iteration 42 280\t loss: 2.919, accuracy: 0.832\n",
      "iteration 43 0\t loss: 2.839, accuracy: 0.830\n",
      "iteration 43 10\t loss: 2.730, accuracy: 0.834\n",
      "iteration 43 20\t loss: 2.835, accuracy: 0.834\n",
      "iteration 43 30\t loss: 2.796, accuracy: 0.841\n",
      "iteration 43 40\t loss: 2.956, accuracy: 0.830\n",
      "iteration 43 50\t loss: 2.932, accuracy: 0.817\n",
      "iteration 43 60\t loss: 2.998, accuracy: 0.813\n",
      "iteration 43 70\t loss: 2.976, accuracy: 0.823\n",
      "iteration 43 80\t loss: 2.729, accuracy: 0.825\n",
      "iteration 43 90\t loss: 2.689, accuracy: 0.821\n",
      "iteration 43 100\t loss: 2.685, accuracy: 0.822\n",
      "iteration 43 110\t loss: 2.455, accuracy: 0.827\n",
      "iteration 43 120\t loss: 2.791, accuracy: 0.820\n",
      "iteration 43 130\t loss: 2.562, accuracy: 0.831\n",
      "iteration 43 140\t loss: 2.827, accuracy: 0.829\n",
      "iteration 43 150\t loss: 2.844, accuracy: 0.830\n",
      "iteration 43 160\t loss: 2.677, accuracy: 0.824\n",
      "iteration 43 170\t loss: 3.141, accuracy: 0.812\n",
      "iteration 43 180\t loss: 3.067, accuracy: 0.802\n",
      "iteration 43 190\t loss: 3.227, accuracy: 0.802\n",
      "iteration 43 200\t loss: 2.633, accuracy: 0.815\n",
      "iteration 43 210\t loss: 2.853, accuracy: 0.816\n",
      "iteration 43 220\t loss: 2.972, accuracy: 0.816\n",
      "iteration 43 230\t loss: 2.748, accuracy: 0.827\n",
      "iteration 43 240\t loss: 2.729, accuracy: 0.828\n",
      "iteration 43 250\t loss: 2.722, accuracy: 0.831\n",
      "iteration 43 260\t loss: 2.916, accuracy: 0.828\n",
      "iteration 43 270\t loss: 2.796, accuracy: 0.830\n",
      "iteration 43 280\t loss: 2.819, accuracy: 0.833\n",
      "iteration 44 0\t loss: 2.828, accuracy: 0.828\n",
      "iteration 44 10\t loss: 2.784, accuracy: 0.822\n",
      "iteration 44 20\t loss: 2.768, accuracy: 0.834\n",
      "iteration 44 30\t loss: 2.864, accuracy: 0.831\n",
      "iteration 44 40\t loss: 2.889, accuracy: 0.830\n",
      "iteration 44 50\t loss: 2.717, accuracy: 0.826\n",
      "iteration 44 60\t loss: 2.790, accuracy: 0.832\n",
      "iteration 44 70\t loss: 3.044, accuracy: 0.820\n",
      "iteration 44 80\t loss: 2.889, accuracy: 0.820\n",
      "iteration 44 90\t loss: 2.863, accuracy: 0.823\n",
      "iteration 44 100\t loss: 2.705, accuracy: 0.823\n",
      "iteration 44 110\t loss: 2.557, accuracy: 0.822\n",
      "iteration 44 120\t loss: 2.937, accuracy: 0.822\n",
      "iteration 44 130\t loss: 2.799, accuracy: 0.820\n",
      "iteration 44 140\t loss: 2.782, accuracy: 0.826\n",
      "iteration 44 150\t loss: 2.919, accuracy: 0.822\n",
      "iteration 44 160\t loss: 2.959, accuracy: 0.818\n",
      "iteration 44 170\t loss: 3.039, accuracy: 0.825\n",
      "iteration 44 180\t loss: 3.271, accuracy: 0.806\n",
      "iteration 44 190\t loss: 3.058, accuracy: 0.815\n",
      "iteration 44 200\t loss: 2.757, accuracy: 0.819\n",
      "iteration 44 210\t loss: 2.921, accuracy: 0.818\n",
      "iteration 44 220\t loss: 3.100, accuracy: 0.812\n",
      "iteration 44 230\t loss: 2.701, accuracy: 0.820\n",
      "iteration 44 240\t loss: 2.505, accuracy: 0.832\n",
      "iteration 44 250\t loss: 2.735, accuracy: 0.833\n",
      "iteration 44 260\t loss: 3.074, accuracy: 0.830\n",
      "iteration 44 270\t loss: 2.859, accuracy: 0.830\n",
      "iteration 44 280\t loss: 2.911, accuracy: 0.832\n",
      "iteration 45 0\t loss: 2.882, accuracy: 0.836\n",
      "iteration 45 10\t loss: 2.766, accuracy: 0.827\n",
      "iteration 45 20\t loss: 3.016, accuracy: 0.830\n",
      "iteration 45 30\t loss: 3.084, accuracy: 0.833\n",
      "iteration 45 40\t loss: 2.992, accuracy: 0.832\n",
      "iteration 45 50\t loss: 2.865, accuracy: 0.829\n",
      "iteration 45 60\t loss: 2.769, accuracy: 0.827\n",
      "iteration 45 70\t loss: 3.213, accuracy: 0.819\n",
      "iteration 45 80\t loss: 2.963, accuracy: 0.822\n",
      "iteration 45 90\t loss: 2.945, accuracy: 0.825\n",
      "iteration 45 100\t loss: 2.855, accuracy: 0.824\n",
      "iteration 45 110\t loss: 2.662, accuracy: 0.820\n",
      "iteration 45 120\t loss: 2.994, accuracy: 0.824\n",
      "iteration 45 130\t loss: 2.828, accuracy: 0.821\n",
      "iteration 45 140\t loss: 2.739, accuracy: 0.829\n",
      "iteration 45 150\t loss: 2.917, accuracy: 0.828\n",
      "iteration 45 160\t loss: 2.783, accuracy: 0.826\n",
      "iteration 45 170\t loss: 3.189, accuracy: 0.829\n",
      "iteration 45 180\t loss: 3.217, accuracy: 0.800\n",
      "iteration 45 190\t loss: 3.099, accuracy: 0.815\n",
      "iteration 45 200\t loss: 2.777, accuracy: 0.825\n",
      "iteration 45 210\t loss: 3.050, accuracy: 0.813\n",
      "iteration 45 220\t loss: 3.001, accuracy: 0.807\n",
      "iteration 45 230\t loss: 2.966, accuracy: 0.822\n",
      "iteration 45 240\t loss: 2.697, accuracy: 0.825\n",
      "iteration 45 250\t loss: 2.926, accuracy: 0.830\n",
      "iteration 45 260\t loss: 3.269, accuracy: 0.832\n",
      "iteration 45 270\t loss: 3.168, accuracy: 0.830\n",
      "iteration 45 280\t loss: 3.133, accuracy: 0.833\n",
      "iteration 46 0\t loss: 2.966, accuracy: 0.837\n",
      "iteration 46 10\t loss: 2.963, accuracy: 0.832\n",
      "iteration 46 20\t loss: 3.123, accuracy: 0.834\n",
      "iteration 46 30\t loss: 3.409, accuracy: 0.827\n",
      "iteration 46 40\t loss: 3.391, accuracy: 0.832\n",
      "iteration 46 50\t loss: 3.076, accuracy: 0.827\n",
      "iteration 46 60\t loss: 3.035, accuracy: 0.826\n",
      "iteration 46 70\t loss: 3.010, accuracy: 0.818\n",
      "iteration 46 80\t loss: 3.188, accuracy: 0.818\n",
      "iteration 46 90\t loss: 3.238, accuracy: 0.818\n",
      "iteration 46 100\t loss: 2.764, accuracy: 0.827\n",
      "iteration 46 110\t loss: 2.682, accuracy: 0.822\n",
      "iteration 46 120\t loss: 3.094, accuracy: 0.812\n",
      "iteration 46 130\t loss: 2.984, accuracy: 0.814\n",
      "iteration 46 140\t loss: 3.077, accuracy: 0.827\n",
      "iteration 46 150\t loss: 3.335, accuracy: 0.822\n",
      "iteration 46 160\t loss: 2.992, accuracy: 0.817\n",
      "iteration 46 170\t loss: 3.233, accuracy: 0.821\n",
      "iteration 46 180\t loss: 3.333, accuracy: 0.811\n",
      "iteration 46 190\t loss: 3.363, accuracy: 0.813\n",
      "iteration 46 200\t loss: 2.753, accuracy: 0.818\n",
      "iteration 46 210\t loss: 2.964, accuracy: 0.822\n",
      "iteration 46 220\t loss: 3.081, accuracy: 0.817\n",
      "iteration 46 230\t loss: 2.852, accuracy: 0.825\n",
      "iteration 46 240\t loss: 2.786, accuracy: 0.828\n",
      "iteration 46 250\t loss: 2.889, accuracy: 0.835\n",
      "iteration 46 260\t loss: 3.390, accuracy: 0.833\n",
      "iteration 46 270\t loss: 3.299, accuracy: 0.829\n",
      "iteration 46 280\t loss: 3.217, accuracy: 0.833\n",
      "iteration 47 0\t loss: 3.437, accuracy: 0.830\n",
      "iteration 47 10\t loss: 3.379, accuracy: 0.827\n",
      "iteration 47 20\t loss: 2.960, accuracy: 0.831\n",
      "iteration 47 30\t loss: 3.205, accuracy: 0.831\n",
      "iteration 47 40\t loss: 3.307, accuracy: 0.828\n",
      "iteration 47 50\t loss: 3.089, accuracy: 0.832\n",
      "iteration 47 60\t loss: 3.035, accuracy: 0.823\n",
      "iteration 47 70\t loss: 3.088, accuracy: 0.822\n",
      "iteration 47 80\t loss: 3.168, accuracy: 0.814\n",
      "iteration 47 90\t loss: 3.027, accuracy: 0.818\n",
      "iteration 47 100\t loss: 2.974, accuracy: 0.824\n",
      "iteration 47 110\t loss: 2.673, accuracy: 0.821\n",
      "iteration 47 120\t loss: 2.995, accuracy: 0.813\n",
      "iteration 47 130\t loss: 2.995, accuracy: 0.814\n",
      "iteration 47 140\t loss: 2.847, accuracy: 0.830\n",
      "iteration 47 150\t loss: 3.236, accuracy: 0.823\n",
      "iteration 47 160\t loss: 3.200, accuracy: 0.823\n",
      "iteration 47 170\t loss: 3.034, accuracy: 0.831\n",
      "iteration 47 180\t loss: 3.379, accuracy: 0.818\n",
      "iteration 47 190\t loss: 3.254, accuracy: 0.807\n",
      "iteration 47 200\t loss: 3.060, accuracy: 0.810\n",
      "iteration 47 210\t loss: 3.287, accuracy: 0.811\n",
      "iteration 47 220\t loss: 2.882, accuracy: 0.818\n",
      "iteration 47 230\t loss: 2.927, accuracy: 0.835\n",
      "iteration 47 240\t loss: 2.883, accuracy: 0.834\n",
      "iteration 47 250\t loss: 3.021, accuracy: 0.830\n",
      "iteration 47 260\t loss: 3.106, accuracy: 0.835\n",
      "iteration 47 270\t loss: 3.199, accuracy: 0.833\n",
      "iteration 47 280\t loss: 3.473, accuracy: 0.834\n",
      "iteration 48 0\t loss: 3.134, accuracy: 0.837\n",
      "iteration 48 10\t loss: 3.153, accuracy: 0.835\n",
      "iteration 48 20\t loss: 3.377, accuracy: 0.832\n",
      "iteration 48 30\t loss: 3.285, accuracy: 0.829\n",
      "iteration 48 40\t loss: 3.219, accuracy: 0.832\n",
      "iteration 48 50\t loss: 3.019, accuracy: 0.825\n",
      "iteration 48 60\t loss: 3.116, accuracy: 0.822\n",
      "iteration 48 70\t loss: 3.170, accuracy: 0.820\n",
      "iteration 48 80\t loss: 3.264, accuracy: 0.823\n",
      "iteration 48 90\t loss: 2.990, accuracy: 0.822\n",
      "iteration 48 100\t loss: 3.048, accuracy: 0.830\n",
      "iteration 48 110\t loss: 2.839, accuracy: 0.825\n",
      "iteration 48 120\t loss: 2.888, accuracy: 0.823\n",
      "iteration 48 130\t loss: 3.136, accuracy: 0.819\n",
      "iteration 48 140\t loss: 2.792, accuracy: 0.818\n",
      "iteration 48 150\t loss: 3.276, accuracy: 0.818\n",
      "iteration 48 160\t loss: 3.230, accuracy: 0.822\n",
      "iteration 48 170\t loss: 3.354, accuracy: 0.826\n",
      "iteration 48 180\t loss: 3.515, accuracy: 0.817\n",
      "iteration 48 190\t loss: 3.229, accuracy: 0.804\n",
      "iteration 48 200\t loss: 3.237, accuracy: 0.819\n",
      "iteration 48 210\t loss: 2.840, accuracy: 0.828\n",
      "iteration 48 220\t loss: 3.099, accuracy: 0.833\n",
      "iteration 48 230\t loss: 2.989, accuracy: 0.837\n",
      "iteration 48 240\t loss: 3.074, accuracy: 0.834\n",
      "iteration 48 250\t loss: 3.130, accuracy: 0.836\n",
      "iteration 48 260\t loss: 3.460, accuracy: 0.833\n",
      "iteration 48 270\t loss: 3.434, accuracy: 0.837\n",
      "iteration 48 280\t loss: 3.311, accuracy: 0.836\n",
      "iteration 49 0\t loss: 3.277, accuracy: 0.842\n",
      "iteration 49 10\t loss: 3.189, accuracy: 0.843\n",
      "iteration 49 20\t loss: 3.270, accuracy: 0.834\n",
      "iteration 49 30\t loss: 3.716, accuracy: 0.830\n",
      "iteration 49 40\t loss: 3.534, accuracy: 0.831\n",
      "iteration 49 50\t loss: 3.420, accuracy: 0.830\n",
      "iteration 49 60\t loss: 3.189, accuracy: 0.831\n",
      "iteration 49 70\t loss: 3.220, accuracy: 0.828\n",
      "iteration 49 80\t loss: 3.135, accuracy: 0.829\n",
      "iteration 49 90\t loss: 3.072, accuracy: 0.833\n",
      "iteration 49 100\t loss: 3.282, accuracy: 0.826\n",
      "iteration 49 110\t loss: 2.796, accuracy: 0.827\n",
      "iteration 49 120\t loss: 2.927, accuracy: 0.831\n",
      "iteration 49 130\t loss: 3.114, accuracy: 0.823\n",
      "iteration 49 140\t loss: 2.856, accuracy: 0.822\n",
      "iteration 49 150\t loss: 2.841, accuracy: 0.829\n",
      "iteration 49 160\t loss: 3.241, accuracy: 0.820\n",
      "iteration 49 170\t loss: 3.390, accuracy: 0.826\n",
      "iteration 49 180\t loss: 3.475, accuracy: 0.826\n",
      "iteration 49 190\t loss: 3.235, accuracy: 0.815\n",
      "iteration 49 200\t loss: 3.447, accuracy: 0.823\n",
      "iteration 49 210\t loss: 3.143, accuracy: 0.823\n",
      "iteration 49 220\t loss: 2.976, accuracy: 0.817\n",
      "iteration 49 230\t loss: 3.233, accuracy: 0.829\n",
      "iteration 49 240\t loss: 3.151, accuracy: 0.828\n",
      "iteration 49 250\t loss: 3.156, accuracy: 0.830\n",
      "iteration 49 260\t loss: 3.496, accuracy: 0.832\n",
      "iteration 49 270\t loss: 3.308, accuracy: 0.836\n",
      "iteration 49 280\t loss: 3.319, accuracy: 0.829\n",
      "iteration 50 0\t loss: 3.403, accuracy: 0.835\n",
      "iteration 50 10\t loss: 3.374, accuracy: 0.836\n",
      "iteration 50 20\t loss: 3.194, accuracy: 0.833\n",
      "iteration 50 30\t loss: 3.487, accuracy: 0.827\n",
      "iteration 50 40\t loss: 3.356, accuracy: 0.832\n",
      "iteration 50 50\t loss: 3.136, accuracy: 0.832\n",
      "iteration 50 60\t loss: 3.148, accuracy: 0.825\n",
      "iteration 50 70\t loss: 3.171, accuracy: 0.827\n",
      "iteration 50 80\t loss: 3.214, accuracy: 0.829\n",
      "iteration 50 90\t loss: 3.082, accuracy: 0.834\n",
      "iteration 50 100\t loss: 3.218, accuracy: 0.830\n",
      "iteration 50 110\t loss: 2.777, accuracy: 0.821\n",
      "iteration 50 120\t loss: 2.939, accuracy: 0.833\n",
      "iteration 50 130\t loss: 3.276, accuracy: 0.825\n",
      "iteration 50 140\t loss: 3.124, accuracy: 0.824\n",
      "iteration 50 150\t loss: 3.088, accuracy: 0.823\n",
      "iteration 50 160\t loss: 3.122, accuracy: 0.824\n",
      "iteration 50 170\t loss: 3.280, accuracy: 0.835\n",
      "iteration 50 180\t loss: 3.598, accuracy: 0.817\n",
      "iteration 50 190\t loss: 3.420, accuracy: 0.800\n",
      "iteration 50 200\t loss: 3.291, accuracy: 0.822\n",
      "iteration 50 210\t loss: 3.171, accuracy: 0.826\n",
      "iteration 50 220\t loss: 3.215, accuracy: 0.825\n",
      "iteration 50 230\t loss: 2.956, accuracy: 0.830\n",
      "iteration 50 240\t loss: 3.119, accuracy: 0.835\n",
      "iteration 50 250\t loss: 3.321, accuracy: 0.835\n",
      "iteration 50 260\t loss: 3.605, accuracy: 0.829\n",
      "iteration 50 270\t loss: 3.253, accuracy: 0.842\n",
      "iteration 50 280\t loss: 3.363, accuracy: 0.841\n",
      "iteration 51 0\t loss: 3.351, accuracy: 0.839\n",
      "iteration 51 10\t loss: 3.263, accuracy: 0.841\n",
      "iteration 51 20\t loss: 3.348, accuracy: 0.834\n",
      "iteration 51 30\t loss: 3.682, accuracy: 0.827\n",
      "iteration 51 40\t loss: 3.517, accuracy: 0.834\n",
      "iteration 51 50\t loss: 3.456, accuracy: 0.823\n",
      "iteration 51 60\t loss: 3.445, accuracy: 0.831\n",
      "iteration 51 70\t loss: 3.332, accuracy: 0.828\n",
      "iteration 51 80\t loss: 3.513, accuracy: 0.832\n",
      "iteration 51 90\t loss: 3.176, accuracy: 0.831\n",
      "iteration 51 100\t loss: 3.076, accuracy: 0.835\n",
      "iteration 51 110\t loss: 3.138, accuracy: 0.831\n",
      "iteration 51 120\t loss: 2.947, accuracy: 0.836\n",
      "iteration 51 130\t loss: 3.093, accuracy: 0.832\n",
      "iteration 51 140\t loss: 2.928, accuracy: 0.831\n",
      "iteration 51 150\t loss: 3.409, accuracy: 0.830\n",
      "iteration 51 160\t loss: 3.365, accuracy: 0.821\n",
      "iteration 51 170\t loss: 3.402, accuracy: 0.827\n",
      "iteration 51 180\t loss: 3.530, accuracy: 0.817\n",
      "iteration 51 190\t loss: 3.649, accuracy: 0.799\n",
      "iteration 51 200\t loss: 3.223, accuracy: 0.811\n",
      "iteration 51 210\t loss: 3.454, accuracy: 0.823\n",
      "iteration 51 220\t loss: 3.298, accuracy: 0.815\n",
      "iteration 51 230\t loss: 3.036, accuracy: 0.832\n",
      "iteration 51 240\t loss: 3.162, accuracy: 0.833\n",
      "iteration 51 250\t loss: 3.325, accuracy: 0.840\n",
      "iteration 51 260\t loss: 3.738, accuracy: 0.832\n",
      "iteration 51 270\t loss: 3.555, accuracy: 0.839\n",
      "iteration 51 280\t loss: 3.587, accuracy: 0.836\n",
      "iteration 52 0\t loss: 3.559, accuracy: 0.838\n",
      "iteration 52 10\t loss: 3.380, accuracy: 0.838\n",
      "iteration 52 20\t loss: 3.278, accuracy: 0.838\n",
      "iteration 52 30\t loss: 3.769, accuracy: 0.827\n",
      "iteration 52 40\t loss: 3.882, accuracy: 0.824\n",
      "iteration 52 50\t loss: 3.187, accuracy: 0.825\n",
      "iteration 52 60\t loss: 3.436, accuracy: 0.830\n",
      "iteration 52 70\t loss: 3.388, accuracy: 0.830\n",
      "iteration 52 80\t loss: 3.442, accuracy: 0.825\n",
      "iteration 52 90\t loss: 3.461, accuracy: 0.833\n",
      "iteration 52 100\t loss: 3.356, accuracy: 0.830\n",
      "iteration 52 110\t loss: 3.270, accuracy: 0.836\n",
      "iteration 52 120\t loss: 3.035, accuracy: 0.835\n",
      "iteration 52 130\t loss: 3.339, accuracy: 0.829\n",
      "iteration 52 140\t loss: 3.070, accuracy: 0.827\n",
      "iteration 52 150\t loss: 3.229, accuracy: 0.831\n",
      "iteration 52 160\t loss: 3.362, accuracy: 0.828\n",
      "iteration 52 170\t loss: 3.606, accuracy: 0.824\n",
      "iteration 52 180\t loss: 3.504, accuracy: 0.819\n",
      "iteration 52 190\t loss: 3.729, accuracy: 0.792\n",
      "iteration 52 200\t loss: 3.390, accuracy: 0.830\n",
      "iteration 52 210\t loss: 3.667, accuracy: 0.817\n",
      "iteration 52 220\t loss: 3.396, accuracy: 0.821\n",
      "iteration 52 230\t loss: 3.184, accuracy: 0.826\n",
      "iteration 52 240\t loss: 3.190, accuracy: 0.827\n",
      "iteration 52 250\t loss: 3.289, accuracy: 0.839\n",
      "iteration 52 260\t loss: 3.732, accuracy: 0.832\n",
      "iteration 52 270\t loss: 3.724, accuracy: 0.838\n",
      "iteration 52 280\t loss: 3.748, accuracy: 0.835\n",
      "iteration 53 0\t loss: 3.593, accuracy: 0.838\n",
      "iteration 53 10\t loss: 3.594, accuracy: 0.838\n",
      "iteration 53 20\t loss: 3.577, accuracy: 0.837\n",
      "iteration 53 30\t loss: 3.504, accuracy: 0.836\n",
      "iteration 53 40\t loss: 3.944, accuracy: 0.828\n",
      "iteration 53 50\t loss: 3.517, accuracy: 0.823\n",
      "iteration 53 60\t loss: 3.366, accuracy: 0.830\n",
      "iteration 53 70\t loss: 3.496, accuracy: 0.822\n",
      "iteration 53 80\t loss: 3.455, accuracy: 0.828\n",
      "iteration 53 90\t loss: 3.447, accuracy: 0.828\n",
      "iteration 53 100\t loss: 3.561, accuracy: 0.831\n",
      "iteration 53 110\t loss: 3.253, accuracy: 0.834\n",
      "iteration 53 120\t loss: 3.309, accuracy: 0.830\n",
      "iteration 53 130\t loss: 3.553, accuracy: 0.830\n",
      "iteration 53 140\t loss: 3.096, accuracy: 0.833\n",
      "iteration 53 150\t loss: 3.208, accuracy: 0.832\n",
      "iteration 53 160\t loss: 3.580, accuracy: 0.824\n",
      "iteration 53 170\t loss: 3.878, accuracy: 0.825\n",
      "iteration 53 180\t loss: 3.766, accuracy: 0.830\n",
      "iteration 53 190\t loss: 4.148, accuracy: 0.775\n",
      "iteration 53 200\t loss: 3.705, accuracy: 0.820\n",
      "iteration 53 210\t loss: 3.451, accuracy: 0.821\n",
      "iteration 53 220\t loss: 3.317, accuracy: 0.823\n",
      "iteration 53 230\t loss: 3.162, accuracy: 0.834\n",
      "iteration 53 240\t loss: 3.274, accuracy: 0.829\n",
      "iteration 53 250\t loss: 3.368, accuracy: 0.838\n",
      "iteration 53 260\t loss: 3.605, accuracy: 0.833\n",
      "iteration 53 270\t loss: 3.532, accuracy: 0.838\n",
      "iteration 53 280\t loss: 3.604, accuracy: 0.834\n",
      "iteration 54 0\t loss: 3.696, accuracy: 0.841\n",
      "iteration 54 10\t loss: 3.557, accuracy: 0.837\n",
      "iteration 54 20\t loss: 3.650, accuracy: 0.835\n",
      "iteration 54 30\t loss: 3.953, accuracy: 0.830\n",
      "iteration 54 40\t loss: 3.914, accuracy: 0.830\n",
      "iteration 54 50\t loss: 3.557, accuracy: 0.828\n",
      "iteration 54 60\t loss: 3.513, accuracy: 0.834\n",
      "iteration 54 70\t loss: 3.616, accuracy: 0.827\n",
      "iteration 54 80\t loss: 3.467, accuracy: 0.826\n",
      "iteration 54 90\t loss: 3.459, accuracy: 0.830\n",
      "iteration 54 100\t loss: 3.784, accuracy: 0.835\n",
      "iteration 54 110\t loss: 3.238, accuracy: 0.831\n",
      "iteration 54 120\t loss: 3.219, accuracy: 0.834\n",
      "iteration 54 130\t loss: 3.363, accuracy: 0.841\n",
      "iteration 54 140\t loss: 3.343, accuracy: 0.834\n",
      "iteration 54 150\t loss: 3.300, accuracy: 0.832\n",
      "iteration 54 160\t loss: 3.378, accuracy: 0.833\n",
      "iteration 54 170\t loss: 3.706, accuracy: 0.831\n",
      "iteration 54 180\t loss: 3.765, accuracy: 0.833\n",
      "iteration 54 190\t loss: 3.981, accuracy: 0.796\n",
      "iteration 54 200\t loss: 3.584, accuracy: 0.825\n",
      "iteration 54 210\t loss: 3.217, accuracy: 0.817\n",
      "iteration 54 220\t loss: 3.395, accuracy: 0.822\n",
      "iteration 54 230\t loss: 3.308, accuracy: 0.834\n",
      "iteration 54 240\t loss: 3.375, accuracy: 0.830\n",
      "iteration 54 250\t loss: 3.624, accuracy: 0.836\n",
      "iteration 54 260\t loss: 3.767, accuracy: 0.836\n",
      "iteration 54 270\t loss: 3.672, accuracy: 0.836\n",
      "iteration 54 280\t loss: 3.862, accuracy: 0.829\n",
      "iteration 55 0\t loss: 3.853, accuracy: 0.832\n",
      "iteration 55 10\t loss: 3.356, accuracy: 0.835\n",
      "iteration 55 20\t loss: 3.428, accuracy: 0.841\n",
      "iteration 55 30\t loss: 4.131, accuracy: 0.833\n",
      "iteration 55 40\t loss: 4.210, accuracy: 0.827\n",
      "iteration 55 50\t loss: 3.449, accuracy: 0.825\n",
      "iteration 55 60\t loss: 3.527, accuracy: 0.833\n",
      "iteration 55 70\t loss: 4.078, accuracy: 0.826\n",
      "iteration 55 80\t loss: 3.598, accuracy: 0.826\n",
      "iteration 55 90\t loss: 3.745, accuracy: 0.827\n",
      "iteration 55 100\t loss: 3.550, accuracy: 0.832\n",
      "iteration 55 110\t loss: 3.384, accuracy: 0.831\n",
      "iteration 55 120\t loss: 3.408, accuracy: 0.836\n",
      "iteration 55 130\t loss: 3.616, accuracy: 0.829\n",
      "iteration 55 140\t loss: 3.582, accuracy: 0.836\n",
      "iteration 55 150\t loss: 3.464, accuracy: 0.828\n",
      "iteration 55 160\t loss: 3.533, accuracy: 0.827\n",
      "iteration 55 170\t loss: 3.832, accuracy: 0.827\n",
      "iteration 55 180\t loss: 3.919, accuracy: 0.828\n",
      "iteration 55 190\t loss: 3.893, accuracy: 0.806\n",
      "iteration 55 200\t loss: 3.656, accuracy: 0.821\n",
      "iteration 55 210\t loss: 3.538, accuracy: 0.819\n",
      "iteration 55 220\t loss: 3.692, accuracy: 0.818\n",
      "iteration 55 230\t loss: 3.383, accuracy: 0.828\n",
      "iteration 55 240\t loss: 3.453, accuracy: 0.831\n",
      "iteration 55 250\t loss: 3.631, accuracy: 0.838\n",
      "iteration 55 260\t loss: 3.992, accuracy: 0.828\n",
      "iteration 55 270\t loss: 3.666, accuracy: 0.839\n",
      "iteration 55 280\t loss: 3.905, accuracy: 0.835\n",
      "iteration 56 0\t loss: 3.872, accuracy: 0.832\n",
      "iteration 56 10\t loss: 3.725, accuracy: 0.838\n",
      "iteration 56 20\t loss: 3.745, accuracy: 0.838\n",
      "iteration 56 30\t loss: 4.271, accuracy: 0.832\n",
      "iteration 56 40\t loss: 4.182, accuracy: 0.834\n",
      "iteration 56 50\t loss: 3.890, accuracy: 0.836\n",
      "iteration 56 60\t loss: 3.739, accuracy: 0.832\n",
      "iteration 56 70\t loss: 3.901, accuracy: 0.830\n",
      "iteration 56 80\t loss: 3.923, accuracy: 0.830\n",
      "iteration 56 90\t loss: 4.158, accuracy: 0.829\n",
      "iteration 56 100\t loss: 3.751, accuracy: 0.828\n",
      "iteration 56 110\t loss: 3.730, accuracy: 0.823\n",
      "iteration 56 120\t loss: 3.369, accuracy: 0.833\n",
      "iteration 56 130\t loss: 3.776, accuracy: 0.831\n",
      "iteration 56 140\t loss: 3.433, accuracy: 0.840\n",
      "iteration 56 150\t loss: 3.516, accuracy: 0.831\n",
      "iteration 56 160\t loss: 3.327, accuracy: 0.833\n",
      "iteration 56 170\t loss: 3.731, accuracy: 0.833\n",
      "iteration 56 180\t loss: 3.965, accuracy: 0.829\n",
      "iteration 56 190\t loss: 3.776, accuracy: 0.817\n",
      "iteration 56 200\t loss: 3.819, accuracy: 0.828\n",
      "iteration 56 210\t loss: 3.689, accuracy: 0.826\n",
      "iteration 56 220\t loss: 3.730, accuracy: 0.813\n",
      "iteration 56 230\t loss: 3.289, accuracy: 0.833\n",
      "iteration 56 240\t loss: 3.364, accuracy: 0.833\n",
      "iteration 56 250\t loss: 3.739, accuracy: 0.836\n",
      "iteration 56 260\t loss: 4.097, accuracy: 0.832\n",
      "iteration 56 270\t loss: 3.954, accuracy: 0.837\n",
      "iteration 56 280\t loss: 3.952, accuracy: 0.833\n",
      "iteration 57 0\t loss: 3.974, accuracy: 0.840\n",
      "iteration 57 10\t loss: 3.814, accuracy: 0.841\n",
      "iteration 57 20\t loss: 3.561, accuracy: 0.838\n",
      "iteration 57 30\t loss: 4.028, accuracy: 0.838\n",
      "iteration 57 40\t loss: 4.207, accuracy: 0.835\n",
      "iteration 57 50\t loss: 3.846, accuracy: 0.835\n",
      "iteration 57 60\t loss: 3.699, accuracy: 0.828\n",
      "iteration 57 70\t loss: 3.895, accuracy: 0.832\n",
      "iteration 57 80\t loss: 3.588, accuracy: 0.826\n",
      "iteration 57 90\t loss: 3.886, accuracy: 0.831\n",
      "iteration 57 100\t loss: 3.936, accuracy: 0.831\n",
      "iteration 57 110\t loss: 3.423, accuracy: 0.835\n",
      "iteration 57 120\t loss: 3.339, accuracy: 0.835\n",
      "iteration 57 130\t loss: 3.551, accuracy: 0.840\n",
      "iteration 57 140\t loss: 3.563, accuracy: 0.836\n",
      "iteration 57 150\t loss: 3.403, accuracy: 0.831\n",
      "iteration 57 160\t loss: 3.681, accuracy: 0.829\n",
      "iteration 57 170\t loss: 4.015, accuracy: 0.827\n",
      "iteration 57 180\t loss: 4.225, accuracy: 0.832\n",
      "iteration 57 190\t loss: 4.140, accuracy: 0.810\n",
      "iteration 57 200\t loss: 3.756, accuracy: 0.831\n",
      "iteration 57 210\t loss: 3.678, accuracy: 0.823\n",
      "iteration 57 220\t loss: 3.656, accuracy: 0.824\n",
      "iteration 57 230\t loss: 3.527, accuracy: 0.827\n",
      "iteration 57 240\t loss: 3.410, accuracy: 0.833\n",
      "iteration 57 250\t loss: 3.672, accuracy: 0.838\n",
      "iteration 57 260\t loss: 4.243, accuracy: 0.831\n",
      "iteration 57 270\t loss: 3.977, accuracy: 0.839\n",
      "iteration 57 280\t loss: 3.891, accuracy: 0.840\n",
      "iteration 58 0\t loss: 4.037, accuracy: 0.837\n",
      "iteration 58 10\t loss: 4.134, accuracy: 0.839\n",
      "iteration 58 20\t loss: 3.695, accuracy: 0.840\n",
      "iteration 58 30\t loss: 3.919, accuracy: 0.835\n",
      "iteration 58 40\t loss: 4.310, accuracy: 0.828\n",
      "iteration 58 50\t loss: 3.820, accuracy: 0.828\n",
      "iteration 58 60\t loss: 3.771, accuracy: 0.829\n",
      "iteration 58 70\t loss: 3.945, accuracy: 0.833\n",
      "iteration 58 80\t loss: 3.908, accuracy: 0.831\n",
      "iteration 58 90\t loss: 3.925, accuracy: 0.832\n",
      "iteration 58 100\t loss: 3.932, accuracy: 0.825\n",
      "iteration 58 110\t loss: 3.713, accuracy: 0.831\n",
      "iteration 58 120\t loss: 3.529, accuracy: 0.829\n",
      "iteration 58 130\t loss: 3.566, accuracy: 0.828\n",
      "iteration 58 140\t loss: 3.378, accuracy: 0.831\n",
      "iteration 58 150\t loss: 3.388, accuracy: 0.833\n",
      "iteration 58 160\t loss: 3.726, accuracy: 0.830\n",
      "iteration 58 170\t loss: 3.912, accuracy: 0.835\n",
      "iteration 58 180\t loss: 4.210, accuracy: 0.830\n",
      "iteration 58 190\t loss: 4.351, accuracy: 0.817\n",
      "iteration 58 200\t loss: 4.043, accuracy: 0.822\n",
      "iteration 58 210\t loss: 3.869, accuracy: 0.812\n",
      "iteration 58 220\t loss: 4.114, accuracy: 0.815\n",
      "iteration 58 230\t loss: 3.727, accuracy: 0.820\n",
      "iteration 58 240\t loss: 3.819, accuracy: 0.825\n",
      "iteration 58 250\t loss: 3.908, accuracy: 0.830\n",
      "iteration 58 260\t loss: 4.772, accuracy: 0.816\n",
      "iteration 58 270\t loss: 3.987, accuracy: 0.838\n",
      "iteration 58 280\t loss: 3.709, accuracy: 0.834\n",
      "iteration 59 0\t loss: 3.773, accuracy: 0.839\n",
      "iteration 59 10\t loss: 3.949, accuracy: 0.840\n",
      "iteration 59 20\t loss: 4.074, accuracy: 0.838\n",
      "iteration 59 30\t loss: 4.274, accuracy: 0.835\n",
      "iteration 59 40\t loss: 4.252, accuracy: 0.835\n",
      "iteration 59 50\t loss: 4.097, accuracy: 0.834\n",
      "iteration 59 60\t loss: 3.905, accuracy: 0.823\n",
      "iteration 59 70\t loss: 4.327, accuracy: 0.825\n",
      "iteration 59 80\t loss: 4.249, accuracy: 0.821\n",
      "iteration 59 90\t loss: 4.262, accuracy: 0.823\n",
      "iteration 59 100\t loss: 4.371, accuracy: 0.833\n",
      "iteration 59 110\t loss: 3.839, accuracy: 0.833\n",
      "iteration 59 120\t loss: 3.633, accuracy: 0.833\n",
      "iteration 59 130\t loss: 3.974, accuracy: 0.834\n",
      "iteration 59 140\t loss: 3.994, accuracy: 0.828\n",
      "iteration 59 150\t loss: 3.954, accuracy: 0.833\n",
      "iteration 59 160\t loss: 3.861, accuracy: 0.827\n",
      "iteration 59 170\t loss: 4.438, accuracy: 0.832\n",
      "iteration 59 180\t loss: 4.652, accuracy: 0.827\n",
      "iteration 59 190\t loss: 4.464, accuracy: 0.818\n",
      "iteration 59 200\t loss: 4.235, accuracy: 0.818\n",
      "iteration 59 210\t loss: 4.003, accuracy: 0.811\n",
      "iteration 59 220\t loss: 4.206, accuracy: 0.808\n",
      "iteration 59 230\t loss: 4.076, accuracy: 0.818\n",
      "iteration 59 240\t loss: 4.149, accuracy: 0.826\n",
      "iteration 59 250\t loss: 3.919, accuracy: 0.833\n",
      "iteration 59 260\t loss: 4.437, accuracy: 0.828\n",
      "iteration 59 270\t loss: 4.334, accuracy: 0.830\n",
      "iteration 59 280\t loss: 4.029, accuracy: 0.830\n",
      "iteration 60 0\t loss: 4.031, accuracy: 0.834\n",
      "iteration 60 10\t loss: 4.058, accuracy: 0.837\n",
      "iteration 60 20\t loss: 4.099, accuracy: 0.835\n",
      "iteration 60 30\t loss: 4.273, accuracy: 0.835\n",
      "iteration 60 40\t loss: 4.563, accuracy: 0.828\n",
      "iteration 60 50\t loss: 4.371, accuracy: 0.828\n",
      "iteration 60 60\t loss: 3.974, accuracy: 0.827\n",
      "iteration 60 70\t loss: 4.220, accuracy: 0.834\n",
      "iteration 60 80\t loss: 4.325, accuracy: 0.829\n",
      "iteration 60 90\t loss: 4.208, accuracy: 0.822\n",
      "iteration 60 100\t loss: 4.515, accuracy: 0.826\n",
      "iteration 60 110\t loss: 4.522, accuracy: 0.830\n",
      "iteration 60 120\t loss: 3.712, accuracy: 0.827\n",
      "iteration 60 130\t loss: 3.735, accuracy: 0.832\n",
      "iteration 60 140\t loss: 3.606, accuracy: 0.830\n",
      "iteration 60 150\t loss: 4.062, accuracy: 0.833\n",
      "iteration 60 160\t loss: 4.177, accuracy: 0.823\n",
      "iteration 60 170\t loss: 4.109, accuracy: 0.832\n",
      "iteration 60 180\t loss: 4.143, accuracy: 0.835\n",
      "iteration 60 190\t loss: 4.188, accuracy: 0.820\n",
      "iteration 60 200\t loss: 3.949, accuracy: 0.825\n",
      "iteration 60 210\t loss: 3.758, accuracy: 0.820\n",
      "iteration 60 220\t loss: 4.112, accuracy: 0.816\n",
      "iteration 60 230\t loss: 3.675, accuracy: 0.822\n",
      "iteration 60 240\t loss: 3.784, accuracy: 0.831\n",
      "iteration 60 250\t loss: 4.089, accuracy: 0.835\n",
      "iteration 60 260\t loss: 4.419, accuracy: 0.825\n",
      "iteration 60 270\t loss: 4.317, accuracy: 0.830\n",
      "iteration 60 280\t loss: 4.142, accuracy: 0.833\n",
      "iteration 61 0\t loss: 4.012, accuracy: 0.836\n",
      "iteration 61 10\t loss: 4.628, accuracy: 0.838\n",
      "iteration 61 20\t loss: 4.295, accuracy: 0.838\n",
      "iteration 61 30\t loss: 4.504, accuracy: 0.835\n",
      "iteration 61 40\t loss: 4.523, accuracy: 0.830\n",
      "iteration 61 50\t loss: 4.045, accuracy: 0.828\n",
      "iteration 61 60\t loss: 3.758, accuracy: 0.834\n",
      "iteration 61 70\t loss: 4.449, accuracy: 0.830\n",
      "iteration 61 80\t loss: 4.571, accuracy: 0.825\n",
      "iteration 61 90\t loss: 4.261, accuracy: 0.832\n",
      "iteration 61 100\t loss: 4.086, accuracy: 0.835\n",
      "iteration 61 110\t loss: 4.087, accuracy: 0.837\n",
      "iteration 61 120\t loss: 3.678, accuracy: 0.832\n",
      "iteration 61 130\t loss: 4.039, accuracy: 0.830\n",
      "iteration 61 140\t loss: 3.995, accuracy: 0.827\n",
      "iteration 61 150\t loss: 3.982, accuracy: 0.834\n",
      "iteration 61 160\t loss: 3.986, accuracy: 0.827\n",
      "iteration 61 170\t loss: 4.396, accuracy: 0.833\n",
      "iteration 61 180\t loss: 4.610, accuracy: 0.834\n",
      "iteration 61 190\t loss: 4.496, accuracy: 0.815\n",
      "iteration 61 200\t loss: 4.055, accuracy: 0.829\n",
      "iteration 61 210\t loss: 3.922, accuracy: 0.821\n",
      "iteration 61 220\t loss: 4.192, accuracy: 0.812\n",
      "iteration 61 230\t loss: 3.771, accuracy: 0.828\n",
      "iteration 61 240\t loss: 3.498, accuracy: 0.833\n",
      "iteration 61 250\t loss: 3.797, accuracy: 0.839\n",
      "iteration 61 260\t loss: 4.109, accuracy: 0.833\n",
      "iteration 61 270\t loss: 4.107, accuracy: 0.831\n",
      "iteration 61 280\t loss: 4.052, accuracy: 0.835\n",
      "iteration 62 0\t loss: 4.031, accuracy: 0.838\n",
      "iteration 62 10\t loss: 4.144, accuracy: 0.839\n",
      "iteration 62 20\t loss: 4.163, accuracy: 0.842\n",
      "iteration 62 30\t loss: 4.348, accuracy: 0.839\n",
      "iteration 62 40\t loss: 4.599, accuracy: 0.830\n",
      "iteration 62 50\t loss: 4.280, accuracy: 0.837\n",
      "iteration 62 60\t loss: 3.762, accuracy: 0.828\n",
      "iteration 62 70\t loss: 4.162, accuracy: 0.832\n",
      "iteration 62 80\t loss: 4.401, accuracy: 0.825\n",
      "iteration 62 90\t loss: 4.278, accuracy: 0.832\n",
      "iteration 62 100\t loss: 4.089, accuracy: 0.832\n",
      "iteration 62 110\t loss: 3.898, accuracy: 0.840\n",
      "iteration 62 120\t loss: 3.766, accuracy: 0.838\n",
      "iteration 62 130\t loss: 3.896, accuracy: 0.836\n",
      "iteration 62 140\t loss: 4.138, accuracy: 0.826\n",
      "iteration 62 150\t loss: 3.931, accuracy: 0.836\n",
      "iteration 62 160\t loss: 4.254, accuracy: 0.834\n",
      "iteration 62 170\t loss: 4.333, accuracy: 0.832\n",
      "iteration 62 180\t loss: 4.606, accuracy: 0.835\n",
      "iteration 62 190\t loss: 4.560, accuracy: 0.818\n",
      "iteration 62 200\t loss: 4.580, accuracy: 0.824\n",
      "iteration 62 210\t loss: 3.898, accuracy: 0.812\n",
      "iteration 62 220\t loss: 4.504, accuracy: 0.809\n",
      "iteration 62 230\t loss: 4.066, accuracy: 0.822\n",
      "iteration 62 240\t loss: 3.640, accuracy: 0.830\n",
      "iteration 62 250\t loss: 3.968, accuracy: 0.839\n",
      "iteration 62 260\t loss: 4.397, accuracy: 0.836\n",
      "iteration 62 270\t loss: 4.287, accuracy: 0.836\n",
      "iteration 62 280\t loss: 4.173, accuracy: 0.837\n",
      "iteration 63 0\t loss: 4.350, accuracy: 0.832\n",
      "iteration 63 10\t loss: 4.439, accuracy: 0.839\n",
      "iteration 63 20\t loss: 4.441, accuracy: 0.838\n",
      "iteration 63 30\t loss: 4.435, accuracy: 0.839\n",
      "iteration 63 40\t loss: 4.756, accuracy: 0.835\n",
      "iteration 63 50\t loss: 4.364, accuracy: 0.833\n",
      "iteration 63 60\t loss: 4.068, accuracy: 0.827\n",
      "iteration 63 70\t loss: 4.237, accuracy: 0.832\n",
      "iteration 63 80\t loss: 4.567, accuracy: 0.828\n",
      "iteration 63 90\t loss: 4.164, accuracy: 0.833\n",
      "iteration 63 100\t loss: 4.422, accuracy: 0.833\n",
      "iteration 63 110\t loss: 4.280, accuracy: 0.833\n",
      "iteration 63 120\t loss: 3.816, accuracy: 0.841\n",
      "iteration 63 130\t loss: 3.769, accuracy: 0.839\n",
      "iteration 63 140\t loss: 4.115, accuracy: 0.842\n",
      "iteration 63 150\t loss: 3.952, accuracy: 0.828\n",
      "iteration 63 160\t loss: 3.924, accuracy: 0.827\n",
      "iteration 63 170\t loss: 4.063, accuracy: 0.836\n",
      "iteration 63 180\t loss: 4.545, accuracy: 0.825\n",
      "iteration 63 190\t loss: 4.586, accuracy: 0.817\n",
      "iteration 63 200\t loss: 4.392, accuracy: 0.822\n",
      "iteration 63 210\t loss: 3.953, accuracy: 0.829\n",
      "iteration 63 220\t loss: 4.386, accuracy: 0.812\n",
      "iteration 63 230\t loss: 4.113, accuracy: 0.823\n",
      "iteration 63 240\t loss: 3.543, accuracy: 0.833\n",
      "iteration 63 250\t loss: 4.137, accuracy: 0.838\n",
      "iteration 63 260\t loss: 4.542, accuracy: 0.832\n",
      "iteration 63 270\t loss: 4.329, accuracy: 0.840\n",
      "iteration 63 280\t loss: 3.957, accuracy: 0.838\n",
      "iteration 64 0\t loss: 4.028, accuracy: 0.843\n",
      "iteration 64 10\t loss: 4.389, accuracy: 0.840\n",
      "iteration 64 20\t loss: 4.440, accuracy: 0.841\n",
      "iteration 64 30\t loss: 4.505, accuracy: 0.845\n",
      "iteration 64 40\t loss: 4.743, accuracy: 0.835\n",
      "iteration 64 50\t loss: 4.239, accuracy: 0.836\n",
      "iteration 64 60\t loss: 3.756, accuracy: 0.826\n",
      "iteration 64 70\t loss: 4.494, accuracy: 0.830\n",
      "iteration 64 80\t loss: 4.767, accuracy: 0.824\n",
      "iteration 64 90\t loss: 4.053, accuracy: 0.830\n",
      "iteration 64 100\t loss: 4.139, accuracy: 0.838\n",
      "iteration 64 110\t loss: 4.335, accuracy: 0.839\n",
      "iteration 64 120\t loss: 3.907, accuracy: 0.837\n",
      "iteration 64 130\t loss: 3.934, accuracy: 0.837\n",
      "iteration 64 140\t loss: 3.936, accuracy: 0.842\n",
      "iteration 64 150\t loss: 3.793, accuracy: 0.832\n",
      "iteration 64 160\t loss: 3.937, accuracy: 0.831\n",
      "iteration 64 170\t loss: 3.942, accuracy: 0.833\n",
      "iteration 64 180\t loss: 4.161, accuracy: 0.840\n",
      "iteration 64 190\t loss: 4.871, accuracy: 0.814\n",
      "iteration 64 200\t loss: 4.489, accuracy: 0.823\n",
      "iteration 64 210\t loss: 4.176, accuracy: 0.827\n",
      "iteration 64 220\t loss: 4.324, accuracy: 0.809\n",
      "iteration 64 230\t loss: 4.426, accuracy: 0.818\n",
      "iteration 64 240\t loss: 3.697, accuracy: 0.829\n",
      "iteration 64 250\t loss: 4.172, accuracy: 0.827\n",
      "iteration 64 260\t loss: 4.863, accuracy: 0.826\n",
      "iteration 64 270\t loss: 4.865, accuracy: 0.839\n",
      "iteration 64 280\t loss: 4.728, accuracy: 0.835\n",
      "iteration 65 0\t loss: 4.404, accuracy: 0.835\n",
      "iteration 65 10\t loss: 4.352, accuracy: 0.837\n",
      "iteration 65 20\t loss: 4.498, accuracy: 0.837\n",
      "iteration 65 30\t loss: 4.573, accuracy: 0.840\n",
      "iteration 65 40\t loss: 4.649, accuracy: 0.836\n",
      "iteration 65 50\t loss: 4.376, accuracy: 0.837\n",
      "iteration 65 60\t loss: 3.848, accuracy: 0.814\n",
      "iteration 65 70\t loss: 4.162, accuracy: 0.829\n",
      "iteration 65 80\t loss: 4.602, accuracy: 0.828\n",
      "iteration 65 90\t loss: 4.378, accuracy: 0.826\n",
      "iteration 65 100\t loss: 4.530, accuracy: 0.831\n",
      "iteration 65 110\t loss: 4.326, accuracy: 0.831\n",
      "iteration 65 120\t loss: 4.185, accuracy: 0.833\n",
      "iteration 65 130\t loss: 4.344, accuracy: 0.836\n",
      "iteration 65 140\t loss: 4.411, accuracy: 0.836\n",
      "iteration 65 150\t loss: 4.240, accuracy: 0.831\n",
      "iteration 65 160\t loss: 4.004, accuracy: 0.823\n",
      "iteration 65 170\t loss: 4.362, accuracy: 0.822\n",
      "iteration 65 180\t loss: 4.401, accuracy: 0.832\n",
      "iteration 65 190\t loss: 4.363, accuracy: 0.819\n",
      "iteration 65 200\t loss: 5.005, accuracy: 0.824\n",
      "iteration 65 210\t loss: 4.675, accuracy: 0.826\n",
      "iteration 65 220\t loss: 4.262, accuracy: 0.812\n",
      "iteration 65 230\t loss: 4.865, accuracy: 0.819\n",
      "iteration 65 240\t loss: 3.883, accuracy: 0.827\n",
      "iteration 65 250\t loss: 4.266, accuracy: 0.838\n",
      "iteration 65 260\t loss: 4.754, accuracy: 0.837\n",
      "iteration 65 270\t loss: 4.819, accuracy: 0.837\n",
      "iteration 65 280\t loss: 4.518, accuracy: 0.839\n",
      "iteration 66 0\t loss: 4.569, accuracy: 0.841\n",
      "iteration 66 10\t loss: 4.655, accuracy: 0.841\n",
      "iteration 66 20\t loss: 4.593, accuracy: 0.842\n",
      "iteration 66 30\t loss: 5.004, accuracy: 0.831\n",
      "iteration 66 40\t loss: 4.890, accuracy: 0.831\n",
      "iteration 66 50\t loss: 4.342, accuracy: 0.830\n",
      "iteration 66 60\t loss: 4.466, accuracy: 0.831\n",
      "iteration 66 70\t loss: 4.468, accuracy: 0.830\n",
      "iteration 66 80\t loss: 4.615, accuracy: 0.831\n",
      "iteration 66 90\t loss: 4.556, accuracy: 0.834\n",
      "iteration 66 100\t loss: 4.394, accuracy: 0.835\n",
      "iteration 66 110\t loss: 4.539, accuracy: 0.835\n",
      "iteration 66 120\t loss: 4.071, accuracy: 0.836\n",
      "iteration 66 130\t loss: 4.570, accuracy: 0.835\n",
      "iteration 66 140\t loss: 4.623, accuracy: 0.837\n",
      "iteration 66 150\t loss: 4.437, accuracy: 0.839\n",
      "iteration 66 160\t loss: 4.521, accuracy: 0.838\n",
      "iteration 66 170\t loss: 4.509, accuracy: 0.837\n",
      "iteration 66 180\t loss: 4.953, accuracy: 0.829\n",
      "iteration 66 190\t loss: 4.953, accuracy: 0.811\n",
      "iteration 66 200\t loss: 4.726, accuracy: 0.822\n",
      "iteration 66 210\t loss: 4.496, accuracy: 0.837\n",
      "iteration 66 220\t loss: 4.289, accuracy: 0.819\n",
      "iteration 66 230\t loss: 4.346, accuracy: 0.827\n",
      "iteration 66 240\t loss: 4.370, accuracy: 0.836\n",
      "iteration 66 250\t loss: 4.425, accuracy: 0.835\n",
      "iteration 66 260\t loss: 4.700, accuracy: 0.822\n",
      "iteration 66 270\t loss: 4.439, accuracy: 0.838\n",
      "iteration 66 280\t loss: 4.505, accuracy: 0.839\n",
      "iteration 67 0\t loss: 4.441, accuracy: 0.843\n",
      "iteration 67 10\t loss: 4.492, accuracy: 0.844\n",
      "iteration 67 20\t loss: 4.524, accuracy: 0.847\n",
      "iteration 67 30\t loss: 4.732, accuracy: 0.842\n",
      "iteration 67 40\t loss: 5.476, accuracy: 0.827\n",
      "iteration 67 50\t loss: 4.812, accuracy: 0.838\n",
      "iteration 67 60\t loss: 3.986, accuracy: 0.820\n",
      "iteration 67 70\t loss: 4.505, accuracy: 0.833\n",
      "iteration 67 80\t loss: 5.214, accuracy: 0.823\n",
      "iteration 67 90\t loss: 4.484, accuracy: 0.829\n",
      "iteration 67 100\t loss: 4.750, accuracy: 0.834\n",
      "iteration 67 110\t loss: 4.725, accuracy: 0.833\n",
      "iteration 67 120\t loss: 4.221, accuracy: 0.830\n",
      "iteration 67 130\t loss: 4.215, accuracy: 0.832\n",
      "iteration 67 140\t loss: 4.356, accuracy: 0.833\n",
      "iteration 67 150\t loss: 4.144, accuracy: 0.829\n",
      "iteration 67 160\t loss: 4.220, accuracy: 0.831\n",
      "iteration 67 170\t loss: 4.238, accuracy: 0.830\n",
      "iteration 67 180\t loss: 4.718, accuracy: 0.839\n",
      "iteration 67 190\t loss: 4.783, accuracy: 0.825\n",
      "iteration 67 200\t loss: 4.424, accuracy: 0.825\n",
      "iteration 67 210\t loss: 4.278, accuracy: 0.833\n",
      "iteration 67 220\t loss: 4.261, accuracy: 0.817\n",
      "iteration 67 230\t loss: 4.430, accuracy: 0.822\n",
      "iteration 67 240\t loss: 4.246, accuracy: 0.833\n",
      "iteration 67 250\t loss: 4.247, accuracy: 0.837\n",
      "iteration 67 260\t loss: 4.591, accuracy: 0.838\n",
      "iteration 67 270\t loss: 4.711, accuracy: 0.838\n",
      "iteration 67 280\t loss: 4.568, accuracy: 0.844\n",
      "iteration 68 0\t loss: 4.547, accuracy: 0.841\n",
      "iteration 68 10\t loss: 4.783, accuracy: 0.848\n",
      "iteration 68 20\t loss: 4.700, accuracy: 0.843\n",
      "iteration 68 30\t loss: 4.594, accuracy: 0.845\n",
      "iteration 68 40\t loss: 5.405, accuracy: 0.833\n",
      "iteration 68 50\t loss: 5.192, accuracy: 0.836\n",
      "iteration 68 60\t loss: 4.415, accuracy: 0.822\n",
      "iteration 68 70\t loss: 4.544, accuracy: 0.834\n",
      "iteration 68 80\t loss: 4.877, accuracy: 0.832\n",
      "iteration 68 90\t loss: 4.627, accuracy: 0.834\n",
      "iteration 68 100\t loss: 4.748, accuracy: 0.835\n",
      "iteration 68 110\t loss: 4.737, accuracy: 0.833\n",
      "iteration 68 120\t loss: 4.252, accuracy: 0.835\n",
      "iteration 68 130\t loss: 4.330, accuracy: 0.835\n",
      "iteration 68 140\t loss: 4.722, accuracy: 0.833\n",
      "iteration 68 150\t loss: 4.531, accuracy: 0.833\n",
      "iteration 68 160\t loss: 4.295, accuracy: 0.830\n",
      "iteration 68 170\t loss: 4.378, accuracy: 0.837\n",
      "iteration 68 180\t loss: 4.601, accuracy: 0.833\n",
      "iteration 68 190\t loss: 4.616, accuracy: 0.817\n",
      "iteration 68 200\t loss: 4.659, accuracy: 0.820\n",
      "iteration 68 210\t loss: 4.762, accuracy: 0.827\n",
      "iteration 68 220\t loss: 4.139, accuracy: 0.814\n",
      "iteration 68 230\t loss: 4.503, accuracy: 0.821\n",
      "iteration 68 240\t loss: 4.173, accuracy: 0.831\n",
      "iteration 68 250\t loss: 4.068, accuracy: 0.832\n",
      "iteration 68 260\t loss: 4.675, accuracy: 0.839\n",
      "iteration 68 270\t loss: 5.027, accuracy: 0.833\n",
      "iteration 68 280\t loss: 4.943, accuracy: 0.837\n",
      "iteration 69 0\t loss: 4.499, accuracy: 0.842\n",
      "iteration 69 10\t loss: 4.536, accuracy: 0.839\n",
      "iteration 69 20\t loss: 4.596, accuracy: 0.842\n",
      "iteration 69 30\t loss: 4.613, accuracy: 0.841\n",
      "iteration 69 40\t loss: 4.839, accuracy: 0.841\n",
      "iteration 69 50\t loss: 5.066, accuracy: 0.836\n",
      "iteration 69 60\t loss: 4.403, accuracy: 0.813\n",
      "iteration 69 70\t loss: 4.916, accuracy: 0.828\n",
      "iteration 69 80\t loss: 4.845, accuracy: 0.826\n",
      "iteration 69 90\t loss: 4.621, accuracy: 0.832\n",
      "iteration 69 100\t loss: 5.022, accuracy: 0.831\n",
      "iteration 69 110\t loss: 5.137, accuracy: 0.827\n",
      "iteration 69 120\t loss: 4.444, accuracy: 0.833\n",
      "iteration 69 130\t loss: 4.277, accuracy: 0.835\n",
      "iteration 69 140\t loss: 4.254, accuracy: 0.838\n",
      "iteration 69 150\t loss: 4.147, accuracy: 0.830\n",
      "iteration 69 160\t loss: 4.521, accuracy: 0.827\n",
      "iteration 69 170\t loss: 4.550, accuracy: 0.833\n",
      "iteration 69 180\t loss: 4.684, accuracy: 0.835\n",
      "iteration 69 190\t loss: 4.534, accuracy: 0.833\n",
      "iteration 69 200\t loss: 4.500, accuracy: 0.822\n",
      "iteration 69 210\t loss: 4.402, accuracy: 0.837\n",
      "iteration 69 220\t loss: 4.404, accuracy: 0.831\n",
      "iteration 69 230\t loss: 4.491, accuracy: 0.825\n",
      "iteration 69 240\t loss: 4.431, accuracy: 0.838\n",
      "iteration 69 250\t loss: 4.313, accuracy: 0.840\n",
      "iteration 69 260\t loss: 4.653, accuracy: 0.840\n",
      "iteration 69 270\t loss: 5.390, accuracy: 0.830\n",
      "iteration 69 280\t loss: 4.843, accuracy: 0.843\n",
      "iteration 70 0\t loss: 4.737, accuracy: 0.842\n",
      "iteration 70 10\t loss: 4.757, accuracy: 0.839\n",
      "iteration 70 20\t loss: 4.724, accuracy: 0.840\n",
      "iteration 70 30\t loss: 4.827, accuracy: 0.834\n",
      "iteration 70 40\t loss: 5.516, accuracy: 0.830\n",
      "iteration 70 50\t loss: 5.316, accuracy: 0.837\n",
      "iteration 70 60\t loss: 4.724, accuracy: 0.822\n",
      "iteration 70 70\t loss: 4.449, accuracy: 0.830\n",
      "iteration 70 80\t loss: 5.141, accuracy: 0.830\n",
      "iteration 70 90\t loss: 4.603, accuracy: 0.823\n",
      "iteration 70 100\t loss: 4.673, accuracy: 0.830\n",
      "iteration 70 110\t loss: 4.756, accuracy: 0.836\n",
      "iteration 70 120\t loss: 4.357, accuracy: 0.836\n",
      "iteration 70 130\t loss: 4.411, accuracy: 0.836\n",
      "iteration 70 140\t loss: 4.829, accuracy: 0.836\n",
      "iteration 70 150\t loss: 4.490, accuracy: 0.833\n",
      "iteration 70 160\t loss: 4.488, accuracy: 0.826\n",
      "iteration 70 170\t loss: 4.702, accuracy: 0.829\n",
      "iteration 70 180\t loss: 4.796, accuracy: 0.838\n",
      "iteration 70 190\t loss: 5.000, accuracy: 0.830\n",
      "iteration 70 200\t loss: 4.771, accuracy: 0.822\n",
      "iteration 70 210\t loss: 4.504, accuracy: 0.832\n",
      "iteration 70 220\t loss: 4.608, accuracy: 0.826\n",
      "iteration 70 230\t loss: 4.634, accuracy: 0.819\n",
      "iteration 70 240\t loss: 4.351, accuracy: 0.836\n",
      "iteration 70 250\t loss: 4.462, accuracy: 0.835\n",
      "iteration 70 260\t loss: 5.167, accuracy: 0.834\n",
      "iteration 70 270\t loss: 5.464, accuracy: 0.836\n",
      "iteration 70 280\t loss: 5.368, accuracy: 0.840\n",
      "iteration 71 0\t loss: 4.806, accuracy: 0.838\n",
      "iteration 71 10\t loss: 4.627, accuracy: 0.843\n",
      "iteration 71 20\t loss: 4.591, accuracy: 0.843\n",
      "iteration 71 30\t loss: 4.755, accuracy: 0.842\n",
      "iteration 71 40\t loss: 5.271, accuracy: 0.843\n",
      "iteration 71 50\t loss: 6.098, accuracy: 0.828\n",
      "iteration 71 60\t loss: 4.597, accuracy: 0.807\n",
      "iteration 71 70\t loss: 4.900, accuracy: 0.828\n",
      "iteration 71 80\t loss: 5.207, accuracy: 0.822\n",
      "iteration 71 90\t loss: 4.996, accuracy: 0.823\n",
      "iteration 71 100\t loss: 4.746, accuracy: 0.824\n",
      "iteration 71 110\t loss: 5.042, accuracy: 0.832\n",
      "iteration 71 120\t loss: 4.585, accuracy: 0.832\n",
      "iteration 71 130\t loss: 4.698, accuracy: 0.837\n",
      "iteration 71 140\t loss: 4.805, accuracy: 0.839\n",
      "iteration 71 150\t loss: 4.780, accuracy: 0.838\n",
      "iteration 71 160\t loss: 4.678, accuracy: 0.831\n",
      "iteration 71 170\t loss: 4.582, accuracy: 0.837\n",
      "iteration 71 180\t loss: 5.159, accuracy: 0.839\n",
      "iteration 71 190\t loss: 5.045, accuracy: 0.827\n",
      "iteration 71 200\t loss: 5.055, accuracy: 0.819\n",
      "iteration 71 210\t loss: 4.695, accuracy: 0.841\n",
      "iteration 71 220\t loss: 4.426, accuracy: 0.825\n",
      "iteration 71 230\t loss: 4.462, accuracy: 0.825\n",
      "iteration 71 240\t loss: 4.485, accuracy: 0.836\n",
      "iteration 71 250\t loss: 4.954, accuracy: 0.843\n",
      "iteration 71 260\t loss: 5.283, accuracy: 0.843\n",
      "iteration 71 270\t loss: 5.874, accuracy: 0.833\n",
      "iteration 71 280\t loss: 5.289, accuracy: 0.841\n",
      "iteration 72 0\t loss: 5.194, accuracy: 0.834\n",
      "iteration 72 10\t loss: 5.176, accuracy: 0.842\n",
      "iteration 72 20\t loss: 5.409, accuracy: 0.838\n",
      "iteration 72 30\t loss: 5.310, accuracy: 0.842\n",
      "iteration 72 40\t loss: 5.151, accuracy: 0.841\n",
      "iteration 72 50\t loss: 5.402, accuracy: 0.834\n",
      "iteration 72 60\t loss: 4.637, accuracy: 0.834\n",
      "iteration 72 70\t loss: 4.893, accuracy: 0.810\n",
      "iteration 72 80\t loss: 5.256, accuracy: 0.821\n",
      "iteration 72 90\t loss: 4.883, accuracy: 0.823\n",
      "iteration 72 100\t loss: 5.239, accuracy: 0.828\n",
      "iteration 72 110\t loss: 5.401, accuracy: 0.835\n",
      "iteration 72 120\t loss: 5.061, accuracy: 0.835\n",
      "iteration 72 130\t loss: 4.696, accuracy: 0.836\n",
      "iteration 72 140\t loss: 4.829, accuracy: 0.841\n",
      "iteration 72 150\t loss: 4.887, accuracy: 0.842\n",
      "iteration 72 160\t loss: 4.553, accuracy: 0.829\n",
      "iteration 72 170\t loss: 4.666, accuracy: 0.835\n",
      "iteration 72 180\t loss: 5.152, accuracy: 0.837\n",
      "iteration 72 190\t loss: 5.090, accuracy: 0.828\n",
      "iteration 72 200\t loss: 5.080, accuracy: 0.828\n",
      "iteration 72 210\t loss: 4.633, accuracy: 0.835\n",
      "iteration 72 220\t loss: 4.626, accuracy: 0.825\n",
      "iteration 72 230\t loss: 5.040, accuracy: 0.822\n",
      "iteration 72 240\t loss: 4.550, accuracy: 0.833\n",
      "iteration 72 250\t loss: 4.904, accuracy: 0.840\n",
      "iteration 72 260\t loss: 5.219, accuracy: 0.839\n",
      "iteration 72 270\t loss: 5.573, accuracy: 0.836\n",
      "iteration 72 280\t loss: 4.661, accuracy: 0.838\n",
      "iteration 73 0\t loss: 4.838, accuracy: 0.840\n",
      "iteration 73 10\t loss: 4.966, accuracy: 0.847\n",
      "iteration 73 20\t loss: 4.943, accuracy: 0.845\n",
      "iteration 73 30\t loss: 5.089, accuracy: 0.845\n",
      "iteration 73 40\t loss: 5.028, accuracy: 0.843\n",
      "iteration 73 50\t loss: 5.497, accuracy: 0.835\n",
      "iteration 73 60\t loss: 5.014, accuracy: 0.836\n",
      "iteration 73 70\t loss: 4.518, accuracy: 0.813\n",
      "iteration 73 80\t loss: 5.340, accuracy: 0.832\n",
      "iteration 73 90\t loss: 5.300, accuracy: 0.824\n",
      "iteration 73 100\t loss: 4.820, accuracy: 0.825\n",
      "iteration 73 110\t loss: 5.015, accuracy: 0.832\n",
      "iteration 73 120\t loss: 4.818, accuracy: 0.839\n",
      "iteration 73 130\t loss: 4.597, accuracy: 0.840\n",
      "iteration 73 140\t loss: 4.915, accuracy: 0.834\n",
      "iteration 73 150\t loss: 4.724, accuracy: 0.836\n",
      "iteration 73 160\t loss: 4.653, accuracy: 0.829\n",
      "iteration 73 170\t loss: 4.683, accuracy: 0.836\n",
      "iteration 73 180\t loss: 5.302, accuracy: 0.842\n",
      "iteration 73 190\t loss: 5.482, accuracy: 0.835\n",
      "iteration 73 200\t loss: 5.582, accuracy: 0.820\n",
      "iteration 73 210\t loss: 5.150, accuracy: 0.838\n",
      "iteration 73 220\t loss: 4.375, accuracy: 0.816\n",
      "iteration 73 230\t loss: 4.743, accuracy: 0.825\n",
      "iteration 73 240\t loss: 5.041, accuracy: 0.835\n",
      "iteration 73 250\t loss: 4.804, accuracy: 0.840\n",
      "iteration 73 260\t loss: 5.296, accuracy: 0.837\n",
      "iteration 73 270\t loss: 5.297, accuracy: 0.837\n",
      "iteration 73 280\t loss: 5.290, accuracy: 0.844\n",
      "iteration 74 0\t loss: 4.907, accuracy: 0.839\n",
      "iteration 74 10\t loss: 5.224, accuracy: 0.845\n",
      "iteration 74 20\t loss: 5.285, accuracy: 0.845\n",
      "iteration 74 30\t loss: 5.238, accuracy: 0.846\n",
      "iteration 74 40\t loss: 5.489, accuracy: 0.839\n",
      "iteration 74 50\t loss: 5.452, accuracy: 0.839\n",
      "iteration 74 60\t loss: 5.161, accuracy: 0.836\n",
      "iteration 74 70\t loss: 4.914, accuracy: 0.814\n",
      "iteration 74 80\t loss: 5.163, accuracy: 0.831\n",
      "iteration 74 90\t loss: 5.457, accuracy: 0.819\n",
      "iteration 74 100\t loss: 4.693, accuracy: 0.820\n",
      "iteration 74 110\t loss: 5.234, accuracy: 0.830\n",
      "iteration 74 120\t loss: 5.254, accuracy: 0.837\n",
      "iteration 74 130\t loss: 4.869, accuracy: 0.834\n",
      "iteration 74 140\t loss: 5.057, accuracy: 0.838\n",
      "iteration 74 150\t loss: 5.117, accuracy: 0.836\n",
      "iteration 74 160\t loss: 4.694, accuracy: 0.832\n",
      "iteration 74 170\t loss: 4.829, accuracy: 0.838\n",
      "iteration 74 180\t loss: 5.208, accuracy: 0.833\n",
      "iteration 74 190\t loss: 5.392, accuracy: 0.833\n",
      "iteration 74 200\t loss: 5.874, accuracy: 0.814\n",
      "iteration 74 210\t loss: 5.485, accuracy: 0.834\n",
      "iteration 74 220\t loss: 4.525, accuracy: 0.820\n",
      "iteration 74 230\t loss: 5.096, accuracy: 0.819\n",
      "iteration 74 240\t loss: 4.776, accuracy: 0.835\n",
      "iteration 74 250\t loss: 4.752, accuracy: 0.838\n",
      "iteration 74 260\t loss: 5.122, accuracy: 0.841\n",
      "iteration 74 270\t loss: 5.382, accuracy: 0.840\n",
      "iteration 74 280\t loss: 5.341, accuracy: 0.844\n",
      "iteration 75 0\t loss: 5.196, accuracy: 0.839\n",
      "iteration 75 10\t loss: 5.038, accuracy: 0.837\n",
      "iteration 75 20\t loss: 5.265, accuracy: 0.837\n",
      "iteration 75 30\t loss: 5.241, accuracy: 0.838\n",
      "iteration 75 40\t loss: 5.365, accuracy: 0.840\n",
      "iteration 75 50\t loss: 5.478, accuracy: 0.841\n",
      "iteration 75 60\t loss: 5.290, accuracy: 0.842\n",
      "iteration 75 70\t loss: 5.130, accuracy: 0.838\n",
      "iteration 75 80\t loss: 5.055, accuracy: 0.832\n",
      "iteration 75 90\t loss: 5.312, accuracy: 0.837\n",
      "iteration 75 100\t loss: 4.918, accuracy: 0.832\n",
      "iteration 75 110\t loss: 5.053, accuracy: 0.831\n",
      "iteration 75 120\t loss: 5.143, accuracy: 0.841\n",
      "iteration 75 130\t loss: 4.860, accuracy: 0.840\n",
      "iteration 75 140\t loss: 4.930, accuracy: 0.838\n",
      "iteration 75 150\t loss: 4.893, accuracy: 0.839\n",
      "iteration 75 160\t loss: 4.551, accuracy: 0.833\n",
      "iteration 75 170\t loss: 4.944, accuracy: 0.834\n",
      "iteration 75 180\t loss: 5.167, accuracy: 0.840\n",
      "iteration 75 190\t loss: 5.406, accuracy: 0.835\n",
      "iteration 75 200\t loss: 5.412, accuracy: 0.818\n",
      "iteration 75 210\t loss: 5.158, accuracy: 0.844\n",
      "iteration 75 220\t loss: 4.964, accuracy: 0.834\n",
      "iteration 75 230\t loss: 5.001, accuracy: 0.821\n",
      "iteration 75 240\t loss: 5.019, accuracy: 0.834\n",
      "iteration 75 250\t loss: 5.167, accuracy: 0.838\n",
      "iteration 75 260\t loss: 5.399, accuracy: 0.839\n",
      "iteration 75 270\t loss: 5.938, accuracy: 0.834\n",
      "iteration 75 280\t loss: 5.592, accuracy: 0.839\n",
      "iteration 76 0\t loss: 5.368, accuracy: 0.844\n",
      "iteration 76 10\t loss: 5.212, accuracy: 0.839\n",
      "iteration 76 20\t loss: 5.383, accuracy: 0.845\n",
      "iteration 76 30\t loss: 5.463, accuracy: 0.844\n",
      "iteration 76 40\t loss: 5.367, accuracy: 0.840\n",
      "iteration 76 50\t loss: 5.856, accuracy: 0.837\n",
      "iteration 76 60\t loss: 5.472, accuracy: 0.841\n",
      "iteration 76 70\t loss: 5.218, accuracy: 0.829\n",
      "iteration 76 80\t loss: 5.203, accuracy: 0.835\n",
      "iteration 76 90\t loss: 4.908, accuracy: 0.834\n",
      "iteration 76 100\t loss: 5.108, accuracy: 0.835\n",
      "iteration 76 110\t loss: 5.213, accuracy: 0.833\n",
      "iteration 76 120\t loss: 5.087, accuracy: 0.836\n",
      "iteration 76 130\t loss: 5.080, accuracy: 0.833\n",
      "iteration 76 140\t loss: 5.066, accuracy: 0.832\n",
      "iteration 76 150\t loss: 4.791, accuracy: 0.835\n",
      "iteration 76 160\t loss: 4.835, accuracy: 0.839\n",
      "iteration 76 170\t loss: 5.048, accuracy: 0.838\n",
      "iteration 76 180\t loss: 5.169, accuracy: 0.841\n",
      "iteration 76 190\t loss: 5.308, accuracy: 0.838\n",
      "iteration 76 200\t loss: 5.320, accuracy: 0.823\n",
      "iteration 76 210\t loss: 5.621, accuracy: 0.831\n",
      "iteration 76 220\t loss: 4.987, accuracy: 0.823\n",
      "iteration 76 230\t loss: 5.240, accuracy: 0.820\n",
      "iteration 76 240\t loss: 5.081, accuracy: 0.835\n",
      "iteration 76 250\t loss: 4.957, accuracy: 0.841\n",
      "iteration 76 260\t loss: 4.970, accuracy: 0.839\n",
      "iteration 76 270\t loss: 5.599, accuracy: 0.833\n",
      "iteration 76 280\t loss: 5.460, accuracy: 0.840\n",
      "iteration 77 0\t loss: 5.551, accuracy: 0.840\n",
      "iteration 77 10\t loss: 5.640, accuracy: 0.844\n",
      "iteration 77 20\t loss: 5.605, accuracy: 0.846\n",
      "iteration 77 30\t loss: 5.583, accuracy: 0.844\n",
      "iteration 77 40\t loss: 5.841, accuracy: 0.842\n",
      "iteration 77 50\t loss: 5.949, accuracy: 0.847\n",
      "iteration 77 60\t loss: 5.331, accuracy: 0.838\n",
      "iteration 77 70\t loss: 5.287, accuracy: 0.835\n",
      "iteration 77 80\t loss: 5.626, accuracy: 0.834\n",
      "iteration 77 90\t loss: 5.856, accuracy: 0.835\n",
      "iteration 77 100\t loss: 5.525, accuracy: 0.832\n",
      "iteration 77 110\t loss: 4.968, accuracy: 0.834\n",
      "iteration 77 120\t loss: 5.096, accuracy: 0.842\n",
      "iteration 77 130\t loss: 5.157, accuracy: 0.842\n",
      "iteration 77 140\t loss: 5.515, accuracy: 0.840\n",
      "iteration 77 150\t loss: 5.216, accuracy: 0.836\n",
      "iteration 77 160\t loss: 4.873, accuracy: 0.831\n",
      "iteration 77 170\t loss: 5.364, accuracy: 0.841\n",
      "iteration 77 180\t loss: 5.478, accuracy: 0.845\n",
      "iteration 77 190\t loss: 5.680, accuracy: 0.832\n",
      "iteration 77 200\t loss: 5.406, accuracy: 0.828\n",
      "iteration 77 210\t loss: 5.462, accuracy: 0.831\n",
      "iteration 77 220\t loss: 4.864, accuracy: 0.829\n",
      "iteration 77 230\t loss: 5.602, accuracy: 0.818\n",
      "iteration 77 240\t loss: 5.198, accuracy: 0.833\n",
      "iteration 77 250\t loss: 5.113, accuracy: 0.838\n",
      "iteration 77 260\t loss: 5.457, accuracy: 0.840\n",
      "iteration 77 270\t loss: 5.755, accuracy: 0.841\n",
      "iteration 77 280\t loss: 5.936, accuracy: 0.842\n",
      "iteration 78 0\t loss: 5.663, accuracy: 0.837\n",
      "iteration 78 10\t loss: 5.403, accuracy: 0.841\n",
      "iteration 78 20\t loss: 5.583, accuracy: 0.841\n",
      "iteration 78 30\t loss: 5.763, accuracy: 0.840\n",
      "iteration 78 40\t loss: 5.983, accuracy: 0.840\n",
      "iteration 78 50\t loss: 6.144, accuracy: 0.837\n",
      "iteration 78 60\t loss: 5.893, accuracy: 0.839\n",
      "iteration 78 70\t loss: 5.388, accuracy: 0.830\n",
      "iteration 78 80\t loss: 5.450, accuracy: 0.839\n",
      "iteration 78 90\t loss: 5.530, accuracy: 0.835\n",
      "iteration 78 100\t loss: 5.326, accuracy: 0.835\n",
      "iteration 78 110\t loss: 5.140, accuracy: 0.832\n",
      "iteration 78 120\t loss: 5.109, accuracy: 0.838\n",
      "iteration 78 130\t loss: 5.221, accuracy: 0.840\n",
      "iteration 78 140\t loss: 5.119, accuracy: 0.845\n",
      "iteration 78 150\t loss: 5.154, accuracy: 0.843\n",
      "iteration 78 160\t loss: 4.669, accuracy: 0.834\n",
      "iteration 78 170\t loss: 5.010, accuracy: 0.837\n",
      "iteration 78 180\t loss: 5.413, accuracy: 0.844\n",
      "iteration 78 190\t loss: 5.454, accuracy: 0.842\n",
      "iteration 78 200\t loss: 5.685, accuracy: 0.832\n",
      "iteration 78 210\t loss: 5.141, accuracy: 0.837\n",
      "iteration 78 220\t loss: 4.758, accuracy: 0.836\n",
      "iteration 78 230\t loss: 5.072, accuracy: 0.827\n",
      "iteration 78 240\t loss: 5.072, accuracy: 0.833\n",
      "iteration 78 250\t loss: 5.247, accuracy: 0.836\n",
      "iteration 78 260\t loss: 5.158, accuracy: 0.842\n",
      "iteration 78 270\t loss: 5.222, accuracy: 0.842\n",
      "iteration 78 280\t loss: 5.341, accuracy: 0.845\n",
      "iteration 79 0\t loss: 5.160, accuracy: 0.842\n",
      "iteration 79 10\t loss: 5.302, accuracy: 0.841\n",
      "iteration 79 20\t loss: 5.474, accuracy: 0.841\n",
      "iteration 79 30\t loss: 5.734, accuracy: 0.842\n",
      "iteration 79 40\t loss: 6.063, accuracy: 0.840\n",
      "iteration 79 50\t loss: 6.381, accuracy: 0.835\n",
      "iteration 79 60\t loss: 5.431, accuracy: 0.840\n",
      "iteration 79 70\t loss: 4.826, accuracy: 0.826\n",
      "iteration 79 80\t loss: 5.468, accuracy: 0.833\n",
      "iteration 79 90\t loss: 5.155, accuracy: 0.835\n",
      "iteration 79 100\t loss: 4.795, accuracy: 0.843\n",
      "iteration 79 110\t loss: 5.208, accuracy: 0.835\n",
      "iteration 79 120\t loss: 5.318, accuracy: 0.838\n",
      "iteration 79 130\t loss: 4.975, accuracy: 0.838\n",
      "iteration 79 140\t loss: 5.184, accuracy: 0.840\n",
      "iteration 79 150\t loss: 5.169, accuracy: 0.838\n",
      "iteration 79 160\t loss: 4.843, accuracy: 0.833\n",
      "iteration 79 170\t loss: 5.103, accuracy: 0.834\n",
      "iteration 79 180\t loss: 5.719, accuracy: 0.833\n",
      "iteration 79 190\t loss: 5.266, accuracy: 0.830\n",
      "iteration 79 200\t loss: 4.843, accuracy: 0.825\n",
      "iteration 79 210\t loss: 5.312, accuracy: 0.833\n",
      "iteration 79 220\t loss: 5.045, accuracy: 0.828\n",
      "iteration 79 230\t loss: 5.159, accuracy: 0.828\n",
      "iteration 79 240\t loss: 5.126, accuracy: 0.836\n",
      "iteration 79 250\t loss: 4.967, accuracy: 0.839\n",
      "iteration 79 260\t loss: 5.312, accuracy: 0.838\n",
      "iteration 79 270\t loss: 5.947, accuracy: 0.838\n",
      "iteration 79 280\t loss: 5.658, accuracy: 0.838\n",
      "iteration 80 0\t loss: 5.538, accuracy: 0.847\n",
      "iteration 80 10\t loss: 5.588, accuracy: 0.843\n",
      "iteration 80 20\t loss: 5.663, accuracy: 0.844\n",
      "iteration 80 30\t loss: 5.374, accuracy: 0.841\n",
      "iteration 80 40\t loss: 5.600, accuracy: 0.841\n",
      "iteration 80 50\t loss: 6.183, accuracy: 0.840\n",
      "iteration 80 60\t loss: 5.670, accuracy: 0.839\n",
      "iteration 80 70\t loss: 4.986, accuracy: 0.828\n",
      "iteration 80 80\t loss: 6.025, accuracy: 0.830\n",
      "iteration 80 90\t loss: 5.754, accuracy: 0.837\n",
      "iteration 80 100\t loss: 5.466, accuracy: 0.834\n",
      "iteration 80 110\t loss: 5.079, accuracy: 0.834\n",
      "iteration 80 120\t loss: 5.402, accuracy: 0.841\n",
      "iteration 80 130\t loss: 5.239, accuracy: 0.844\n",
      "iteration 80 140\t loss: 5.036, accuracy: 0.844\n",
      "iteration 80 150\t loss: 5.157, accuracy: 0.839\n",
      "iteration 80 160\t loss: 4.832, accuracy: 0.833\n",
      "iteration 80 170\t loss: 5.083, accuracy: 0.837\n",
      "iteration 80 180\t loss: 5.368, accuracy: 0.842\n",
      "iteration 80 190\t loss: 5.646, accuracy: 0.837\n",
      "iteration 80 200\t loss: 5.692, accuracy: 0.831\n",
      "iteration 80 210\t loss: 5.683, accuracy: 0.826\n",
      "iteration 80 220\t loss: 5.278, accuracy: 0.832\n",
      "iteration 80 230\t loss: 5.151, accuracy: 0.814\n",
      "iteration 80 240\t loss: 5.087, accuracy: 0.828\n",
      "iteration 80 250\t loss: 5.164, accuracy: 0.839\n",
      "iteration 80 260\t loss: 5.130, accuracy: 0.843\n",
      "iteration 80 270\t loss: 5.476, accuracy: 0.843\n",
      "iteration 80 280\t loss: 5.514, accuracy: 0.843\n",
      "iteration 81 0\t loss: 5.573, accuracy: 0.838\n",
      "iteration 81 10\t loss: 5.910, accuracy: 0.841\n",
      "iteration 81 20\t loss: 5.853, accuracy: 0.844\n",
      "iteration 81 30\t loss: 5.790, accuracy: 0.845\n",
      "iteration 81 40\t loss: 5.943, accuracy: 0.840\n",
      "iteration 81 50\t loss: 5.870, accuracy: 0.839\n",
      "iteration 81 60\t loss: 5.538, accuracy: 0.841\n",
      "iteration 81 70\t loss: 4.772, accuracy: 0.835\n",
      "iteration 81 80\t loss: 5.422, accuracy: 0.835\n",
      "iteration 81 90\t loss: 5.467, accuracy: 0.838\n",
      "iteration 81 100\t loss: 5.252, accuracy: 0.839\n",
      "iteration 81 110\t loss: 5.104, accuracy: 0.835\n",
      "iteration 81 120\t loss: 5.437, accuracy: 0.839\n",
      "iteration 81 130\t loss: 5.171, accuracy: 0.838\n",
      "iteration 81 140\t loss: 5.460, accuracy: 0.834\n",
      "iteration 81 150\t loss: 5.171, accuracy: 0.831\n",
      "iteration 81 160\t loss: 5.371, accuracy: 0.828\n",
      "iteration 81 170\t loss: 5.549, accuracy: 0.832\n",
      "iteration 81 180\t loss: 5.901, accuracy: 0.835\n",
      "iteration 81 190\t loss: 5.898, accuracy: 0.832\n",
      "iteration 81 200\t loss: 5.692, accuracy: 0.835\n",
      "iteration 81 210\t loss: 5.476, accuracy: 0.831\n",
      "iteration 81 220\t loss: 5.107, accuracy: 0.833\n",
      "iteration 81 230\t loss: 5.168, accuracy: 0.829\n",
      "iteration 81 240\t loss: 5.433, accuracy: 0.827\n",
      "iteration 81 250\t loss: 5.180, accuracy: 0.831\n",
      "iteration 81 260\t loss: 5.230, accuracy: 0.833\n",
      "iteration 81 270\t loss: 5.824, accuracy: 0.833\n",
      "iteration 81 280\t loss: 5.617, accuracy: 0.845\n",
      "iteration 82 0\t loss: 5.325, accuracy: 0.842\n",
      "iteration 82 10\t loss: 5.586, accuracy: 0.843\n",
      "iteration 82 20\t loss: 5.632, accuracy: 0.847\n",
      "iteration 82 30\t loss: 5.735, accuracy: 0.847\n",
      "iteration 82 40\t loss: 6.013, accuracy: 0.842\n",
      "iteration 82 50\t loss: 6.222, accuracy: 0.839\n",
      "iteration 82 60\t loss: 5.467, accuracy: 0.841\n",
      "iteration 82 70\t loss: 5.134, accuracy: 0.829\n",
      "iteration 82 80\t loss: 5.526, accuracy: 0.835\n",
      "iteration 82 90\t loss: 5.747, accuracy: 0.834\n",
      "iteration 82 100\t loss: 5.692, accuracy: 0.834\n",
      "iteration 82 110\t loss: 5.706, accuracy: 0.828\n",
      "iteration 82 120\t loss: 5.813, accuracy: 0.843\n",
      "iteration 82 130\t loss: 5.576, accuracy: 0.841\n",
      "iteration 82 140\t loss: 5.333, accuracy: 0.843\n",
      "iteration 82 150\t loss: 5.415, accuracy: 0.841\n",
      "iteration 82 160\t loss: 5.206, accuracy: 0.823\n",
      "iteration 82 170\t loss: 5.656, accuracy: 0.826\n",
      "iteration 82 180\t loss: 5.762, accuracy: 0.838\n",
      "iteration 82 190\t loss: 6.440, accuracy: 0.819\n",
      "iteration 82 200\t loss: 5.420, accuracy: 0.837\n",
      "iteration 82 210\t loss: 5.216, accuracy: 0.840\n",
      "iteration 82 220\t loss: 5.295, accuracy: 0.835\n",
      "iteration 82 230\t loss: 5.444, accuracy: 0.833\n",
      "iteration 82 240\t loss: 5.268, accuracy: 0.837\n",
      "iteration 82 250\t loss: 5.303, accuracy: 0.841\n",
      "iteration 82 260\t loss: 5.499, accuracy: 0.842\n",
      "iteration 82 270\t loss: 5.427, accuracy: 0.844\n",
      "iteration 82 280\t loss: 5.540, accuracy: 0.845\n",
      "iteration 83 0\t loss: 5.417, accuracy: 0.844\n",
      "iteration 83 10\t loss: 5.379, accuracy: 0.842\n",
      "iteration 83 20\t loss: 5.501, accuracy: 0.845\n",
      "iteration 83 30\t loss: 5.734, accuracy: 0.846\n",
      "iteration 83 40\t loss: 6.288, accuracy: 0.841\n",
      "iteration 83 50\t loss: 6.111, accuracy: 0.842\n",
      "iteration 83 60\t loss: 5.741, accuracy: 0.842\n",
      "iteration 83 70\t loss: 5.522, accuracy: 0.834\n",
      "iteration 83 80\t loss: 5.454, accuracy: 0.838\n",
      "iteration 83 90\t loss: 5.848, accuracy: 0.842\n",
      "iteration 83 100\t loss: 5.772, accuracy: 0.840\n",
      "iteration 83 110\t loss: 5.649, accuracy: 0.836\n",
      "iteration 83 120\t loss: 5.833, accuracy: 0.835\n",
      "iteration 83 130\t loss: 5.875, accuracy: 0.840\n",
      "iteration 83 140\t loss: 5.651, accuracy: 0.842\n",
      "iteration 83 150\t loss: 5.232, accuracy: 0.845\n",
      "iteration 83 160\t loss: 4.949, accuracy: 0.835\n",
      "iteration 83 170\t loss: 4.963, accuracy: 0.838\n",
      "iteration 83 180\t loss: 5.647, accuracy: 0.844\n",
      "iteration 83 190\t loss: 6.264, accuracy: 0.838\n",
      "iteration 83 200\t loss: 6.059, accuracy: 0.823\n",
      "iteration 83 210\t loss: 5.676, accuracy: 0.832\n",
      "iteration 83 220\t loss: 5.797, accuracy: 0.820\n",
      "iteration 83 230\t loss: 5.803, accuracy: 0.820\n",
      "iteration 83 240\t loss: 5.909, accuracy: 0.831\n",
      "iteration 83 250\t loss: 5.664, accuracy: 0.841\n",
      "iteration 83 260\t loss: 5.835, accuracy: 0.834\n",
      "iteration 83 270\t loss: 5.843, accuracy: 0.835\n",
      "iteration 83 280\t loss: 5.998, accuracy: 0.842\n",
      "iteration 84 0\t loss: 6.265, accuracy: 0.843\n",
      "iteration 84 10\t loss: 6.185, accuracy: 0.842\n",
      "iteration 84 20\t loss: 6.298, accuracy: 0.845\n",
      "iteration 84 30\t loss: 6.059, accuracy: 0.846\n",
      "iteration 84 40\t loss: 6.683, accuracy: 0.842\n",
      "iteration 84 50\t loss: 6.638, accuracy: 0.840\n",
      "iteration 84 60\t loss: 5.824, accuracy: 0.841\n",
      "iteration 84 70\t loss: 5.273, accuracy: 0.827\n",
      "iteration 84 80\t loss: 6.413, accuracy: 0.834\n",
      "iteration 84 90\t loss: 6.249, accuracy: 0.836\n",
      "iteration 84 100\t loss: 5.426, accuracy: 0.836\n",
      "iteration 84 110\t loss: 5.428, accuracy: 0.841\n",
      "iteration 84 120\t loss: 5.354, accuracy: 0.842\n",
      "iteration 84 130\t loss: 5.951, accuracy: 0.839\n",
      "iteration 84 140\t loss: 5.926, accuracy: 0.841\n",
      "iteration 84 150\t loss: 5.856, accuracy: 0.841\n",
      "iteration 84 160\t loss: 5.416, accuracy: 0.833\n",
      "iteration 84 170\t loss: 5.160, accuracy: 0.833\n",
      "iteration 84 180\t loss: 5.730, accuracy: 0.833\n",
      "iteration 84 190\t loss: 5.682, accuracy: 0.832\n",
      "iteration 84 200\t loss: 5.668, accuracy: 0.821\n",
      "iteration 84 210\t loss: 5.619, accuracy: 0.834\n",
      "iteration 84 220\t loss: 5.647, accuracy: 0.832\n",
      "iteration 84 230\t loss: 4.967, accuracy: 0.827\n",
      "iteration 84 240\t loss: 5.365, accuracy: 0.836\n",
      "iteration 84 250\t loss: 5.744, accuracy: 0.844\n",
      "iteration 84 260\t loss: 6.086, accuracy: 0.837\n",
      "iteration 84 270\t loss: 5.696, accuracy: 0.840\n",
      "iteration 84 280\t loss: 5.894, accuracy: 0.841\n",
      "iteration 85 0\t loss: 5.831, accuracy: 0.848\n",
      "iteration 85 10\t loss: 5.859, accuracy: 0.845\n",
      "iteration 85 20\t loss: 5.895, accuracy: 0.846\n",
      "iteration 85 30\t loss: 6.306, accuracy: 0.842\n",
      "iteration 85 40\t loss: 6.177, accuracy: 0.842\n",
      "iteration 85 50\t loss: 6.084, accuracy: 0.843\n",
      "iteration 85 60\t loss: 5.738, accuracy: 0.841\n",
      "iteration 85 70\t loss: 5.381, accuracy: 0.827\n",
      "iteration 85 80\t loss: 5.797, accuracy: 0.833\n",
      "iteration 85 90\t loss: 6.620, accuracy: 0.834\n",
      "iteration 85 100\t loss: 5.745, accuracy: 0.839\n",
      "iteration 85 110\t loss: 5.708, accuracy: 0.839\n",
      "iteration 85 120\t loss: 5.562, accuracy: 0.840\n",
      "iteration 85 130\t loss: 5.940, accuracy: 0.839\n",
      "iteration 85 140\t loss: 6.682, accuracy: 0.833\n",
      "iteration 85 150\t loss: 6.254, accuracy: 0.832\n",
      "iteration 85 160\t loss: 5.740, accuracy: 0.830\n",
      "iteration 85 170\t loss: 5.802, accuracy: 0.830\n",
      "iteration 85 180\t loss: 5.997, accuracy: 0.838\n",
      "iteration 85 190\t loss: 6.574, accuracy: 0.831\n",
      "iteration 85 200\t loss: 6.483, accuracy: 0.822\n",
      "iteration 85 210\t loss: 5.976, accuracy: 0.834\n",
      "iteration 85 220\t loss: 5.686, accuracy: 0.832\n",
      "iteration 85 230\t loss: 5.692, accuracy: 0.822\n",
      "iteration 85 240\t loss: 5.942, accuracy: 0.832\n",
      "iteration 85 250\t loss: 6.049, accuracy: 0.840\n",
      "iteration 85 260\t loss: 6.303, accuracy: 0.838\n",
      "iteration 85 270\t loss: 6.410, accuracy: 0.840\n",
      "iteration 85 280\t loss: 6.356, accuracy: 0.839\n",
      "iteration 86 0\t loss: 6.063, accuracy: 0.844\n",
      "iteration 86 10\t loss: 5.953, accuracy: 0.840\n",
      "iteration 86 20\t loss: 6.240, accuracy: 0.841\n",
      "iteration 86 30\t loss: 6.855, accuracy: 0.838\n",
      "iteration 86 40\t loss: 6.647, accuracy: 0.833\n",
      "iteration 86 50\t loss: 6.600, accuracy: 0.840\n",
      "iteration 86 60\t loss: 6.288, accuracy: 0.841\n",
      "iteration 86 70\t loss: 5.977, accuracy: 0.837\n",
      "iteration 86 80\t loss: 5.880, accuracy: 0.832\n",
      "iteration 86 90\t loss: 6.277, accuracy: 0.838\n",
      "iteration 86 100\t loss: 5.845, accuracy: 0.835\n",
      "iteration 86 110\t loss: 5.436, accuracy: 0.834\n",
      "iteration 86 120\t loss: 5.444, accuracy: 0.843\n",
      "iteration 86 130\t loss: 5.909, accuracy: 0.842\n",
      "iteration 86 140\t loss: 5.881, accuracy: 0.840\n",
      "iteration 86 150\t loss: 5.901, accuracy: 0.835\n",
      "iteration 86 160\t loss: 5.558, accuracy: 0.835\n",
      "iteration 86 170\t loss: 5.626, accuracy: 0.832\n",
      "iteration 86 180\t loss: 5.833, accuracy: 0.839\n",
      "iteration 86 190\t loss: 6.179, accuracy: 0.831\n",
      "iteration 86 200\t loss: 6.257, accuracy: 0.831\n",
      "iteration 86 210\t loss: 6.009, accuracy: 0.828\n",
      "iteration 86 220\t loss: 5.588, accuracy: 0.836\n",
      "iteration 86 230\t loss: 5.784, accuracy: 0.831\n",
      "iteration 86 240\t loss: 5.925, accuracy: 0.839\n",
      "iteration 86 250\t loss: 5.836, accuracy: 0.837\n",
      "iteration 86 260\t loss: 5.955, accuracy: 0.837\n",
      "iteration 86 270\t loss: 6.193, accuracy: 0.839\n",
      "iteration 86 280\t loss: 6.475, accuracy: 0.845\n",
      "iteration 87 0\t loss: 6.288, accuracy: 0.844\n",
      "iteration 87 10\t loss: 6.071, accuracy: 0.839\n",
      "iteration 87 20\t loss: 5.799, accuracy: 0.840\n",
      "iteration 87 30\t loss: 5.759, accuracy: 0.842\n",
      "iteration 87 40\t loss: 6.087, accuracy: 0.842\n",
      "iteration 87 50\t loss: 6.299, accuracy: 0.839\n",
      "iteration 87 60\t loss: 6.483, accuracy: 0.836\n",
      "iteration 87 70\t loss: 5.938, accuracy: 0.830\n",
      "iteration 87 80\t loss: 6.283, accuracy: 0.833\n",
      "iteration 87 90\t loss: 6.642, accuracy: 0.841\n",
      "iteration 87 100\t loss: 5.816, accuracy: 0.834\n",
      "iteration 87 110\t loss: 5.592, accuracy: 0.839\n",
      "iteration 87 120\t loss: 6.054, accuracy: 0.844\n",
      "iteration 87 130\t loss: 5.975, accuracy: 0.843\n",
      "iteration 87 140\t loss: 5.906, accuracy: 0.844\n",
      "iteration 87 150\t loss: 5.851, accuracy: 0.840\n",
      "iteration 87 160\t loss: 5.638, accuracy: 0.836\n",
      "iteration 87 170\t loss: 5.762, accuracy: 0.838\n",
      "iteration 87 180\t loss: 5.925, accuracy: 0.843\n",
      "iteration 87 190\t loss: 6.349, accuracy: 0.836\n",
      "iteration 87 200\t loss: 5.885, accuracy: 0.831\n",
      "iteration 87 210\t loss: 6.179, accuracy: 0.837\n",
      "iteration 87 220\t loss: 5.354, accuracy: 0.838\n",
      "iteration 87 230\t loss: 5.682, accuracy: 0.831\n",
      "iteration 87 240\t loss: 5.925, accuracy: 0.836\n",
      "iteration 87 250\t loss: 5.535, accuracy: 0.840\n",
      "iteration 87 260\t loss: 6.008, accuracy: 0.835\n",
      "iteration 87 270\t loss: 5.978, accuracy: 0.840\n",
      "iteration 87 280\t loss: 5.943, accuracy: 0.837\n",
      "iteration 88 0\t loss: 6.681, accuracy: 0.841\n",
      "iteration 88 10\t loss: 6.953, accuracy: 0.840\n",
      "iteration 88 20\t loss: 6.429, accuracy: 0.845\n",
      "iteration 88 30\t loss: 5.994, accuracy: 0.841\n",
      "iteration 88 40\t loss: 6.246, accuracy: 0.840\n",
      "iteration 88 50\t loss: 6.955, accuracy: 0.837\n",
      "iteration 88 60\t loss: 6.659, accuracy: 0.836\n",
      "iteration 88 70\t loss: 6.100, accuracy: 0.835\n",
      "iteration 88 80\t loss: 6.090, accuracy: 0.838\n",
      "iteration 88 90\t loss: 6.458, accuracy: 0.839\n",
      "iteration 88 100\t loss: 6.521, accuracy: 0.836\n",
      "iteration 88 110\t loss: 6.060, accuracy: 0.830\n",
      "iteration 88 120\t loss: 6.259, accuracy: 0.837\n",
      "iteration 88 130\t loss: 6.057, accuracy: 0.841\n",
      "iteration 88 140\t loss: 6.163, accuracy: 0.843\n",
      "iteration 88 150\t loss: 6.704, accuracy: 0.839\n",
      "iteration 88 160\t loss: 5.864, accuracy: 0.831\n",
      "iteration 88 170\t loss: 6.146, accuracy: 0.831\n",
      "iteration 88 180\t loss: 6.340, accuracy: 0.842\n",
      "iteration 88 190\t loss: 6.872, accuracy: 0.831\n",
      "iteration 88 200\t loss: 6.966, accuracy: 0.813\n",
      "iteration 88 210\t loss: 6.588, accuracy: 0.833\n",
      "iteration 88 220\t loss: 5.956, accuracy: 0.835\n",
      "iteration 88 230\t loss: 6.026, accuracy: 0.835\n",
      "iteration 88 240\t loss: 6.331, accuracy: 0.835\n",
      "iteration 88 250\t loss: 6.480, accuracy: 0.845\n",
      "iteration 88 260\t loss: 6.665, accuracy: 0.843\n",
      "iteration 88 270\t loss: 6.592, accuracy: 0.838\n",
      "iteration 88 280\t loss: 6.394, accuracy: 0.845\n",
      "iteration 89 0\t loss: 6.277, accuracy: 0.844\n",
      "iteration 89 10\t loss: 6.437, accuracy: 0.842\n",
      "iteration 89 20\t loss: 6.239, accuracy: 0.842\n",
      "iteration 89 30\t loss: 6.284, accuracy: 0.842\n",
      "iteration 89 40\t loss: 6.203, accuracy: 0.840\n",
      "iteration 89 50\t loss: 6.647, accuracy: 0.841\n",
      "iteration 89 60\t loss: 6.907, accuracy: 0.828\n",
      "iteration 89 70\t loss: 6.059, accuracy: 0.822\n",
      "iteration 89 80\t loss: 5.915, accuracy: 0.834\n",
      "iteration 89 90\t loss: 6.634, accuracy: 0.838\n",
      "iteration 89 100\t loss: 6.309, accuracy: 0.832\n",
      "iteration 89 110\t loss: 6.555, accuracy: 0.836\n",
      "iteration 89 120\t loss: 7.161, accuracy: 0.838\n",
      "iteration 89 130\t loss: 6.366, accuracy: 0.844\n",
      "iteration 89 140\t loss: 6.231, accuracy: 0.840\n",
      "iteration 89 150\t loss: 6.205, accuracy: 0.836\n",
      "iteration 89 160\t loss: 5.975, accuracy: 0.832\n",
      "iteration 89 170\t loss: 5.868, accuracy: 0.829\n",
      "iteration 89 180\t loss: 5.983, accuracy: 0.843\n",
      "iteration 89 190\t loss: 6.818, accuracy: 0.835\n",
      "iteration 89 200\t loss: 6.766, accuracy: 0.827\n",
      "iteration 89 210\t loss: 5.951, accuracy: 0.830\n",
      "iteration 89 220\t loss: 5.950, accuracy: 0.832\n",
      "iteration 89 230\t loss: 6.238, accuracy: 0.830\n",
      "iteration 89 240\t loss: 6.031, accuracy: 0.831\n",
      "iteration 89 250\t loss: 6.110, accuracy: 0.841\n",
      "iteration 89 260\t loss: 6.778, accuracy: 0.840\n",
      "iteration 89 270\t loss: 6.568, accuracy: 0.843\n",
      "iteration 89 280\t loss: 6.358, accuracy: 0.845\n",
      "iteration 90 0\t loss: 6.498, accuracy: 0.842\n",
      "iteration 90 10\t loss: 6.421, accuracy: 0.844\n",
      "iteration 90 20\t loss: 6.258, accuracy: 0.842\n",
      "iteration 90 30\t loss: 6.664, accuracy: 0.846\n",
      "iteration 90 40\t loss: 6.746, accuracy: 0.843\n",
      "iteration 90 50\t loss: 6.318, accuracy: 0.842\n",
      "iteration 90 60\t loss: 6.501, accuracy: 0.843\n",
      "iteration 90 70\t loss: 6.233, accuracy: 0.838\n",
      "iteration 90 80\t loss: 6.037, accuracy: 0.833\n",
      "iteration 90 90\t loss: 6.367, accuracy: 0.839\n",
      "iteration 90 100\t loss: 6.246, accuracy: 0.834\n",
      "iteration 90 110\t loss: 6.173, accuracy: 0.832\n",
      "iteration 90 120\t loss: 6.172, accuracy: 0.832\n",
      "iteration 90 130\t loss: 5.943, accuracy: 0.837\n",
      "iteration 90 140\t loss: 6.327, accuracy: 0.840\n",
      "iteration 90 150\t loss: 6.172, accuracy: 0.839\n",
      "iteration 90 160\t loss: 5.992, accuracy: 0.833\n",
      "iteration 90 170\t loss: 5.813, accuracy: 0.829\n",
      "iteration 90 180\t loss: 6.295, accuracy: 0.841\n",
      "iteration 90 190\t loss: 6.768, accuracy: 0.832\n",
      "iteration 90 200\t loss: 6.459, accuracy: 0.832\n",
      "iteration 90 210\t loss: 6.225, accuracy: 0.824\n",
      "iteration 90 220\t loss: 5.808, accuracy: 0.830\n",
      "iteration 90 230\t loss: 6.416, accuracy: 0.822\n",
      "iteration 90 240\t loss: 5.993, accuracy: 0.831\n",
      "iteration 90 250\t loss: 5.644, accuracy: 0.838\n",
      "iteration 90 260\t loss: 6.330, accuracy: 0.846\n",
      "iteration 90 270\t loss: 6.976, accuracy: 0.839\n",
      "iteration 90 280\t loss: 6.990, accuracy: 0.839\n",
      "iteration 91 0\t loss: 6.660, accuracy: 0.840\n",
      "iteration 91 10\t loss: 6.852, accuracy: 0.843\n",
      "iteration 91 20\t loss: 6.622, accuracy: 0.843\n",
      "iteration 91 30\t loss: 6.435, accuracy: 0.846\n",
      "iteration 91 40\t loss: 6.735, accuracy: 0.843\n",
      "iteration 91 50\t loss: 7.218, accuracy: 0.845\n",
      "iteration 91 60\t loss: 7.530, accuracy: 0.840\n",
      "iteration 91 70\t loss: 6.466, accuracy: 0.830\n",
      "iteration 91 80\t loss: 6.171, accuracy: 0.835\n",
      "iteration 91 90\t loss: 6.517, accuracy: 0.841\n",
      "iteration 91 100\t loss: 6.499, accuracy: 0.841\n",
      "iteration 91 110\t loss: 6.178, accuracy: 0.833\n",
      "iteration 91 120\t loss: 6.053, accuracy: 0.837\n",
      "iteration 91 130\t loss: 6.241, accuracy: 0.840\n",
      "iteration 91 140\t loss: 6.401, accuracy: 0.837\n",
      "iteration 91 150\t loss: 6.423, accuracy: 0.841\n",
      "iteration 91 160\t loss: 6.198, accuracy: 0.835\n",
      "iteration 91 170\t loss: 6.152, accuracy: 0.834\n",
      "iteration 91 180\t loss: 6.445, accuracy: 0.839\n",
      "iteration 91 190\t loss: 7.001, accuracy: 0.829\n",
      "iteration 91 200\t loss: 6.822, accuracy: 0.821\n",
      "iteration 91 210\t loss: 6.045, accuracy: 0.832\n",
      "iteration 91 220\t loss: 5.858, accuracy: 0.832\n",
      "iteration 91 230\t loss: 6.222, accuracy: 0.843\n",
      "iteration 91 240\t loss: 6.257, accuracy: 0.834\n",
      "iteration 91 250\t loss: 6.176, accuracy: 0.840\n",
      "iteration 91 260\t loss: 6.177, accuracy: 0.843\n",
      "iteration 91 270\t loss: 6.363, accuracy: 0.838\n",
      "iteration 91 280\t loss: 6.665, accuracy: 0.847\n",
      "iteration 92 0\t loss: 6.817, accuracy: 0.846\n",
      "iteration 92 10\t loss: 6.655, accuracy: 0.846\n",
      "iteration 92 20\t loss: 6.415, accuracy: 0.846\n",
      "iteration 92 30\t loss: 6.083, accuracy: 0.849\n",
      "iteration 92 40\t loss: 6.260, accuracy: 0.848\n",
      "iteration 92 50\t loss: 6.443, accuracy: 0.844\n",
      "iteration 92 60\t loss: 6.454, accuracy: 0.844\n",
      "iteration 92 70\t loss: 6.257, accuracy: 0.833\n",
      "iteration 92 80\t loss: 6.533, accuracy: 0.839\n",
      "iteration 92 90\t loss: 6.627, accuracy: 0.842\n",
      "iteration 92 100\t loss: 6.460, accuracy: 0.843\n",
      "iteration 92 110\t loss: 6.313, accuracy: 0.837\n",
      "iteration 92 120\t loss: 6.267, accuracy: 0.843\n",
      "iteration 92 130\t loss: 6.654, accuracy: 0.845\n",
      "iteration 92 140\t loss: 6.964, accuracy: 0.844\n",
      "iteration 92 150\t loss: 6.757, accuracy: 0.842\n",
      "iteration 92 160\t loss: 6.322, accuracy: 0.837\n",
      "iteration 92 170\t loss: 6.403, accuracy: 0.835\n",
      "iteration 92 180\t loss: 6.228, accuracy: 0.841\n",
      "iteration 92 190\t loss: 6.715, accuracy: 0.838\n",
      "iteration 92 200\t loss: 6.703, accuracy: 0.837\n",
      "iteration 92 210\t loss: 6.480, accuracy: 0.834\n",
      "iteration 92 220\t loss: 6.337, accuracy: 0.831\n",
      "iteration 92 230\t loss: 5.893, accuracy: 0.836\n",
      "iteration 92 240\t loss: 6.700, accuracy: 0.833\n",
      "iteration 92 250\t loss: 6.528, accuracy: 0.843\n",
      "iteration 92 260\t loss: 6.547, accuracy: 0.839\n",
      "iteration 92 270\t loss: 6.415, accuracy: 0.841\n",
      "iteration 92 280\t loss: 6.325, accuracy: 0.847\n",
      "iteration 93 0\t loss: 6.569, accuracy: 0.848\n",
      "iteration 93 10\t loss: 6.793, accuracy: 0.845\n",
      "iteration 93 20\t loss: 6.455, accuracy: 0.844\n",
      "iteration 93 30\t loss: 6.705, accuracy: 0.845\n",
      "iteration 93 40\t loss: 6.817, accuracy: 0.841\n",
      "iteration 93 50\t loss: 6.827, accuracy: 0.845\n",
      "iteration 93 60\t loss: 7.150, accuracy: 0.841\n",
      "iteration 93 70\t loss: 6.649, accuracy: 0.828\n",
      "iteration 93 80\t loss: 6.838, accuracy: 0.836\n",
      "iteration 93 90\t loss: 6.524, accuracy: 0.839\n",
      "iteration 93 100\t loss: 6.406, accuracy: 0.841\n",
      "iteration 93 110\t loss: 6.334, accuracy: 0.836\n",
      "iteration 93 120\t loss: 6.601, accuracy: 0.840\n",
      "iteration 93 130\t loss: 6.508, accuracy: 0.843\n",
      "iteration 93 140\t loss: 6.465, accuracy: 0.842\n",
      "iteration 93 150\t loss: 6.521, accuracy: 0.845\n",
      "iteration 93 160\t loss: 6.262, accuracy: 0.844\n",
      "iteration 93 170\t loss: 6.592, accuracy: 0.837\n",
      "iteration 93 180\t loss: 6.820, accuracy: 0.840\n",
      "iteration 93 190\t loss: 6.613, accuracy: 0.843\n",
      "iteration 93 200\t loss: 6.525, accuracy: 0.842\n",
      "iteration 93 210\t loss: 6.395, accuracy: 0.836\n",
      "iteration 93 220\t loss: 6.786, accuracy: 0.843\n",
      "iteration 93 230\t loss: 6.156, accuracy: 0.832\n",
      "iteration 93 240\t loss: 6.294, accuracy: 0.836\n",
      "iteration 93 250\t loss: 6.913, accuracy: 0.838\n",
      "iteration 93 260\t loss: 7.442, accuracy: 0.841\n",
      "iteration 93 270\t loss: 7.423, accuracy: 0.837\n",
      "iteration 93 280\t loss: 6.657, accuracy: 0.846\n",
      "iteration 94 0\t loss: 6.516, accuracy: 0.846\n",
      "iteration 94 10\t loss: 6.888, accuracy: 0.844\n",
      "iteration 94 20\t loss: 6.981, accuracy: 0.845\n",
      "iteration 94 30\t loss: 6.922, accuracy: 0.845\n",
      "iteration 94 40\t loss: 7.377, accuracy: 0.842\n",
      "iteration 94 50\t loss: 7.377, accuracy: 0.840\n",
      "iteration 94 60\t loss: 6.991, accuracy: 0.845\n",
      "iteration 94 70\t loss: 6.402, accuracy: 0.839\n",
      "iteration 94 80\t loss: 6.966, accuracy: 0.829\n",
      "iteration 94 90\t loss: 7.513, accuracy: 0.840\n",
      "iteration 94 100\t loss: 7.355, accuracy: 0.832\n",
      "iteration 94 110\t loss: 7.063, accuracy: 0.834\n",
      "iteration 94 120\t loss: 6.777, accuracy: 0.835\n",
      "iteration 94 130\t loss: 6.442, accuracy: 0.842\n",
      "iteration 94 140\t loss: 6.443, accuracy: 0.841\n",
      "iteration 94 150\t loss: 6.494, accuracy: 0.843\n",
      "iteration 94 160\t loss: 5.729, accuracy: 0.839\n",
      "iteration 94 170\t loss: 6.160, accuracy: 0.839\n",
      "iteration 94 180\t loss: 6.710, accuracy: 0.842\n",
      "iteration 94 190\t loss: 7.184, accuracy: 0.844\n",
      "iteration 94 200\t loss: 6.535, accuracy: 0.835\n",
      "iteration 94 210\t loss: 6.480, accuracy: 0.829\n",
      "iteration 94 220\t loss: 6.289, accuracy: 0.831\n",
      "iteration 94 230\t loss: 6.585, accuracy: 0.837\n",
      "iteration 94 240\t loss: 6.861, accuracy: 0.832\n",
      "iteration 94 250\t loss: 6.841, accuracy: 0.841\n",
      "iteration 94 260\t loss: 7.352, accuracy: 0.834\n",
      "iteration 94 270\t loss: 6.924, accuracy: 0.833\n",
      "iteration 94 280\t loss: 7.237, accuracy: 0.847\n",
      "iteration 95 0\t loss: 6.995, accuracy: 0.842\n",
      "iteration 95 10\t loss: 6.761, accuracy: 0.843\n",
      "iteration 95 20\t loss: 6.993, accuracy: 0.842\n",
      "iteration 95 30\t loss: 7.349, accuracy: 0.841\n",
      "iteration 95 40\t loss: 7.340, accuracy: 0.845\n",
      "iteration 95 50\t loss: 7.242, accuracy: 0.838\n",
      "iteration 95 60\t loss: 6.967, accuracy: 0.838\n",
      "iteration 95 70\t loss: 7.068, accuracy: 0.838\n",
      "iteration 95 80\t loss: 6.799, accuracy: 0.836\n",
      "iteration 95 90\t loss: 7.029, accuracy: 0.841\n",
      "iteration 95 100\t loss: 6.487, accuracy: 0.844\n",
      "iteration 95 110\t loss: 6.121, accuracy: 0.839\n",
      "iteration 95 120\t loss: 6.428, accuracy: 0.841\n",
      "iteration 95 130\t loss: 6.755, accuracy: 0.845\n",
      "iteration 95 140\t loss: 6.796, accuracy: 0.844\n",
      "iteration 95 150\t loss: 6.606, accuracy: 0.845\n",
      "iteration 95 160\t loss: 6.474, accuracy: 0.835\n",
      "iteration 95 170\t loss: 6.626, accuracy: 0.835\n",
      "iteration 95 180\t loss: 6.599, accuracy: 0.844\n",
      "iteration 95 190\t loss: 7.363, accuracy: 0.841\n",
      "iteration 95 200\t loss: 7.587, accuracy: 0.828\n",
      "iteration 95 210\t loss: 6.764, accuracy: 0.831\n",
      "iteration 95 220\t loss: 6.769, accuracy: 0.839\n",
      "iteration 95 230\t loss: 6.319, accuracy: 0.823\n",
      "iteration 95 240\t loss: 7.117, accuracy: 0.831\n",
      "iteration 95 250\t loss: 7.078, accuracy: 0.839\n",
      "iteration 95 260\t loss: 7.082, accuracy: 0.840\n",
      "iteration 95 270\t loss: 7.196, accuracy: 0.834\n",
      "iteration 95 280\t loss: 6.991, accuracy: 0.842\n",
      "iteration 96 0\t loss: 7.008, accuracy: 0.845\n",
      "iteration 96 10\t loss: 6.997, accuracy: 0.845\n",
      "iteration 96 20\t loss: 7.240, accuracy: 0.843\n",
      "iteration 96 30\t loss: 7.188, accuracy: 0.841\n",
      "iteration 96 40\t loss: 7.044, accuracy: 0.846\n",
      "iteration 96 50\t loss: 7.606, accuracy: 0.838\n",
      "iteration 96 60\t loss: 7.525, accuracy: 0.838\n",
      "iteration 96 70\t loss: 6.715, accuracy: 0.826\n",
      "iteration 96 80\t loss: 7.228, accuracy: 0.833\n",
      "iteration 96 90\t loss: 8.184, accuracy: 0.833\n",
      "iteration 96 100\t loss: 6.992, accuracy: 0.834\n",
      "iteration 96 110\t loss: 6.922, accuracy: 0.838\n",
      "iteration 96 120\t loss: 6.521, accuracy: 0.835\n",
      "iteration 96 130\t loss: 6.794, accuracy: 0.833\n",
      "iteration 96 140\t loss: 6.513, accuracy: 0.837\n",
      "iteration 96 150\t loss: 7.409, accuracy: 0.840\n",
      "iteration 96 160\t loss: 6.847, accuracy: 0.835\n",
      "iteration 96 170\t loss: 6.649, accuracy: 0.840\n",
      "iteration 96 180\t loss: 6.871, accuracy: 0.841\n",
      "iteration 96 190\t loss: 7.808, accuracy: 0.840\n",
      "iteration 96 200\t loss: 7.904, accuracy: 0.824\n",
      "iteration 96 210\t loss: 7.115, accuracy: 0.819\n",
      "iteration 96 220\t loss: 6.955, accuracy: 0.838\n",
      "iteration 96 230\t loss: 6.576, accuracy: 0.829\n",
      "iteration 96 240\t loss: 6.748, accuracy: 0.833\n",
      "iteration 96 250\t loss: 6.960, accuracy: 0.841\n",
      "iteration 96 260\t loss: 7.101, accuracy: 0.840\n",
      "iteration 96 270\t loss: 6.937, accuracy: 0.836\n",
      "iteration 96 280\t loss: 6.421, accuracy: 0.843\n",
      "iteration 97 0\t loss: 6.498, accuracy: 0.844\n",
      "iteration 97 10\t loss: 6.823, accuracy: 0.843\n",
      "iteration 97 20\t loss: 6.982, accuracy: 0.844\n",
      "iteration 97 30\t loss: 7.209, accuracy: 0.845\n",
      "iteration 97 40\t loss: 7.399, accuracy: 0.843\n",
      "iteration 97 50\t loss: 7.505, accuracy: 0.842\n",
      "iteration 97 60\t loss: 7.384, accuracy: 0.842\n",
      "iteration 97 70\t loss: 6.659, accuracy: 0.838\n",
      "iteration 97 80\t loss: 6.701, accuracy: 0.832\n",
      "iteration 97 90\t loss: 7.581, accuracy: 0.842\n",
      "iteration 97 100\t loss: 7.111, accuracy: 0.843\n",
      "iteration 97 110\t loss: 6.332, accuracy: 0.840\n",
      "iteration 97 120\t loss: 6.452, accuracy: 0.839\n",
      "iteration 97 130\t loss: 7.345, accuracy: 0.844\n",
      "iteration 97 140\t loss: 7.393, accuracy: 0.843\n",
      "iteration 97 150\t loss: 6.740, accuracy: 0.844\n",
      "iteration 97 160\t loss: 6.713, accuracy: 0.837\n",
      "iteration 97 170\t loss: 6.207, accuracy: 0.836\n",
      "iteration 97 180\t loss: 6.687, accuracy: 0.843\n",
      "iteration 97 190\t loss: 7.549, accuracy: 0.844\n",
      "iteration 97 200\t loss: 7.867, accuracy: 0.828\n",
      "iteration 97 210\t loss: 6.989, accuracy: 0.825\n",
      "iteration 97 220\t loss: 6.821, accuracy: 0.830\n",
      "iteration 97 230\t loss: 7.161, accuracy: 0.839\n",
      "iteration 97 240\t loss: 6.651, accuracy: 0.830\n",
      "iteration 97 250\t loss: 7.025, accuracy: 0.839\n",
      "iteration 97 260\t loss: 7.707, accuracy: 0.840\n",
      "iteration 97 270\t loss: 7.421, accuracy: 0.842\n",
      "iteration 97 280\t loss: 7.330, accuracy: 0.841\n",
      "iteration 98 0\t loss: 7.132, accuracy: 0.841\n",
      "iteration 98 10\t loss: 7.055, accuracy: 0.839\n",
      "iteration 98 20\t loss: 6.875, accuracy: 0.844\n",
      "iteration 98 30\t loss: 7.237, accuracy: 0.845\n",
      "iteration 98 40\t loss: 7.357, accuracy: 0.845\n",
      "iteration 98 50\t loss: 7.668, accuracy: 0.839\n",
      "iteration 98 60\t loss: 7.403, accuracy: 0.835\n",
      "iteration 98 70\t loss: 6.798, accuracy: 0.844\n",
      "iteration 98 80\t loss: 6.764, accuracy: 0.828\n",
      "iteration 98 90\t loss: 7.404, accuracy: 0.842\n",
      "iteration 98 100\t loss: 7.700, accuracy: 0.844\n",
      "iteration 98 110\t loss: 7.111, accuracy: 0.843\n",
      "iteration 98 120\t loss: 6.298, accuracy: 0.835\n",
      "iteration 98 130\t loss: 6.820, accuracy: 0.844\n",
      "iteration 98 140\t loss: 6.841, accuracy: 0.841\n",
      "iteration 98 150\t loss: 6.799, accuracy: 0.843\n",
      "iteration 98 160\t loss: 6.949, accuracy: 0.840\n",
      "iteration 98 170\t loss: 6.188, accuracy: 0.832\n",
      "iteration 98 180\t loss: 6.794, accuracy: 0.844\n",
      "iteration 98 190\t loss: 7.129, accuracy: 0.845\n",
      "iteration 98 200\t loss: 7.300, accuracy: 0.832\n",
      "iteration 98 210\t loss: 6.887, accuracy: 0.841\n",
      "iteration 98 220\t loss: 6.557, accuracy: 0.830\n",
      "iteration 98 230\t loss: 6.472, accuracy: 0.837\n",
      "iteration 98 240\t loss: 6.795, accuracy: 0.838\n",
      "iteration 98 250\t loss: 7.066, accuracy: 0.842\n",
      "iteration 98 260\t loss: 7.557, accuracy: 0.840\n",
      "iteration 98 270\t loss: 7.409, accuracy: 0.840\n",
      "iteration 98 280\t loss: 7.083, accuracy: 0.844\n",
      "iteration 99 0\t loss: 7.208, accuracy: 0.846\n",
      "iteration 99 10\t loss: 6.784, accuracy: 0.842\n",
      "iteration 99 20\t loss: 6.838, accuracy: 0.846\n",
      "iteration 99 30\t loss: 7.482, accuracy: 0.846\n",
      "iteration 99 40\t loss: 7.624, accuracy: 0.846\n",
      "iteration 99 50\t loss: 7.418, accuracy: 0.847\n",
      "iteration 99 60\t loss: 7.385, accuracy: 0.843\n",
      "iteration 99 70\t loss: 7.055, accuracy: 0.844\n",
      "iteration 99 80\t loss: 7.089, accuracy: 0.836\n",
      "iteration 99 90\t loss: 6.805, accuracy: 0.844\n",
      "iteration 99 100\t loss: 7.315, accuracy: 0.844\n",
      "iteration 99 110\t loss: 7.226, accuracy: 0.839\n",
      "iteration 99 120\t loss: 6.393, accuracy: 0.834\n",
      "iteration 99 130\t loss: 6.836, accuracy: 0.845\n",
      "iteration 99 140\t loss: 7.147, accuracy: 0.847\n",
      "iteration 99 150\t loss: 6.928, accuracy: 0.847\n",
      "iteration 99 160\t loss: 6.524, accuracy: 0.836\n",
      "iteration 99 170\t loss: 6.844, accuracy: 0.837\n",
      "iteration 99 180\t loss: 7.081, accuracy: 0.841\n",
      "iteration 99 190\t loss: 7.172, accuracy: 0.845\n",
      "iteration 99 200\t loss: 7.364, accuracy: 0.839\n",
      "iteration 99 210\t loss: 7.352, accuracy: 0.836\n",
      "iteration 99 220\t loss: 7.163, accuracy: 0.827\n",
      "iteration 99 230\t loss: 6.543, accuracy: 0.829\n",
      "iteration 99 240\t loss: 6.786, accuracy: 0.838\n",
      "iteration 99 250\t loss: 6.832, accuracy: 0.844\n",
      "iteration 99 260\t loss: 7.184, accuracy: 0.844\n",
      "iteration 99 270\t loss: 7.444, accuracy: 0.842\n",
      "iteration 99 280\t loss: 7.211, accuracy: 0.844\n",
      "Model saved in file: my-model\n",
      "True\n",
      "iteration 0 0\t loss: 28.490, accuracy: 0.111\n",
      "iteration 0 10\t loss: 2.490, accuracy: 0.179\n",
      "iteration 0 20\t loss: 2.257, accuracy: 0.183\n",
      "iteration 0 30\t loss: 2.242, accuracy: 0.193\n",
      "iteration 0 40\t loss: 2.236, accuracy: 0.196\n",
      "iteration 0 50\t loss: 2.233, accuracy: 0.196\n",
      "iteration 0 60\t loss: 2.230, accuracy: 0.196\n",
      "iteration 0 70\t loss: 2.225, accuracy: 0.196\n",
      "iteration 0 80\t loss: 2.221, accuracy: 0.196\n",
      "iteration 0 90\t loss: 2.216, accuracy: 0.196\n",
      "iteration 0 100\t loss: 2.217, accuracy: 0.196\n",
      "iteration 0 110\t loss: 2.203, accuracy: 0.197\n",
      "iteration 0 120\t loss: 2.207, accuracy: 0.198\n",
      "iteration 0 130\t loss: 2.153, accuracy: 0.260\n",
      "iteration 0 140\t loss: 2.088, accuracy: 0.276\n",
      "iteration 0 150\t loss: 2.034, accuracy: 0.327\n",
      "iteration 0 160\t loss: 1.953, accuracy: 0.363\n",
      "iteration 0 170\t loss: 1.816, accuracy: 0.407\n",
      "iteration 0 180\t loss: 1.662, accuracy: 0.459\n",
      "iteration 0 190\t loss: 1.607, accuracy: 0.477\n",
      "iteration 0 200\t loss: 1.602, accuracy: 0.481\n",
      "iteration 0 210\t loss: 1.445, accuracy: 0.537\n",
      "iteration 0 220\t loss: 1.412, accuracy: 0.553\n",
      "iteration 0 230\t loss: 1.336, accuracy: 0.583\n",
      "iteration 0 240\t loss: 1.330, accuracy: 0.574\n",
      "iteration 0 250\t loss: 1.254, accuracy: 0.615\n",
      "iteration 0 260\t loss: 1.224, accuracy: 0.624\n",
      "iteration 0 270\t loss: 1.152, accuracy: 0.643\n",
      "iteration 0 280\t loss: 1.163, accuracy: 0.641\n",
      "iteration 1 0\t loss: 1.199, accuracy: 0.630\n",
      "iteration 1 10\t loss: 1.106, accuracy: 0.665\n",
      "iteration 1 20\t loss: 1.132, accuracy: 0.656\n",
      "iteration 1 30\t loss: 1.082, accuracy: 0.667\n",
      "iteration 1 40\t loss: 1.057, accuracy: 0.682\n",
      "iteration 1 50\t loss: 1.054, accuracy: 0.679\n",
      "iteration 1 60\t loss: 1.029, accuracy: 0.692\n",
      "iteration 1 70\t loss: 1.025, accuracy: 0.690\n",
      "iteration 1 80\t loss: 0.980, accuracy: 0.708\n",
      "iteration 1 90\t loss: 0.965, accuracy: 0.707\n",
      "iteration 1 100\t loss: 0.971, accuracy: 0.707\n",
      "iteration 1 110\t loss: 0.966, accuracy: 0.709\n",
      "iteration 1 120\t loss: 0.923, accuracy: 0.719\n",
      "iteration 1 130\t loss: 0.958, accuracy: 0.709\n",
      "iteration 1 140\t loss: 0.899, accuracy: 0.728\n",
      "iteration 1 150\t loss: 0.901, accuracy: 0.726\n",
      "iteration 1 160\t loss: 0.918, accuracy: 0.727\n",
      "iteration 1 170\t loss: 0.910, accuracy: 0.735\n",
      "iteration 1 180\t loss: 0.885, accuracy: 0.732\n",
      "iteration 1 190\t loss: 0.891, accuracy: 0.737\n",
      "iteration 1 200\t loss: 0.898, accuracy: 0.733\n",
      "iteration 1 210\t loss: 0.877, accuracy: 0.739\n",
      "iteration 1 220\t loss: 0.899, accuracy: 0.728\n",
      "iteration 1 230\t loss: 0.903, accuracy: 0.723\n",
      "iteration 1 240\t loss: 0.809, accuracy: 0.763\n",
      "iteration 1 250\t loss: 0.825, accuracy: 0.754\n",
      "iteration 1 260\t loss: 0.860, accuracy: 0.749\n",
      "iteration 1 270\t loss: 0.817, accuracy: 0.758\n",
      "iteration 1 280\t loss: 0.828, accuracy: 0.749\n",
      "iteration 2 0\t loss: 0.771, accuracy: 0.776\n",
      "iteration 2 10\t loss: 0.798, accuracy: 0.764\n",
      "iteration 2 20\t loss: 0.779, accuracy: 0.769\n",
      "iteration 2 30\t loss: 0.777, accuracy: 0.772\n",
      "iteration 2 40\t loss: 0.800, accuracy: 0.762\n",
      "iteration 2 50\t loss: 0.775, accuracy: 0.772\n",
      "iteration 2 60\t loss: 0.772, accuracy: 0.778\n",
      "iteration 2 70\t loss: 0.754, accuracy: 0.778\n",
      "iteration 2 80\t loss: 0.744, accuracy: 0.782\n",
      "iteration 2 90\t loss: 0.755, accuracy: 0.776\n",
      "iteration 2 100\t loss: 0.760, accuracy: 0.775\n",
      "iteration 2 110\t loss: 0.753, accuracy: 0.779\n",
      "iteration 2 120\t loss: 0.738, accuracy: 0.780\n",
      "iteration 2 130\t loss: 0.772, accuracy: 0.775\n",
      "iteration 2 140\t loss: 0.707, accuracy: 0.794\n",
      "iteration 2 150\t loss: 0.717, accuracy: 0.793\n",
      "iteration 2 160\t loss: 0.732, accuracy: 0.783\n",
      "iteration 2 170\t loss: 0.754, accuracy: 0.783\n",
      "iteration 2 180\t loss: 0.718, accuracy: 0.787\n",
      "iteration 2 190\t loss: 0.726, accuracy: 0.794\n",
      "iteration 2 200\t loss: 0.748, accuracy: 0.783\n",
      "iteration 2 210\t loss: 0.729, accuracy: 0.792\n",
      "iteration 2 220\t loss: 0.676, accuracy: 0.803\n",
      "iteration 2 230\t loss: 0.707, accuracy: 0.794\n",
      "iteration 2 240\t loss: 0.706, accuracy: 0.794\n",
      "iteration 2 250\t loss: 0.695, accuracy: 0.800\n",
      "iteration 2 260\t loss: 0.732, accuracy: 0.795\n",
      "iteration 2 270\t loss: 0.730, accuracy: 0.786\n",
      "iteration 2 280\t loss: 0.715, accuracy: 0.789\n",
      "iteration 3 0\t loss: 0.678, accuracy: 0.803\n",
      "iteration 3 10\t loss: 0.685, accuracy: 0.803\n",
      "iteration 3 20\t loss: 0.693, accuracy: 0.798\n",
      "iteration 3 30\t loss: 0.687, accuracy: 0.797\n",
      "iteration 3 40\t loss: 0.716, accuracy: 0.788\n",
      "iteration 3 50\t loss: 0.659, accuracy: 0.810\n",
      "iteration 3 60\t loss: 0.685, accuracy: 0.803\n",
      "iteration 3 70\t loss: 0.655, accuracy: 0.810\n",
      "iteration 3 80\t loss: 0.677, accuracy: 0.802\n",
      "iteration 3 90\t loss: 0.694, accuracy: 0.798\n",
      "iteration 3 100\t loss: 0.659, accuracy: 0.806\n",
      "iteration 3 110\t loss: 0.699, accuracy: 0.798\n",
      "iteration 3 120\t loss: 0.678, accuracy: 0.798\n",
      "iteration 3 130\t loss: 0.688, accuracy: 0.801\n",
      "iteration 3 140\t loss: 0.652, accuracy: 0.813\n",
      "iteration 3 150\t loss: 0.679, accuracy: 0.814\n",
      "iteration 3 160\t loss: 0.681, accuracy: 0.799\n",
      "iteration 3 170\t loss: 0.724, accuracy: 0.794\n",
      "iteration 3 180\t loss: 0.679, accuracy: 0.799\n",
      "iteration 3 190\t loss: 0.651, accuracy: 0.819\n",
      "iteration 3 200\t loss: 0.665, accuracy: 0.811\n",
      "iteration 3 210\t loss: 0.676, accuracy: 0.809\n",
      "iteration 3 220\t loss: 0.641, accuracy: 0.816\n",
      "iteration 3 230\t loss: 0.683, accuracy: 0.808\n",
      "iteration 3 240\t loss: 0.651, accuracy: 0.816\n",
      "iteration 3 250\t loss: 0.695, accuracy: 0.810\n",
      "iteration 3 260\t loss: 0.686, accuracy: 0.805\n",
      "iteration 3 270\t loss: 0.664, accuracy: 0.809\n",
      "iteration 3 280\t loss: 0.673, accuracy: 0.805\n",
      "iteration 4 0\t loss: 0.632, accuracy: 0.813\n",
      "iteration 4 10\t loss: 0.650, accuracy: 0.826\n",
      "iteration 4 20\t loss: 0.668, accuracy: 0.811\n",
      "iteration 4 30\t loss: 0.660, accuracy: 0.807\n",
      "iteration 4 40\t loss: 0.640, accuracy: 0.816\n",
      "iteration 4 50\t loss: 0.650, accuracy: 0.820\n",
      "iteration 4 60\t loss: 0.672, accuracy: 0.803\n",
      "iteration 4 70\t loss: 0.635, accuracy: 0.820\n",
      "iteration 4 80\t loss: 0.634, accuracy: 0.817\n",
      "iteration 4 90\t loss: 0.629, accuracy: 0.823\n",
      "iteration 4 100\t loss: 0.645, accuracy: 0.813\n",
      "iteration 4 110\t loss: 0.662, accuracy: 0.811\n",
      "iteration 4 120\t loss: 0.634, accuracy: 0.814\n",
      "iteration 4 130\t loss: 0.684, accuracy: 0.806\n",
      "iteration 4 140\t loss: 0.662, accuracy: 0.809\n",
      "iteration 4 150\t loss: 0.674, accuracy: 0.817\n",
      "iteration 4 160\t loss: 0.659, accuracy: 0.803\n",
      "iteration 4 170\t loss: 0.626, accuracy: 0.825\n",
      "iteration 4 180\t loss: 0.641, accuracy: 0.819\n",
      "iteration 4 190\t loss: 0.625, accuracy: 0.820\n",
      "iteration 4 200\t loss: 0.629, accuracy: 0.827\n",
      "iteration 4 210\t loss: 0.634, accuracy: 0.820\n",
      "iteration 4 220\t loss: 0.614, accuracy: 0.831\n",
      "iteration 4 230\t loss: 0.609, accuracy: 0.828\n",
      "iteration 4 240\t loss: 0.629, accuracy: 0.825\n",
      "iteration 4 250\t loss: 0.638, accuracy: 0.827\n",
      "iteration 4 260\t loss: 0.652, accuracy: 0.817\n",
      "iteration 4 270\t loss: 0.652, accuracy: 0.816\n",
      "iteration 4 280\t loss: 0.637, accuracy: 0.828\n",
      "iteration 5 0\t loss: 0.597, accuracy: 0.831\n",
      "iteration 5 10\t loss: 0.619, accuracy: 0.833\n",
      "iteration 5 20\t loss: 0.633, accuracy: 0.827\n",
      "iteration 5 30\t loss: 0.628, accuracy: 0.822\n",
      "iteration 5 40\t loss: 0.614, accuracy: 0.825\n",
      "iteration 5 50\t loss: 0.632, accuracy: 0.830\n",
      "iteration 5 60\t loss: 0.679, accuracy: 0.807\n",
      "iteration 5 70\t loss: 0.604, accuracy: 0.828\n",
      "iteration 5 80\t loss: 0.613, accuracy: 0.822\n",
      "iteration 5 90\t loss: 0.616, accuracy: 0.828\n",
      "iteration 5 100\t loss: 0.661, accuracy: 0.809\n",
      "iteration 5 110\t loss: 0.671, accuracy: 0.808\n",
      "iteration 5 120\t loss: 0.626, accuracy: 0.820\n",
      "iteration 5 130\t loss: 0.652, accuracy: 0.816\n",
      "iteration 5 140\t loss: 0.628, accuracy: 0.823\n",
      "iteration 5 150\t loss: 0.651, accuracy: 0.826\n",
      "iteration 5 160\t loss: 0.613, accuracy: 0.821\n",
      "iteration 5 170\t loss: 0.638, accuracy: 0.826\n",
      "iteration 5 180\t loss: 0.614, accuracy: 0.830\n",
      "iteration 5 190\t loss: 0.608, accuracy: 0.827\n",
      "iteration 5 200\t loss: 0.615, accuracy: 0.836\n",
      "iteration 5 210\t loss: 0.648, accuracy: 0.815\n",
      "iteration 5 220\t loss: 0.639, accuracy: 0.827\n",
      "iteration 5 230\t loss: 0.626, accuracy: 0.826\n",
      "iteration 5 240\t loss: 0.635, accuracy: 0.825\n",
      "iteration 5 250\t loss: 0.677, accuracy: 0.813\n",
      "iteration 5 260\t loss: 0.677, accuracy: 0.820\n",
      "iteration 5 270\t loss: 0.648, accuracy: 0.820\n",
      "iteration 5 280\t loss: 0.651, accuracy: 0.832\n",
      "iteration 6 0\t loss: 0.612, accuracy: 0.829\n",
      "iteration 6 10\t loss: 0.593, accuracy: 0.839\n",
      "iteration 6 20\t loss: 0.616, accuracy: 0.833\n",
      "iteration 6 30\t loss: 0.613, accuracy: 0.825\n",
      "iteration 6 40\t loss: 0.615, accuracy: 0.828\n",
      "iteration 6 50\t loss: 0.620, accuracy: 0.833\n",
      "iteration 6 60\t loss: 0.643, accuracy: 0.822\n",
      "iteration 6 70\t loss: 0.596, accuracy: 0.836\n",
      "iteration 6 80\t loss: 0.595, accuracy: 0.830\n",
      "iteration 6 90\t loss: 0.600, accuracy: 0.837\n",
      "iteration 6 100\t loss: 0.658, accuracy: 0.815\n",
      "iteration 6 110\t loss: 0.729, accuracy: 0.798\n",
      "iteration 6 120\t loss: 0.612, accuracy: 0.828\n",
      "iteration 6 130\t loss: 0.693, accuracy: 0.818\n",
      "iteration 6 140\t loss: 0.632, accuracy: 0.821\n",
      "iteration 6 150\t loss: 0.667, accuracy: 0.826\n",
      "iteration 6 160\t loss: 0.635, accuracy: 0.817\n",
      "iteration 6 170\t loss: 0.623, accuracy: 0.832\n",
      "iteration 6 180\t loss: 0.614, accuracy: 0.831\n",
      "iteration 6 190\t loss: 0.630, accuracy: 0.825\n",
      "iteration 6 200\t loss: 0.616, accuracy: 0.839\n",
      "iteration 6 210\t loss: 0.624, accuracy: 0.832\n",
      "iteration 6 220\t loss: 0.636, accuracy: 0.833\n",
      "iteration 6 230\t loss: 0.703, accuracy: 0.814\n",
      "iteration 6 240\t loss: 0.648, accuracy: 0.824\n",
      "iteration 6 250\t loss: 0.691, accuracy: 0.807\n",
      "iteration 6 260\t loss: 0.688, accuracy: 0.824\n",
      "iteration 6 270\t loss: 0.677, accuracy: 0.816\n",
      "iteration 6 280\t loss: 0.677, accuracy: 0.829\n",
      "iteration 7 0\t loss: 0.638, accuracy: 0.826\n",
      "iteration 7 10\t loss: 0.608, accuracy: 0.839\n",
      "iteration 7 20\t loss: 0.623, accuracy: 0.831\n",
      "iteration 7 30\t loss: 0.650, accuracy: 0.822\n",
      "iteration 7 40\t loss: 0.620, accuracy: 0.830\n",
      "iteration 7 50\t loss: 0.621, accuracy: 0.837\n",
      "iteration 7 60\t loss: 0.610, accuracy: 0.841\n",
      "iteration 7 70\t loss: 0.614, accuracy: 0.836\n",
      "iteration 7 80\t loss: 0.593, accuracy: 0.834\n",
      "iteration 7 90\t loss: 0.613, accuracy: 0.841\n",
      "iteration 7 100\t loss: 0.677, accuracy: 0.819\n",
      "iteration 7 110\t loss: 0.816, accuracy: 0.785\n",
      "iteration 7 120\t loss: 0.647, accuracy: 0.829\n",
      "iteration 7 130\t loss: 0.639, accuracy: 0.829\n",
      "iteration 7 140\t loss: 0.626, accuracy: 0.827\n",
      "iteration 7 150\t loss: 0.658, accuracy: 0.823\n",
      "iteration 7 160\t loss: 0.622, accuracy: 0.822\n",
      "iteration 7 170\t loss: 0.630, accuracy: 0.839\n",
      "iteration 7 180\t loss: 0.621, accuracy: 0.834\n",
      "iteration 7 190\t loss: 0.658, accuracy: 0.824\n",
      "iteration 7 200\t loss: 0.645, accuracy: 0.839\n",
      "iteration 7 210\t loss: 0.610, accuracy: 0.839\n",
      "iteration 7 220\t loss: 0.670, accuracy: 0.830\n",
      "iteration 7 230\t loss: 0.653, accuracy: 0.830\n",
      "iteration 7 240\t loss: 0.645, accuracy: 0.825\n",
      "iteration 7 250\t loss: 0.702, accuracy: 0.815\n",
      "iteration 7 260\t loss: 0.625, accuracy: 0.837\n",
      "iteration 7 270\t loss: 0.733, accuracy: 0.813\n",
      "iteration 7 280\t loss: 0.698, accuracy: 0.827\n",
      "iteration 8 0\t loss: 0.649, accuracy: 0.834\n",
      "iteration 8 10\t loss: 0.686, accuracy: 0.822\n",
      "iteration 8 20\t loss: 0.653, accuracy: 0.827\n",
      "iteration 8 30\t loss: 0.667, accuracy: 0.824\n",
      "iteration 8 40\t loss: 0.663, accuracy: 0.833\n",
      "iteration 8 50\t loss: 0.618, accuracy: 0.834\n",
      "iteration 8 60\t loss: 0.669, accuracy: 0.833\n",
      "iteration 8 70\t loss: 0.631, accuracy: 0.826\n",
      "iteration 8 80\t loss: 0.636, accuracy: 0.835\n",
      "iteration 8 90\t loss: 0.608, accuracy: 0.830\n",
      "iteration 8 100\t loss: 0.694, accuracy: 0.821\n",
      "iteration 8 110\t loss: 0.751, accuracy: 0.807\n",
      "iteration 8 120\t loss: 0.713, accuracy: 0.822\n",
      "iteration 8 130\t loss: 0.714, accuracy: 0.815\n",
      "iteration 8 140\t loss: 0.668, accuracy: 0.824\n",
      "iteration 8 150\t loss: 0.626, accuracy: 0.831\n",
      "iteration 8 160\t loss: 0.632, accuracy: 0.822\n",
      "iteration 8 170\t loss: 0.620, accuracy: 0.842\n",
      "iteration 8 180\t loss: 0.630, accuracy: 0.835\n",
      "iteration 8 190\t loss: 0.654, accuracy: 0.826\n",
      "iteration 8 200\t loss: 0.654, accuracy: 0.840\n",
      "iteration 8 210\t loss: 0.635, accuracy: 0.836\n",
      "iteration 8 220\t loss: 0.643, accuracy: 0.837\n",
      "iteration 8 230\t loss: 0.622, accuracy: 0.844\n",
      "iteration 8 240\t loss: 0.705, accuracy: 0.808\n",
      "iteration 8 250\t loss: 0.668, accuracy: 0.833\n",
      "iteration 8 260\t loss: 0.636, accuracy: 0.842\n",
      "iteration 8 270\t loss: 0.684, accuracy: 0.829\n",
      "iteration 8 280\t loss: 0.722, accuracy: 0.828\n",
      "iteration 9 0\t loss: 0.661, accuracy: 0.834\n",
      "iteration 9 10\t loss: 0.643, accuracy: 0.834\n",
      "iteration 9 20\t loss: 0.706, accuracy: 0.821\n",
      "iteration 9 30\t loss: 0.655, accuracy: 0.837\n",
      "iteration 9 40\t loss: 0.717, accuracy: 0.834\n",
      "iteration 9 50\t loss: 0.650, accuracy: 0.830\n",
      "iteration 9 60\t loss: 0.655, accuracy: 0.835\n",
      "iteration 9 70\t loss: 0.633, accuracy: 0.836\n",
      "iteration 9 80\t loss: 0.680, accuracy: 0.822\n",
      "iteration 9 90\t loss: 0.642, accuracy: 0.830\n",
      "iteration 9 100\t loss: 0.656, accuracy: 0.837\n",
      "iteration 9 110\t loss: 0.687, accuracy: 0.826\n",
      "iteration 9 120\t loss: 0.767, accuracy: 0.823\n",
      "iteration 9 130\t loss: 0.686, accuracy: 0.815\n",
      "iteration 9 140\t loss: 0.735, accuracy: 0.829\n",
      "iteration 9 150\t loss: 0.662, accuracy: 0.838\n",
      "iteration 9 160\t loss: 0.631, accuracy: 0.833\n",
      "iteration 9 170\t loss: 0.629, accuracy: 0.841\n",
      "iteration 9 180\t loss: 0.635, accuracy: 0.834\n",
      "iteration 9 190\t loss: 0.664, accuracy: 0.830\n",
      "iteration 9 200\t loss: 0.719, accuracy: 0.832\n",
      "iteration 9 210\t loss: 0.662, accuracy: 0.833\n",
      "iteration 9 220\t loss: 0.668, accuracy: 0.839\n",
      "iteration 9 230\t loss: 0.659, accuracy: 0.837\n",
      "iteration 9 240\t loss: 0.739, accuracy: 0.801\n",
      "iteration 9 250\t loss: 0.695, accuracy: 0.838\n",
      "iteration 9 260\t loss: 0.692, accuracy: 0.836\n",
      "iteration 9 270\t loss: 0.702, accuracy: 0.831\n",
      "iteration 9 280\t loss: 0.721, accuracy: 0.830\n"
     ]
    }
   ],
   "source": [
    "test_saving()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fine-tuning a Pre-trained Network on CIFAR-10\n",
    "(20 points)\n",
    "\n",
    "[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) is another popular benchmark for image classification.\n",
    "We provide you with modified verstion of the file cifar10.py from [https://github.com/Hvass-Labs/TensorFlow-Tutorials](https://github.com/Hvass-Labs/TensorFlow-Tutorials).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import read_cifar10 as cf10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a generator for the CIFAR-10 Dataset, yielding the next batch every time next is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@read_data.restartable\n",
    "def cifar10_dataset_generator(dataset_name, batch_size, restrict_size=1000):\n",
    "    assert dataset_name in ['train', 'test']\n",
    "    assert batch_size > 0 or batch_size == -1  # -1 for entire dataset\n",
    "    \n",
    "    X_all_unrestricted, y_all = (cf10.load_training_data() if dataset_name == 'train'\n",
    "                                 else cf10.load_test_data())\n",
    "    \n",
    "    actual_restrict_size = restrict_size if dataset_name == 'train' else int(1e10)\n",
    "    X_all = X_all_unrestricted[:actual_restrict_size]\n",
    "    data_len = X_all.shape[0]\n",
    "    batch_size = batch_size if batch_size > 0 else data_len\n",
    "    \n",
    "    X_all_padded = np.concatenate([X_all, X_all[:batch_size]], axis=0)\n",
    "    y_all_padded = np.concatenate([y_all, y_all[:batch_size]], axis=0)\n",
    "    \n",
    "    for slice_i in range(math.ceil(data_len / batch_size)):\n",
    "        idx = slice_i * batch_size\n",
    "        X_batch = X_all_padded[idx:idx + batch_size]*255\n",
    "        y_batch = np.ravel(y_all_padded[idx:idx + batch_size])\n",
    "        yield X_batch.astype(np.uint8), y_batch.astype(np.uint8)\n",
    "\n",
    "cifar10_dataset_generators = {\n",
    "    'train': cifar10_dataset_generator('train', 1000),\n",
    "    'test': cifar10_dataset_generator('test', -1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1 Fine-tuning\n",
    "Let's fine-tune SVHN net on **1000 examples** from CIFAR-10. \n",
    "Compare test accuracies of the following scenarios: \n",
    "  - Training `cnn_map` from scratch on the 1000 CIFAR-10 examples\n",
    "  - Fine-tuning SVHN net (`cnn_map` trained on SVHN dataset) on 1000 exampes from CIFAR-10. Use `new_train_model()` defined above to load SVHN net weights, but train on the CIFAR-10 examples.\n",
    "  \n",
    "**Important:** please do not change the `restrict_size=1000` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Results:**  \n",
    "  \n",
    "Run 1:\n",
    "  \n",
    "Accuracy for training cnn_map from scratch on the 1000 CIFAR examples: 0.352   \n",
    "Accuracy for training cnn_map using loaded SVHN weights: 0.332 \n",
    "(these results shown below)\n",
    "\n",
    "Run 2:\n",
    "  \n",
    "Accuracy for training cnn_map from scratch on the 1000 CIFAR examples: 0.320 \n",
    "Accuracy for training cnn_map using loaded SVHN weights: 0.343\n",
    "\n",
    "My results show that I am getting similar accuracies with both methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn_expanded_dict = apply_classification_loss(cnn_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 0\t loss: 44.126, accuracy: 0.110\n",
      "iteration 1 0\t loss: 40.660, accuracy: 0.106\n",
      "iteration 2 0\t loss: 45.088, accuracy: 0.100\n",
      "iteration 3 0\t loss: 25.023, accuracy: 0.102\n",
      "iteration 4 0\t loss: 18.011, accuracy: 0.103\n",
      "iteration 5 0\t loss: 11.468, accuracy: 0.099\n",
      "iteration 6 0\t loss: 7.698, accuracy: 0.100\n",
      "iteration 7 0\t loss: 5.025, accuracy: 0.093\n",
      "iteration 8 0\t loss: 3.763, accuracy: 0.097\n",
      "iteration 9 0\t loss: 3.582, accuracy: 0.115\n",
      "iteration 10 0\t loss: 3.169, accuracy: 0.112\n",
      "iteration 11 0\t loss: 2.701, accuracy: 0.114\n",
      "iteration 12 0\t loss: 2.440, accuracy: 0.114\n",
      "iteration 13 0\t loss: 2.348, accuracy: 0.117\n",
      "iteration 14 0\t loss: 2.323, accuracy: 0.106\n",
      "iteration 15 0\t loss: 2.318, accuracy: 0.103\n",
      "iteration 16 0\t loss: 2.318, accuracy: 0.099\n",
      "iteration 17 0\t loss: 2.315, accuracy: 0.098\n",
      "iteration 18 0\t loss: 2.310, accuracy: 0.099\n",
      "iteration 19 0\t loss: 2.303, accuracy: 0.102\n",
      "iteration 20 0\t loss: 2.298, accuracy: 0.106\n",
      "iteration 21 0\t loss: 2.292, accuracy: 0.115\n",
      "iteration 22 0\t loss: 2.286, accuracy: 0.121\n",
      "iteration 23 0\t loss: 2.279, accuracy: 0.133\n",
      "iteration 24 0\t loss: 2.273, accuracy: 0.141\n",
      "iteration 25 0\t loss: 2.267, accuracy: 0.145\n",
      "iteration 26 0\t loss: 2.261, accuracy: 0.150\n",
      "iteration 27 0\t loss: 2.254, accuracy: 0.154\n",
      "iteration 28 0\t loss: 2.245, accuracy: 0.159\n",
      "iteration 29 0\t loss: 2.235, accuracy: 0.163\n",
      "iteration 30 0\t loss: 2.225, accuracy: 0.169\n",
      "iteration 31 0\t loss: 2.216, accuracy: 0.172\n",
      "iteration 32 0\t loss: 2.205, accuracy: 0.176\n",
      "iteration 33 0\t loss: 2.193, accuracy: 0.176\n",
      "iteration 34 0\t loss: 2.181, accuracy: 0.180\n",
      "iteration 35 0\t loss: 2.167, accuracy: 0.188\n",
      "iteration 36 0\t loss: 2.152, accuracy: 0.194\n",
      "iteration 37 0\t loss: 2.134, accuracy: 0.200\n",
      "iteration 38 0\t loss: 2.111, accuracy: 0.210\n",
      "iteration 39 0\t loss: 2.086, accuracy: 0.224\n",
      "iteration 40 0\t loss: 2.074, accuracy: 0.224\n",
      "iteration 41 0\t loss: 2.049, accuracy: 0.240\n",
      "iteration 42 0\t loss: 2.016, accuracy: 0.253\n",
      "iteration 43 0\t loss: 2.031, accuracy: 0.246\n",
      "iteration 44 0\t loss: 2.004, accuracy: 0.266\n",
      "iteration 45 0\t loss: 1.982, accuracy: 0.274\n",
      "iteration 46 0\t loss: 1.976, accuracy: 0.277\n",
      "iteration 47 0\t loss: 1.971, accuracy: 0.282\n",
      "iteration 48 0\t loss: 1.952, accuracy: 0.293\n",
      "iteration 49 0\t loss: 1.936, accuracy: 0.294\n",
      "iteration 50 0\t loss: 1.926, accuracy: 0.304\n",
      "iteration 51 0\t loss: 1.921, accuracy: 0.307\n",
      "iteration 52 0\t loss: 1.927, accuracy: 0.304\n",
      "iteration 53 0\t loss: 1.917, accuracy: 0.312\n",
      "iteration 54 0\t loss: 1.913, accuracy: 0.318\n",
      "iteration 55 0\t loss: 1.910, accuracy: 0.319\n",
      "iteration 56 0\t loss: 1.921, accuracy: 0.317\n",
      "iteration 57 0\t loss: 1.908, accuracy: 0.324\n",
      "iteration 58 0\t loss: 1.951, accuracy: 0.325\n",
      "iteration 59 0\t loss: 1.952, accuracy: 0.319\n",
      "iteration 60 0\t loss: 1.949, accuracy: 0.330\n",
      "iteration 61 0\t loss: 1.917, accuracy: 0.334\n",
      "iteration 62 0\t loss: 1.920, accuracy: 0.332\n",
      "iteration 63 0\t loss: 1.945, accuracy: 0.333\n",
      "iteration 64 0\t loss: 1.925, accuracy: 0.341\n",
      "iteration 65 0\t loss: 1.927, accuracy: 0.339\n",
      "iteration 66 0\t loss: 1.972, accuracy: 0.338\n",
      "iteration 67 0\t loss: 1.954, accuracy: 0.340\n",
      "iteration 68 0\t loss: 1.961, accuracy: 0.340\n",
      "iteration 69 0\t loss: 1.997, accuracy: 0.342\n",
      "iteration 70 0\t loss: 1.999, accuracy: 0.344\n",
      "iteration 71 0\t loss: 2.011, accuracy: 0.348\n",
      "iteration 72 0\t loss: 2.028, accuracy: 0.347\n",
      "iteration 73 0\t loss: 2.043, accuracy: 0.347\n",
      "iteration 74 0\t loss: 2.064, accuracy: 0.348\n",
      "iteration 75 0\t loss: 2.085, accuracy: 0.350\n",
      "iteration 76 0\t loss: 2.107, accuracy: 0.351\n",
      "iteration 77 0\t loss: 2.137, accuracy: 0.351\n",
      "iteration 78 0\t loss: 2.140, accuracy: 0.353\n",
      "iteration 79 0\t loss: 2.179, accuracy: 0.353\n",
      "iteration 80 0\t loss: 2.205, accuracy: 0.353\n",
      "iteration 81 0\t loss: 2.216, accuracy: 0.353\n",
      "iteration 82 0\t loss: 2.269, accuracy: 0.353\n",
      "iteration 83 0\t loss: 2.306, accuracy: 0.351\n",
      "iteration 84 0\t loss: 2.327, accuracy: 0.352\n",
      "iteration 85 0\t loss: 2.367, accuracy: 0.351\n",
      "iteration 86 0\t loss: 2.408, accuracy: 0.352\n",
      "iteration 87 0\t loss: 2.432, accuracy: 0.351\n",
      "iteration 88 0\t loss: 2.472, accuracy: 0.351\n",
      "iteration 89 0\t loss: 2.521, accuracy: 0.351\n",
      "iteration 90 0\t loss: 2.552, accuracy: 0.351\n",
      "iteration 91 0\t loss: 2.594, accuracy: 0.352\n",
      "iteration 92 0\t loss: 2.642, accuracy: 0.351\n",
      "iteration 93 0\t loss: 2.680, accuracy: 0.350\n",
      "iteration 94 0\t loss: 2.706, accuracy: 0.353\n",
      "iteration 95 0\t loss: 2.746, accuracy: 0.353\n",
      "iteration 96 0\t loss: 2.798, accuracy: 0.352\n",
      "iteration 97 0\t loss: 2.842, accuracy: 0.351\n",
      "iteration 98 0\t loss: 2.871, accuracy: 0.352\n",
      "iteration 99 0\t loss: 2.909, accuracy: 0.352\n"
     ]
    }
   ],
   "source": [
    "## train a model from scratch\n",
    "\n",
    "new_train_model(cnn_expanded_dict, cifar10_dataset_generators, epoch_n=100, \n",
    "                print_every=10, save_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "iteration 0 0\t loss: 32.435, accuracy: 0.103\n",
      "iteration 1 0\t loss: 46.614, accuracy: 0.103\n",
      "iteration 2 0\t loss: 50.296, accuracy: 0.100\n",
      "iteration 3 0\t loss: 26.691, accuracy: 0.130\n",
      "iteration 4 0\t loss: 18.186, accuracy: 0.123\n",
      "iteration 5 0\t loss: 12.374, accuracy: 0.102\n",
      "iteration 6 0\t loss: 6.984, accuracy: 0.115\n",
      "iteration 7 0\t loss: 4.781, accuracy: 0.111\n",
      "iteration 8 0\t loss: 3.478, accuracy: 0.108\n",
      "iteration 9 0\t loss: 2.761, accuracy: 0.126\n",
      "iteration 10 0\t loss: 2.546, accuracy: 0.119\n",
      "iteration 11 0\t loss: 2.465, accuracy: 0.127\n",
      "iteration 12 0\t loss: 2.422, accuracy: 0.124\n",
      "iteration 13 0\t loss: 2.388, accuracy: 0.123\n",
      "iteration 14 0\t loss: 2.359, accuracy: 0.126\n",
      "iteration 15 0\t loss: 2.338, accuracy: 0.128\n",
      "iteration 16 0\t loss: 2.322, accuracy: 0.140\n",
      "iteration 17 0\t loss: 2.310, accuracy: 0.146\n",
      "iteration 18 0\t loss: 2.299, accuracy: 0.151\n",
      "iteration 19 0\t loss: 2.290, accuracy: 0.155\n",
      "iteration 20 0\t loss: 2.279, accuracy: 0.160\n",
      "iteration 21 0\t loss: 2.268, accuracy: 0.164\n",
      "iteration 22 0\t loss: 2.258, accuracy: 0.169\n",
      "iteration 23 0\t loss: 2.247, accuracy: 0.172\n",
      "iteration 24 0\t loss: 2.237, accuracy: 0.177\n",
      "iteration 25 0\t loss: 2.227, accuracy: 0.178\n",
      "iteration 26 0\t loss: 2.218, accuracy: 0.181\n",
      "iteration 27 0\t loss: 2.209, accuracy: 0.187\n",
      "iteration 28 0\t loss: 2.199, accuracy: 0.193\n",
      "iteration 29 0\t loss: 2.189, accuracy: 0.200\n",
      "iteration 30 0\t loss: 2.179, accuracy: 0.206\n",
      "iteration 31 0\t loss: 2.168, accuracy: 0.213\n",
      "iteration 32 0\t loss: 2.157, accuracy: 0.220\n",
      "iteration 33 0\t loss: 2.145, accuracy: 0.221\n",
      "iteration 34 0\t loss: 2.133, accuracy: 0.227\n",
      "iteration 35 0\t loss: 2.119, accuracy: 0.229\n",
      "iteration 36 0\t loss: 2.105, accuracy: 0.234\n",
      "iteration 37 0\t loss: 2.090, accuracy: 0.239\n",
      "iteration 38 0\t loss: 2.076, accuracy: 0.243\n",
      "iteration 39 0\t loss: 2.061, accuracy: 0.251\n",
      "iteration 40 0\t loss: 2.045, accuracy: 0.258\n",
      "iteration 41 0\t loss: 2.030, accuracy: 0.268\n",
      "iteration 42 0\t loss: 2.016, accuracy: 0.276\n",
      "iteration 43 0\t loss: 2.004, accuracy: 0.278\n",
      "iteration 44 0\t loss: 1.994, accuracy: 0.283\n",
      "iteration 45 0\t loss: 1.983, accuracy: 0.287\n",
      "iteration 46 0\t loss: 1.972, accuracy: 0.293\n",
      "iteration 47 0\t loss: 1.961, accuracy: 0.297\n",
      "iteration 48 0\t loss: 1.953, accuracy: 0.304\n",
      "iteration 49 0\t loss: 1.948, accuracy: 0.309\n",
      "iteration 50 0\t loss: 1.942, accuracy: 0.310\n",
      "iteration 51 0\t loss: 1.935, accuracy: 0.315\n",
      "iteration 52 0\t loss: 1.930, accuracy: 0.317\n",
      "iteration 53 0\t loss: 1.927, accuracy: 0.320\n",
      "iteration 54 0\t loss: 1.925, accuracy: 0.324\n",
      "iteration 55 0\t loss: 1.927, accuracy: 0.324\n",
      "iteration 56 0\t loss: 1.932, accuracy: 0.325\n",
      "iteration 57 0\t loss: 1.935, accuracy: 0.331\n",
      "iteration 58 0\t loss: 1.940, accuracy: 0.334\n",
      "iteration 59 0\t loss: 1.951, accuracy: 0.336\n",
      "iteration 60 0\t loss: 1.958, accuracy: 0.336\n",
      "iteration 61 0\t loss: 1.969, accuracy: 0.338\n",
      "iteration 62 0\t loss: 1.983, accuracy: 0.339\n",
      "iteration 63 0\t loss: 1.997, accuracy: 0.340\n",
      "iteration 64 0\t loss: 2.019, accuracy: 0.339\n",
      "iteration 65 0\t loss: 2.031, accuracy: 0.339\n",
      "iteration 66 0\t loss: 2.053, accuracy: 0.341\n",
      "iteration 67 0\t loss: 2.074, accuracy: 0.341\n",
      "iteration 68 0\t loss: 2.110, accuracy: 0.340\n",
      "iteration 69 0\t loss: 2.136, accuracy: 0.340\n",
      "iteration 70 0\t loss: 2.174, accuracy: 0.342\n",
      "iteration 71 0\t loss: 2.194, accuracy: 0.341\n",
      "iteration 72 0\t loss: 2.226, accuracy: 0.342\n",
      "iteration 73 0\t loss: 2.266, accuracy: 0.341\n",
      "iteration 74 0\t loss: 2.310, accuracy: 0.340\n",
      "iteration 75 0\t loss: 2.358, accuracy: 0.340\n",
      "iteration 76 0\t loss: 2.403, accuracy: 0.337\n",
      "iteration 77 0\t loss: 2.441, accuracy: 0.340\n",
      "iteration 78 0\t loss: 2.488, accuracy: 0.336\n",
      "iteration 79 0\t loss: 2.539, accuracy: 0.335\n",
      "iteration 80 0\t loss: 2.598, accuracy: 0.336\n",
      "iteration 81 0\t loss: 2.659, accuracy: 0.335\n",
      "iteration 82 0\t loss: 2.710, accuracy: 0.335\n",
      "iteration 83 0\t loss: 2.770, accuracy: 0.334\n",
      "iteration 84 0\t loss: 2.835, accuracy: 0.334\n",
      "iteration 85 0\t loss: 2.901, accuracy: 0.334\n",
      "iteration 86 0\t loss: 2.971, accuracy: 0.333\n",
      "iteration 87 0\t loss: 3.038, accuracy: 0.333\n",
      "iteration 88 0\t loss: 3.097, accuracy: 0.333\n",
      "iteration 89 0\t loss: 3.152, accuracy: 0.333\n",
      "iteration 90 0\t loss: 3.210, accuracy: 0.332\n",
      "iteration 91 0\t loss: 3.272, accuracy: 0.332\n",
      "iteration 92 0\t loss: 3.335, accuracy: 0.333\n",
      "iteration 93 0\t loss: 3.394, accuracy: 0.333\n",
      "iteration 94 0\t loss: 3.448, accuracy: 0.333\n",
      "iteration 95 0\t loss: 3.504, accuracy: 0.334\n",
      "iteration 96 0\t loss: 3.563, accuracy: 0.334\n",
      "iteration 97 0\t loss: 3.620, accuracy: 0.333\n",
      "iteration 98 0\t loss: 3.673, accuracy: 0.332\n",
      "iteration 99 0\t loss: 3.722, accuracy: 0.332\n"
     ]
    }
   ],
   "source": [
    "## fine-tuning SVHN Net using Cifar-10 weights saved in Q2\n",
    "new_train_model(cnn_expanded_dict, cifar10_dataset_generators, epoch_n=100, \n",
    "                print_every=10, load_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: TensorBoard\n",
    "(30 points)\n",
    "\n",
    "[TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) is a very helpful tool for visualization of neural networks. \n",
    "\n",
    "### Q4.1 Plotting\n",
    "Present at least one visualization for each of the following:\n",
    "  - Filters\n",
    "  - Loss\n",
    "  - Accuracy\n",
    "\n",
    "Modify code you have wrote above to also have summary writers. To  run tensorboard, the command is `tensorboard --logdir=path/to/your/log/directory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Filter, loss, and accuracy visualizations\n",
    "\n",
    "def train_model_tensorboard(model_dict, dataset_generators, epoch_n, print_every):\n",
    "    with model_dict['graph'].as_default(), tf.Session() as sess:\n",
    "        tf.summary.scalar('loss', model_dict['loss'])\n",
    "        tf.summary.scalar('accuracy', model_dict['accuracy'])\n",
    "        tf.summary.histogram('filters_conv1', tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'conv1')[0])\n",
    "        tf.summary.histogram('filters_conv2', tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'conv2')[0])\n",
    "        #tf.summary.histogram('filters_conv3', tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'conv3'))\n",
    "        summary_op = tf.summary.merge_all()\n",
    "        \n",
    "        writer_train = tf.summary.FileWriter('./graphs' + '/train', sess.graph)\n",
    "        writer_test = tf.summary.FileWriter('./graphs' + '/test')\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "      \n",
    "        \n",
    "        for epoch_i in range(epoch_n):\n",
    "            for iter_i, data_batch in enumerate(dataset_generators['train']):\n",
    "                train_feed_dict = dict(zip(model_dict['inputs'], data_batch))\n",
    "                _, summary_train = sess.run([model_dict['train_op'], summary_op], feed_dict=train_feed_dict)\n",
    "                # write log\n",
    "                writer_train.add_summary(summary_train, epoch_i)\n",
    "                \n",
    "                if iter_i % print_every == 0:\n",
    "                    collect_arr = []\n",
    "                    for test_batch in dataset_generators['test']:\n",
    "                        test_feed_dict = dict(zip(model_dict['inputs'], test_batch))\n",
    "                        to_compute = [model_dict['loss'], model_dict['accuracy']]\n",
    "                        #collect_arr.append(sess.run(to_compute, test_feed_dict))\n",
    "                        run_test, summary_test = sess.run([to_compute, summary_op], test_feed_dict)\n",
    "                        writer_test.add_summary(summary_test, epoch_i)\n",
    "                        collect_arr.append(run_test)\n",
    "                        \n",
    "                        #summary,_ = sess.run(merged, feed_dict = test_feed_dict)\n",
    "                        #test_writer.add_summary(summary, iter_i)                    \n",
    "                        \n",
    "                    averages = np.mean(collect_arr, axis=0)\n",
    "                    fmt = (epoch_i, iter_i, ) + tuple(averages)\n",
    "                    print('epoch {:d} iter {:d}, loss: {:.3f}, '\n",
    "                          'accuracy: {:.3f}'.format(*fmt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 iter 0, loss: 69.310, accuracy: 0.195\n",
      "epoch 0 iter 20, loss: 2.270, accuracy: 0.181\n",
      "epoch 0 iter 40, loss: 2.238, accuracy: 0.198\n",
      "epoch 0 iter 60, loss: 2.217, accuracy: 0.207\n",
      "epoch 0 iter 80, loss: 2.111, accuracy: 0.264\n",
      "epoch 0 iter 100, loss: 1.914, accuracy: 0.340\n",
      "epoch 0 iter 120, loss: 1.581, accuracy: 0.483\n",
      "epoch 0 iter 140, loss: 1.453, accuracy: 0.536\n",
      "epoch 0 iter 160, loss: 1.367, accuracy: 0.567\n",
      "epoch 0 iter 180, loss: 1.288, accuracy: 0.595\n",
      "epoch 0 iter 200, loss: 1.239, accuracy: 0.621\n",
      "epoch 0 iter 220, loss: 1.199, accuracy: 0.630\n",
      "epoch 0 iter 240, loss: 1.191, accuracy: 0.634\n",
      "epoch 0 iter 260, loss: 1.142, accuracy: 0.647\n",
      "epoch 0 iter 280, loss: 1.096, accuracy: 0.667\n",
      "epoch 1 iter 0, loss: 1.110, accuracy: 0.661\n",
      "epoch 1 iter 20, loss: 1.070, accuracy: 0.673\n",
      "epoch 1 iter 40, loss: 1.085, accuracy: 0.668\n",
      "epoch 1 iter 60, loss: 1.045, accuracy: 0.681\n",
      "epoch 1 iter 80, loss: 1.007, accuracy: 0.691\n",
      "epoch 1 iter 100, loss: 0.999, accuracy: 0.697\n",
      "epoch 1 iter 120, loss: 0.990, accuracy: 0.698\n",
      "epoch 1 iter 140, loss: 0.970, accuracy: 0.709\n",
      "epoch 1 iter 160, loss: 0.976, accuracy: 0.702\n",
      "epoch 1 iter 180, loss: 0.955, accuracy: 0.711\n",
      "epoch 1 iter 200, loss: 0.960, accuracy: 0.711\n",
      "epoch 1 iter 220, loss: 0.928, accuracy: 0.723\n",
      "epoch 1 iter 240, loss: 0.934, accuracy: 0.719\n",
      "epoch 1 iter 260, loss: 0.908, accuracy: 0.731\n",
      "epoch 1 iter 280, loss: 0.915, accuracy: 0.731\n",
      "epoch 2 iter 0, loss: 0.913, accuracy: 0.730\n",
      "epoch 2 iter 20, loss: 0.895, accuracy: 0.734\n",
      "epoch 2 iter 40, loss: 0.908, accuracy: 0.729\n",
      "epoch 2 iter 60, loss: 0.894, accuracy: 0.735\n",
      "epoch 2 iter 80, loss: 0.872, accuracy: 0.742\n",
      "epoch 2 iter 100, loss: 0.857, accuracy: 0.749\n",
      "epoch 2 iter 120, loss: 0.856, accuracy: 0.746\n",
      "epoch 2 iter 140, loss: 0.897, accuracy: 0.732\n",
      "epoch 2 iter 160, loss: 0.862, accuracy: 0.747\n",
      "epoch 2 iter 180, loss: 0.853, accuracy: 0.749\n",
      "epoch 2 iter 200, loss: 0.860, accuracy: 0.744\n",
      "epoch 2 iter 220, loss: 0.837, accuracy: 0.755\n",
      "epoch 2 iter 240, loss: 0.841, accuracy: 0.754\n",
      "epoch 2 iter 260, loss: 0.833, accuracy: 0.755\n",
      "epoch 2 iter 280, loss: 0.840, accuracy: 0.754\n",
      "epoch 3 iter 0, loss: 0.843, accuracy: 0.755\n",
      "epoch 3 iter 20, loss: 0.828, accuracy: 0.757\n",
      "epoch 3 iter 40, loss: 0.849, accuracy: 0.749\n",
      "epoch 3 iter 60, loss: 0.810, accuracy: 0.763\n",
      "epoch 3 iter 80, loss: 0.803, accuracy: 0.765\n",
      "epoch 3 iter 100, loss: 0.786, accuracy: 0.772\n",
      "epoch 3 iter 120, loss: 0.800, accuracy: 0.767\n",
      "epoch 3 iter 140, loss: 0.794, accuracy: 0.769\n",
      "epoch 3 iter 160, loss: 0.818, accuracy: 0.765\n",
      "epoch 3 iter 180, loss: 0.806, accuracy: 0.766\n",
      "epoch 3 iter 200, loss: 0.801, accuracy: 0.767\n",
      "epoch 3 iter 220, loss: 0.780, accuracy: 0.775\n",
      "epoch 3 iter 240, loss: 0.788, accuracy: 0.772\n",
      "epoch 3 iter 260, loss: 0.779, accuracy: 0.776\n",
      "epoch 3 iter 280, loss: 0.782, accuracy: 0.776\n",
      "epoch 4 iter 0, loss: 0.796, accuracy: 0.775\n",
      "epoch 4 iter 20, loss: 0.796, accuracy: 0.770\n",
      "epoch 4 iter 40, loss: 0.818, accuracy: 0.762\n",
      "epoch 4 iter 60, loss: 0.766, accuracy: 0.781\n",
      "epoch 4 iter 80, loss: 0.757, accuracy: 0.780\n",
      "epoch 4 iter 100, loss: 0.748, accuracy: 0.791\n",
      "epoch 4 iter 120, loss: 0.804, accuracy: 0.767\n",
      "epoch 4 iter 140, loss: 0.755, accuracy: 0.784\n",
      "epoch 4 iter 160, loss: 0.807, accuracy: 0.776\n",
      "epoch 4 iter 180, loss: 0.792, accuracy: 0.779\n",
      "epoch 4 iter 200, loss: 0.755, accuracy: 0.788\n",
      "epoch 4 iter 220, loss: 0.732, accuracy: 0.793\n",
      "epoch 4 iter 240, loss: 0.757, accuracy: 0.783\n",
      "epoch 4 iter 260, loss: 0.734, accuracy: 0.797\n",
      "epoch 4 iter 280, loss: 0.775, accuracy: 0.784\n",
      "epoch 5 iter 0, loss: 0.790, accuracy: 0.784\n",
      "epoch 5 iter 20, loss: 0.756, accuracy: 0.785\n",
      "epoch 5 iter 40, loss: 0.729, accuracy: 0.797\n",
      "epoch 5 iter 60, loss: 0.718, accuracy: 0.795\n",
      "epoch 5 iter 80, loss: 0.724, accuracy: 0.792\n",
      "epoch 5 iter 100, loss: 0.719, accuracy: 0.798\n",
      "epoch 5 iter 120, loss: 0.718, accuracy: 0.800\n",
      "epoch 5 iter 140, loss: 0.697, accuracy: 0.808\n",
      "epoch 5 iter 160, loss: 0.744, accuracy: 0.797\n",
      "epoch 5 iter 180, loss: 0.741, accuracy: 0.799\n",
      "epoch 5 iter 200, loss: 0.744, accuracy: 0.796\n",
      "epoch 5 iter 220, loss: 0.700, accuracy: 0.809\n",
      "epoch 5 iter 240, loss: 0.714, accuracy: 0.804\n",
      "epoch 5 iter 260, loss: 0.749, accuracy: 0.802\n",
      "epoch 5 iter 280, loss: 0.741, accuracy: 0.803\n",
      "epoch 6 iter 0, loss: 0.768, accuracy: 0.799\n",
      "epoch 6 iter 20, loss: 0.707, accuracy: 0.806\n",
      "epoch 6 iter 40, loss: 0.707, accuracy: 0.807\n",
      "epoch 6 iter 60, loss: 0.713, accuracy: 0.801\n",
      "epoch 6 iter 80, loss: 0.740, accuracy: 0.793\n",
      "epoch 6 iter 100, loss: 0.724, accuracy: 0.808\n",
      "epoch 6 iter 120, loss: 0.692, accuracy: 0.814\n",
      "epoch 6 iter 140, loss: 0.723, accuracy: 0.809\n",
      "epoch 6 iter 160, loss: 0.746, accuracy: 0.802\n",
      "epoch 6 iter 180, loss: 0.710, accuracy: 0.815\n",
      "epoch 6 iter 200, loss: 0.716, accuracy: 0.808\n",
      "epoch 6 iter 220, loss: 0.739, accuracy: 0.806\n",
      "epoch 6 iter 240, loss: 0.768, accuracy: 0.793\n",
      "epoch 6 iter 260, loss: 0.768, accuracy: 0.805\n",
      "epoch 6 iter 280, loss: 0.793, accuracy: 0.799\n",
      "epoch 7 iter 0, loss: 0.737, accuracy: 0.812\n",
      "epoch 7 iter 20, loss: 0.724, accuracy: 0.810\n",
      "epoch 7 iter 40, loss: 0.728, accuracy: 0.813\n",
      "epoch 7 iter 60, loss: 0.709, accuracy: 0.808\n",
      "epoch 7 iter 80, loss: 0.705, accuracy: 0.813\n",
      "epoch 7 iter 100, loss: 0.743, accuracy: 0.805\n",
      "epoch 7 iter 120, loss: 0.726, accuracy: 0.811\n",
      "epoch 7 iter 140, loss: 0.723, accuracy: 0.814\n",
      "epoch 7 iter 160, loss: 0.773, accuracy: 0.803\n",
      "epoch 7 iter 180, loss: 0.767, accuracy: 0.812\n",
      "epoch 7 iter 200, loss: 0.748, accuracy: 0.808\n",
      "epoch 7 iter 220, loss: 0.715, accuracy: 0.819\n",
      "epoch 7 iter 240, loss: 0.801, accuracy: 0.802\n",
      "epoch 7 iter 260, loss: 0.749, accuracy: 0.818\n",
      "epoch 7 iter 280, loss: 0.859, accuracy: 0.802\n",
      "epoch 8 iter 0, loss: 0.832, accuracy: 0.799\n",
      "epoch 8 iter 20, loss: 0.757, accuracy: 0.811\n",
      "epoch 8 iter 40, loss: 0.748, accuracy: 0.812\n",
      "epoch 8 iter 60, loss: 0.760, accuracy: 0.806\n",
      "epoch 8 iter 80, loss: 0.717, accuracy: 0.815\n",
      "epoch 8 iter 100, loss: 0.769, accuracy: 0.812\n",
      "epoch 8 iter 120, loss: 0.786, accuracy: 0.802\n",
      "epoch 8 iter 140, loss: 0.769, accuracy: 0.814\n",
      "epoch 8 iter 160, loss: 0.808, accuracy: 0.801\n",
      "epoch 8 iter 180, loss: 0.797, accuracy: 0.807\n",
      "epoch 8 iter 200, loss: 0.793, accuracy: 0.816\n",
      "epoch 8 iter 220, loss: 0.746, accuracy: 0.818\n",
      "epoch 8 iter 240, loss: 0.839, accuracy: 0.805\n",
      "epoch 8 iter 260, loss: 0.808, accuracy: 0.814\n",
      "epoch 8 iter 280, loss: 0.993, accuracy: 0.789\n",
      "epoch 9 iter 0, loss: 0.847, accuracy: 0.804\n",
      "epoch 9 iter 20, loss: 0.822, accuracy: 0.806\n",
      "epoch 9 iter 40, loss: 0.779, accuracy: 0.809\n",
      "epoch 9 iter 60, loss: 0.798, accuracy: 0.812\n",
      "epoch 9 iter 80, loss: 0.774, accuracy: 0.808\n",
      "epoch 9 iter 100, loss: 0.814, accuracy: 0.810\n",
      "epoch 9 iter 120, loss: 0.777, accuracy: 0.815\n",
      "epoch 9 iter 140, loss: 0.831, accuracy: 0.812\n",
      "epoch 9 iter 160, loss: 0.834, accuracy: 0.799\n",
      "epoch 9 iter 180, loss: 0.916, accuracy: 0.797\n",
      "epoch 9 iter 200, loss: 0.789, accuracy: 0.822\n",
      "epoch 9 iter 220, loss: 0.787, accuracy: 0.817\n",
      "epoch 9 iter 240, loss: 0.825, accuracy: 0.804\n",
      "epoch 9 iter 260, loss: 0.856, accuracy: 0.811\n",
      "epoch 9 iter 280, loss: 1.032, accuracy: 0.791\n",
      "epoch 10 iter 0, loss: 1.012, accuracy: 0.789\n",
      "epoch 10 iter 20, loss: 0.918, accuracy: 0.796\n",
      "epoch 10 iter 40, loss: 0.797, accuracy: 0.815\n",
      "epoch 10 iter 60, loss: 0.875, accuracy: 0.798\n",
      "epoch 10 iter 80, loss: 0.783, accuracy: 0.811\n",
      "epoch 10 iter 100, loss: 0.814, accuracy: 0.812\n",
      "epoch 10 iter 120, loss: 0.792, accuracy: 0.811\n",
      "epoch 10 iter 140, loss: 0.879, accuracy: 0.807\n",
      "epoch 10 iter 160, loss: 0.839, accuracy: 0.809\n",
      "epoch 10 iter 180, loss: 0.955, accuracy: 0.814\n",
      "epoch 10 iter 200, loss: 0.827, accuracy: 0.822\n",
      "epoch 10 iter 220, loss: 0.869, accuracy: 0.808\n",
      "epoch 10 iter 240, loss: 0.963, accuracy: 0.796\n",
      "epoch 10 iter 260, loss: 0.868, accuracy: 0.809\n",
      "epoch 10 iter 280, loss: 1.205, accuracy: 0.768\n",
      "epoch 11 iter 0, loss: 0.943, accuracy: 0.800\n",
      "epoch 11 iter 20, loss: 0.985, accuracy: 0.798\n",
      "epoch 11 iter 40, loss: 0.847, accuracy: 0.808\n",
      "epoch 11 iter 60, loss: 0.849, accuracy: 0.812\n",
      "epoch 11 iter 80, loss: 0.780, accuracy: 0.815\n",
      "epoch 11 iter 100, loss: 0.807, accuracy: 0.821\n",
      "epoch 11 iter 120, loss: 0.828, accuracy: 0.816\n",
      "epoch 11 iter 140, loss: 0.866, accuracy: 0.814\n",
      "epoch 11 iter 160, loss: 0.823, accuracy: 0.819\n",
      "epoch 11 iter 180, loss: 1.018, accuracy: 0.803\n",
      "epoch 11 iter 200, loss: 0.885, accuracy: 0.826\n",
      "epoch 11 iter 220, loss: 0.886, accuracy: 0.814\n",
      "epoch 11 iter 240, loss: 1.031, accuracy: 0.785\n",
      "epoch 11 iter 260, loss: 0.873, accuracy: 0.810\n",
      "epoch 11 iter 280, loss: 0.935, accuracy: 0.811\n",
      "epoch 12 iter 0, loss: 0.948, accuracy: 0.811\n",
      "epoch 12 iter 20, loss: 0.992, accuracy: 0.804\n",
      "epoch 12 iter 40, loss: 0.833, accuracy: 0.813\n",
      "epoch 12 iter 60, loss: 0.886, accuracy: 0.815\n",
      "epoch 12 iter 80, loss: 0.845, accuracy: 0.819\n",
      "epoch 12 iter 100, loss: 0.841, accuracy: 0.826\n",
      "epoch 12 iter 120, loss: 0.836, accuracy: 0.821\n",
      "epoch 12 iter 140, loss: 0.859, accuracy: 0.824\n",
      "epoch 12 iter 160, loss: 0.876, accuracy: 0.814\n",
      "epoch 12 iter 180, loss: 1.058, accuracy: 0.783\n",
      "epoch 12 iter 200, loss: 0.916, accuracy: 0.830\n",
      "epoch 12 iter 220, loss: 0.919, accuracy: 0.820\n",
      "epoch 12 iter 240, loss: 0.918, accuracy: 0.815\n",
      "epoch 12 iter 260, loss: 0.873, accuracy: 0.823\n",
      "epoch 12 iter 280, loss: 1.067, accuracy: 0.809\n",
      "epoch 13 iter 0, loss: 1.030, accuracy: 0.810\n",
      "epoch 13 iter 20, loss: 1.077, accuracy: 0.805\n",
      "epoch 13 iter 40, loss: 0.898, accuracy: 0.815\n",
      "epoch 13 iter 60, loss: 0.919, accuracy: 0.816\n",
      "epoch 13 iter 80, loss: 0.893, accuracy: 0.812\n",
      "epoch 13 iter 100, loss: 0.884, accuracy: 0.827\n",
      "epoch 13 iter 120, loss: 0.945, accuracy: 0.818\n",
      "epoch 13 iter 140, loss: 0.979, accuracy: 0.815\n",
      "epoch 13 iter 160, loss: 1.008, accuracy: 0.808\n",
      "epoch 13 iter 180, loss: 1.180, accuracy: 0.799\n",
      "epoch 13 iter 200, loss: 0.976, accuracy: 0.819\n",
      "epoch 13 iter 220, loss: 0.997, accuracy: 0.818\n",
      "epoch 13 iter 240, loss: 0.952, accuracy: 0.818\n",
      "epoch 13 iter 260, loss: 0.900, accuracy: 0.822\n",
      "epoch 13 iter 280, loss: 1.130, accuracy: 0.809\n",
      "epoch 14 iter 0, loss: 1.096, accuracy: 0.812\n",
      "epoch 14 iter 20, loss: 1.045, accuracy: 0.815\n",
      "epoch 14 iter 40, loss: 0.968, accuracy: 0.808\n",
      "epoch 14 iter 60, loss: 0.936, accuracy: 0.827\n",
      "epoch 14 iter 80, loss: 0.914, accuracy: 0.822\n",
      "epoch 14 iter 100, loss: 0.931, accuracy: 0.822\n",
      "epoch 14 iter 120, loss: 0.990, accuracy: 0.820\n",
      "epoch 14 iter 140, loss: 1.036, accuracy: 0.815\n",
      "epoch 14 iter 160, loss: 1.026, accuracy: 0.814\n",
      "epoch 14 iter 180, loss: 1.038, accuracy: 0.824\n",
      "epoch 14 iter 200, loss: 1.034, accuracy: 0.819\n",
      "epoch 14 iter 220, loss: 1.044, accuracy: 0.828\n",
      "epoch 14 iter 240, loss: 0.983, accuracy: 0.827\n",
      "epoch 14 iter 260, loss: 0.977, accuracy: 0.821\n",
      "epoch 14 iter 280, loss: 1.148, accuracy: 0.816\n",
      "epoch 15 iter 0, loss: 1.241, accuracy: 0.794\n",
      "epoch 15 iter 20, loss: 1.263, accuracy: 0.807\n",
      "epoch 15 iter 40, loss: 1.077, accuracy: 0.815\n",
      "epoch 15 iter 60, loss: 1.036, accuracy: 0.821\n",
      "epoch 15 iter 80, loss: 1.004, accuracy: 0.823\n",
      "epoch 15 iter 100, loss: 1.117, accuracy: 0.817\n",
      "epoch 15 iter 120, loss: 0.968, accuracy: 0.828\n",
      "epoch 15 iter 140, loss: 1.108, accuracy: 0.809\n",
      "epoch 15 iter 160, loss: 1.221, accuracy: 0.805\n",
      "epoch 15 iter 180, loss: 1.226, accuracy: 0.819\n",
      "epoch 15 iter 200, loss: 1.116, accuracy: 0.817\n",
      "epoch 15 iter 220, loss: 1.139, accuracy: 0.823\n",
      "epoch 15 iter 240, loss: 1.062, accuracy: 0.823\n",
      "epoch 15 iter 260, loss: 1.032, accuracy: 0.815\n",
      "epoch 15 iter 280, loss: 1.198, accuracy: 0.822\n",
      "epoch 16 iter 0, loss: 1.380, accuracy: 0.803\n",
      "epoch 16 iter 20, loss: 1.153, accuracy: 0.817\n",
      "epoch 16 iter 40, loss: 1.101, accuracy: 0.814\n",
      "epoch 16 iter 60, loss: 1.018, accuracy: 0.826\n",
      "epoch 16 iter 80, loss: 1.046, accuracy: 0.821\n",
      "epoch 16 iter 100, loss: 1.065, accuracy: 0.824\n",
      "epoch 16 iter 120, loss: 0.987, accuracy: 0.828\n",
      "epoch 16 iter 140, loss: 1.088, accuracy: 0.816\n",
      "epoch 16 iter 160, loss: 1.242, accuracy: 0.813\n",
      "epoch 16 iter 180, loss: 1.311, accuracy: 0.813\n",
      "epoch 16 iter 200, loss: 1.138, accuracy: 0.826\n",
      "epoch 16 iter 220, loss: 1.093, accuracy: 0.823\n",
      "epoch 16 iter 240, loss: 1.115, accuracy: 0.823\n",
      "epoch 16 iter 260, loss: 1.130, accuracy: 0.818\n",
      "epoch 16 iter 280, loss: 1.211, accuracy: 0.825\n",
      "epoch 17 iter 0, loss: 1.304, accuracy: 0.821\n",
      "epoch 17 iter 20, loss: 1.240, accuracy: 0.818\n",
      "epoch 17 iter 40, loss: 1.221, accuracy: 0.813\n",
      "epoch 17 iter 60, loss: 1.181, accuracy: 0.819\n",
      "epoch 17 iter 80, loss: 1.147, accuracy: 0.827\n",
      "epoch 17 iter 100, loss: 1.191, accuracy: 0.820\n",
      "epoch 17 iter 120, loss: 1.114, accuracy: 0.820\n",
      "epoch 17 iter 140, loss: 1.147, accuracy: 0.822\n",
      "epoch 17 iter 160, loss: 1.194, accuracy: 0.806\n",
      "epoch 17 iter 180, loss: 1.322, accuracy: 0.810\n",
      "epoch 17 iter 200, loss: 1.177, accuracy: 0.824\n",
      "epoch 17 iter 220, loss: 1.173, accuracy: 0.817\n",
      "epoch 17 iter 240, loss: 1.107, accuracy: 0.825\n",
      "epoch 17 iter 260, loss: 1.157, accuracy: 0.823\n",
      "epoch 17 iter 280, loss: 1.306, accuracy: 0.821\n",
      "epoch 18 iter 0, loss: 1.322, accuracy: 0.819\n",
      "epoch 18 iter 20, loss: 1.256, accuracy: 0.816\n",
      "epoch 18 iter 40, loss: 1.128, accuracy: 0.825\n",
      "epoch 18 iter 60, loss: 1.160, accuracy: 0.825\n",
      "epoch 18 iter 80, loss: 1.138, accuracy: 0.822\n",
      "epoch 18 iter 100, loss: 1.250, accuracy: 0.821\n",
      "epoch 18 iter 120, loss: 1.262, accuracy: 0.824\n",
      "epoch 18 iter 140, loss: 1.164, accuracy: 0.823\n",
      "epoch 18 iter 160, loss: 1.184, accuracy: 0.817\n",
      "epoch 18 iter 180, loss: 1.306, accuracy: 0.814\n",
      "epoch 18 iter 200, loss: 1.327, accuracy: 0.818\n",
      "epoch 18 iter 220, loss: 1.207, accuracy: 0.828\n",
      "epoch 18 iter 240, loss: 1.116, accuracy: 0.828\n",
      "epoch 18 iter 260, loss: 1.153, accuracy: 0.834\n",
      "epoch 18 iter 280, loss: 1.360, accuracy: 0.818\n",
      "epoch 19 iter 0, loss: 1.276, accuracy: 0.826\n",
      "epoch 19 iter 20, loss: 1.304, accuracy: 0.821\n",
      "epoch 19 iter 40, loss: 1.258, accuracy: 0.808\n",
      "epoch 19 iter 60, loss: 1.373, accuracy: 0.808\n",
      "epoch 19 iter 80, loss: 1.283, accuracy: 0.818\n",
      "epoch 19 iter 100, loss: 1.184, accuracy: 0.827\n",
      "epoch 19 iter 120, loss: 1.291, accuracy: 0.824\n",
      "epoch 19 iter 140, loss: 1.175, accuracy: 0.824\n",
      "epoch 19 iter 160, loss: 1.240, accuracy: 0.815\n",
      "epoch 19 iter 180, loss: 1.435, accuracy: 0.813\n",
      "epoch 19 iter 200, loss: 1.267, accuracy: 0.820\n",
      "epoch 19 iter 220, loss: 1.382, accuracy: 0.820\n",
      "epoch 19 iter 240, loss: 1.317, accuracy: 0.819\n",
      "epoch 19 iter 260, loss: 1.221, accuracy: 0.818\n",
      "epoch 19 iter 280, loss: 1.418, accuracy: 0.818\n",
      "epoch 20 iter 0, loss: 1.369, accuracy: 0.822\n",
      "epoch 20 iter 20, loss: 1.448, accuracy: 0.823\n",
      "epoch 20 iter 40, loss: 1.415, accuracy: 0.814\n",
      "epoch 20 iter 60, loss: 1.291, accuracy: 0.815\n",
      "epoch 20 iter 80, loss: 1.357, accuracy: 0.825\n",
      "epoch 20 iter 100, loss: 1.288, accuracy: 0.826\n",
      "epoch 20 iter 120, loss: 1.251, accuracy: 0.825\n",
      "epoch 20 iter 140, loss: 1.242, accuracy: 0.824\n",
      "epoch 20 iter 160, loss: 1.349, accuracy: 0.820\n",
      "epoch 20 iter 180, loss: 1.501, accuracy: 0.816\n",
      "epoch 20 iter 200, loss: 1.360, accuracy: 0.813\n",
      "epoch 20 iter 220, loss: 1.409, accuracy: 0.819\n",
      "epoch 20 iter 240, loss: 1.320, accuracy: 0.831\n",
      "epoch 20 iter 260, loss: 1.240, accuracy: 0.829\n",
      "epoch 20 iter 280, loss: 1.440, accuracy: 0.815\n",
      "epoch 21 iter 0, loss: 1.498, accuracy: 0.828\n",
      "epoch 21 iter 20, loss: 1.402, accuracy: 0.830\n",
      "epoch 21 iter 40, loss: 1.492, accuracy: 0.814\n",
      "epoch 21 iter 60, loss: 1.242, accuracy: 0.818\n",
      "epoch 21 iter 80, loss: 1.341, accuracy: 0.824\n",
      "epoch 21 iter 100, loss: 1.360, accuracy: 0.830\n",
      "epoch 21 iter 120, loss: 1.300, accuracy: 0.819\n",
      "epoch 21 iter 140, loss: 1.379, accuracy: 0.805\n",
      "epoch 21 iter 160, loss: 1.294, accuracy: 0.810\n",
      "epoch 21 iter 180, loss: 1.449, accuracy: 0.816\n",
      "epoch 21 iter 200, loss: 1.437, accuracy: 0.804\n",
      "epoch 21 iter 220, loss: 1.331, accuracy: 0.836\n",
      "epoch 21 iter 240, loss: 1.390, accuracy: 0.831\n",
      "epoch 21 iter 260, loss: 1.372, accuracy: 0.832\n",
      "epoch 21 iter 280, loss: 1.555, accuracy: 0.827\n",
      "epoch 22 iter 0, loss: 1.558, accuracy: 0.830\n",
      "epoch 22 iter 20, loss: 1.492, accuracy: 0.828\n",
      "epoch 22 iter 40, loss: 1.536, accuracy: 0.815\n",
      "epoch 22 iter 60, loss: 1.336, accuracy: 0.830\n",
      "epoch 22 iter 80, loss: 1.417, accuracy: 0.826\n",
      "epoch 22 iter 100, loss: 1.474, accuracy: 0.822\n",
      "epoch 22 iter 120, loss: 1.376, accuracy: 0.830\n",
      "epoch 22 iter 140, loss: 1.404, accuracy: 0.822\n",
      "epoch 22 iter 160, loss: 1.372, accuracy: 0.825\n",
      "epoch 22 iter 180, loss: 1.445, accuracy: 0.822\n",
      "epoch 22 iter 200, loss: 1.503, accuracy: 0.799\n",
      "epoch 22 iter 220, loss: 1.474, accuracy: 0.827\n",
      "epoch 22 iter 240, loss: 1.474, accuracy: 0.829\n",
      "epoch 22 iter 260, loss: 1.415, accuracy: 0.832\n",
      "epoch 22 iter 280, loss: 1.489, accuracy: 0.827\n",
      "epoch 23 iter 0, loss: 1.484, accuracy: 0.825\n",
      "epoch 23 iter 20, loss: 1.619, accuracy: 0.829\n",
      "epoch 23 iter 40, loss: 1.539, accuracy: 0.813\n",
      "epoch 23 iter 60, loss: 1.436, accuracy: 0.832\n",
      "epoch 23 iter 80, loss: 1.417, accuracy: 0.828\n",
      "epoch 23 iter 100, loss: 1.510, accuracy: 0.827\n",
      "epoch 23 iter 120, loss: 1.491, accuracy: 0.825\n",
      "epoch 23 iter 140, loss: 1.424, accuracy: 0.817\n",
      "epoch 23 iter 160, loss: 1.465, accuracy: 0.830\n",
      "epoch 23 iter 180, loss: 1.651, accuracy: 0.804\n",
      "epoch 23 iter 200, loss: 1.692, accuracy: 0.822\n",
      "epoch 23 iter 220, loss: 1.453, accuracy: 0.833\n",
      "epoch 23 iter 240, loss: 1.463, accuracy: 0.826\n",
      "epoch 23 iter 260, loss: 1.449, accuracy: 0.831\n",
      "epoch 23 iter 280, loss: 1.494, accuracy: 0.839\n",
      "epoch 24 iter 0, loss: 1.613, accuracy: 0.831\n",
      "epoch 24 iter 20, loss: 1.604, accuracy: 0.823\n",
      "epoch 24 iter 40, loss: 1.599, accuracy: 0.818\n",
      "epoch 24 iter 60, loss: 1.557, accuracy: 0.821\n",
      "epoch 24 iter 80, loss: 1.533, accuracy: 0.827\n",
      "epoch 24 iter 100, loss: 1.413, accuracy: 0.837\n",
      "epoch 24 iter 120, loss: 1.452, accuracy: 0.824\n",
      "epoch 24 iter 140, loss: 1.488, accuracy: 0.817\n",
      "epoch 24 iter 160, loss: 1.534, accuracy: 0.832\n",
      "epoch 24 iter 180, loss: 1.638, accuracy: 0.801\n",
      "epoch 24 iter 200, loss: 1.640, accuracy: 0.828\n",
      "epoch 24 iter 220, loss: 1.679, accuracy: 0.820\n",
      "epoch 24 iter 240, loss: 1.480, accuracy: 0.828\n",
      "epoch 24 iter 260, loss: 1.498, accuracy: 0.840\n",
      "epoch 24 iter 280, loss: 1.536, accuracy: 0.841\n",
      "epoch 25 iter 0, loss: 1.641, accuracy: 0.839\n",
      "epoch 25 iter 20, loss: 1.534, accuracy: 0.830\n",
      "epoch 25 iter 40, loss: 1.607, accuracy: 0.828\n",
      "epoch 25 iter 60, loss: 1.538, accuracy: 0.834\n",
      "epoch 25 iter 80, loss: 1.575, accuracy: 0.826\n",
      "epoch 25 iter 100, loss: 1.435, accuracy: 0.835\n",
      "epoch 25 iter 120, loss: 1.571, accuracy: 0.829\n",
      "epoch 25 iter 140, loss: 1.666, accuracy: 0.828\n",
      "epoch 25 iter 160, loss: 1.582, accuracy: 0.838\n",
      "epoch 25 iter 180, loss: 1.722, accuracy: 0.804\n",
      "epoch 25 iter 200, loss: 1.671, accuracy: 0.819\n",
      "epoch 25 iter 220, loss: 1.634, accuracy: 0.821\n",
      "epoch 25 iter 240, loss: 1.640, accuracy: 0.830\n",
      "epoch 25 iter 260, loss: 1.466, accuracy: 0.829\n",
      "epoch 25 iter 280, loss: 1.585, accuracy: 0.837\n",
      "epoch 26 iter 0, loss: 1.629, accuracy: 0.837\n",
      "epoch 26 iter 20, loss: 1.627, accuracy: 0.832\n",
      "epoch 26 iter 40, loss: 1.663, accuracy: 0.828\n",
      "epoch 26 iter 60, loss: 1.572, accuracy: 0.830\n",
      "epoch 26 iter 80, loss: 1.672, accuracy: 0.826\n",
      "epoch 26 iter 100, loss: 1.511, accuracy: 0.828\n",
      "epoch 26 iter 120, loss: 1.669, accuracy: 0.832\n",
      "epoch 26 iter 140, loss: 1.701, accuracy: 0.836\n",
      "epoch 26 iter 160, loss: 1.586, accuracy: 0.836\n",
      "epoch 26 iter 180, loss: 1.651, accuracy: 0.823\n",
      "epoch 26 iter 200, loss: 1.581, accuracy: 0.825\n",
      "epoch 26 iter 220, loss: 1.806, accuracy: 0.819\n",
      "epoch 26 iter 240, loss: 1.732, accuracy: 0.829\n",
      "epoch 26 iter 260, loss: 1.527, accuracy: 0.829\n",
      "epoch 26 iter 280, loss: 1.669, accuracy: 0.834\n",
      "epoch 27 iter 0, loss: 1.719, accuracy: 0.837\n",
      "epoch 27 iter 20, loss: 1.814, accuracy: 0.832\n",
      "epoch 27 iter 40, loss: 1.631, accuracy: 0.829\n",
      "epoch 27 iter 60, loss: 1.730, accuracy: 0.825\n",
      "epoch 27 iter 80, loss: 1.739, accuracy: 0.835\n",
      "epoch 27 iter 100, loss: 1.685, accuracy: 0.825\n",
      "epoch 27 iter 120, loss: 1.617, accuracy: 0.829\n",
      "epoch 27 iter 140, loss: 2.035, accuracy: 0.831\n",
      "epoch 27 iter 160, loss: 1.769, accuracy: 0.814\n",
      "epoch 27 iter 180, loss: 1.703, accuracy: 0.826\n",
      "epoch 27 iter 200, loss: 1.648, accuracy: 0.842\n",
      "epoch 27 iter 220, loss: 1.861, accuracy: 0.826\n",
      "epoch 27 iter 240, loss: 1.693, accuracy: 0.828\n",
      "epoch 27 iter 260, loss: 1.623, accuracy: 0.835\n",
      "epoch 27 iter 280, loss: 1.792, accuracy: 0.832\n",
      "epoch 28 iter 0, loss: 1.820, accuracy: 0.835\n",
      "epoch 28 iter 20, loss: 1.921, accuracy: 0.827\n",
      "epoch 28 iter 40, loss: 1.767, accuracy: 0.833\n",
      "epoch 28 iter 60, loss: 1.825, accuracy: 0.822\n",
      "epoch 28 iter 80, loss: 1.812, accuracy: 0.834\n",
      "epoch 28 iter 100, loss: 1.630, accuracy: 0.831\n",
      "epoch 28 iter 120, loss: 1.823, accuracy: 0.839\n",
      "epoch 28 iter 140, loss: 2.074, accuracy: 0.832\n",
      "epoch 28 iter 160, loss: 1.821, accuracy: 0.827\n",
      "epoch 28 iter 180, loss: 1.751, accuracy: 0.824\n",
      "epoch 28 iter 200, loss: 1.737, accuracy: 0.841\n",
      "epoch 28 iter 220, loss: 1.755, accuracy: 0.830\n",
      "epoch 28 iter 240, loss: 1.781, accuracy: 0.838\n",
      "epoch 28 iter 260, loss: 1.820, accuracy: 0.832\n",
      "epoch 28 iter 280, loss: 1.862, accuracy: 0.828\n",
      "epoch 29 iter 0, loss: 1.809, accuracy: 0.835\n",
      "epoch 29 iter 20, loss: 1.941, accuracy: 0.830\n",
      "epoch 29 iter 40, loss: 1.782, accuracy: 0.832\n",
      "epoch 29 iter 60, loss: 2.079, accuracy: 0.821\n",
      "epoch 29 iter 80, loss: 1.842, accuracy: 0.839\n",
      "epoch 29 iter 100, loss: 1.784, accuracy: 0.835\n",
      "epoch 29 iter 120, loss: 1.939, accuracy: 0.829\n",
      "epoch 29 iter 140, loss: 2.071, accuracy: 0.836\n",
      "epoch 29 iter 160, loss: 1.910, accuracy: 0.826\n",
      "epoch 29 iter 180, loss: 1.929, accuracy: 0.810\n",
      "epoch 29 iter 200, loss: 1.930, accuracy: 0.834\n",
      "epoch 29 iter 220, loss: 1.884, accuracy: 0.832\n",
      "epoch 29 iter 240, loss: 1.826, accuracy: 0.841\n",
      "epoch 29 iter 260, loss: 1.749, accuracy: 0.839\n",
      "epoch 29 iter 280, loss: 2.016, accuracy: 0.823\n",
      "epoch 30 iter 0, loss: 1.939, accuracy: 0.837\n",
      "epoch 30 iter 20, loss: 2.046, accuracy: 0.828\n",
      "epoch 30 iter 40, loss: 1.897, accuracy: 0.839\n",
      "epoch 30 iter 60, loss: 2.116, accuracy: 0.833\n",
      "epoch 30 iter 80, loss: 1.981, accuracy: 0.836\n",
      "epoch 30 iter 100, loss: 1.898, accuracy: 0.831\n",
      "epoch 30 iter 120, loss: 1.910, accuracy: 0.837\n",
      "epoch 30 iter 140, loss: 2.096, accuracy: 0.831\n",
      "epoch 30 iter 160, loss: 1.775, accuracy: 0.834\n",
      "epoch 30 iter 180, loss: 2.150, accuracy: 0.831\n",
      "epoch 30 iter 200, loss: 2.040, accuracy: 0.825\n",
      "epoch 30 iter 220, loss: 1.902, accuracy: 0.833\n",
      "epoch 30 iter 240, loss: 1.914, accuracy: 0.835\n",
      "epoch 30 iter 260, loss: 1.950, accuracy: 0.834\n",
      "epoch 30 iter 280, loss: 1.938, accuracy: 0.829\n",
      "epoch 31 iter 0, loss: 2.154, accuracy: 0.830\n",
      "epoch 31 iter 20, loss: 2.148, accuracy: 0.832\n",
      "epoch 31 iter 40, loss: 1.955, accuracy: 0.840\n",
      "epoch 31 iter 60, loss: 2.043, accuracy: 0.834\n",
      "epoch 31 iter 80, loss: 2.106, accuracy: 0.832\n",
      "epoch 31 iter 100, loss: 1.957, accuracy: 0.834\n",
      "epoch 31 iter 120, loss: 1.836, accuracy: 0.825\n",
      "epoch 31 iter 140, loss: 2.431, accuracy: 0.829\n",
      "epoch 31 iter 160, loss: 2.110, accuracy: 0.829\n",
      "epoch 31 iter 180, loss: 2.127, accuracy: 0.827\n",
      "epoch 31 iter 200, loss: 2.093, accuracy: 0.825\n",
      "epoch 31 iter 220, loss: 1.832, accuracy: 0.834\n",
      "epoch 31 iter 240, loss: 2.006, accuracy: 0.834\n",
      "epoch 31 iter 260, loss: 1.830, accuracy: 0.838\n",
      "epoch 31 iter 280, loss: 1.953, accuracy: 0.835\n",
      "epoch 32 iter 0, loss: 1.967, accuracy: 0.835\n",
      "epoch 32 iter 20, loss: 1.962, accuracy: 0.839\n",
      "epoch 32 iter 40, loss: 1.873, accuracy: 0.834\n",
      "epoch 32 iter 60, loss: 1.986, accuracy: 0.833\n",
      "epoch 32 iter 80, loss: 2.191, accuracy: 0.834\n",
      "epoch 32 iter 100, loss: 2.086, accuracy: 0.833\n",
      "epoch 32 iter 120, loss: 1.997, accuracy: 0.834\n",
      "epoch 32 iter 140, loss: 2.167, accuracy: 0.834\n",
      "epoch 32 iter 160, loss: 2.129, accuracy: 0.831\n",
      "epoch 32 iter 180, loss: 2.135, accuracy: 0.833\n",
      "epoch 32 iter 200, loss: 1.916, accuracy: 0.828\n",
      "epoch 32 iter 220, loss: 2.089, accuracy: 0.820\n",
      "epoch 32 iter 240, loss: 2.150, accuracy: 0.837\n",
      "epoch 32 iter 260, loss: 2.025, accuracy: 0.824\n",
      "epoch 32 iter 280, loss: 1.945, accuracy: 0.832\n",
      "epoch 33 iter 0, loss: 2.033, accuracy: 0.841\n",
      "epoch 33 iter 20, loss: 2.188, accuracy: 0.841\n",
      "epoch 33 iter 40, loss: 1.999, accuracy: 0.836\n",
      "epoch 33 iter 60, loss: 2.069, accuracy: 0.829\n",
      "epoch 33 iter 80, loss: 2.044, accuracy: 0.837\n",
      "epoch 33 iter 100, loss: 1.944, accuracy: 0.844\n",
      "epoch 33 iter 120, loss: 2.023, accuracy: 0.835\n",
      "epoch 33 iter 140, loss: 2.195, accuracy: 0.840\n",
      "epoch 33 iter 160, loss: 2.151, accuracy: 0.831\n",
      "epoch 33 iter 180, loss: 2.097, accuracy: 0.837\n",
      "epoch 33 iter 200, loss: 2.088, accuracy: 0.819\n",
      "epoch 33 iter 220, loss: 2.182, accuracy: 0.826\n",
      "epoch 33 iter 240, loss: 2.142, accuracy: 0.837\n",
      "epoch 33 iter 260, loss: 1.984, accuracy: 0.828\n",
      "epoch 33 iter 280, loss: 1.948, accuracy: 0.834\n",
      "epoch 34 iter 0, loss: 2.038, accuracy: 0.832\n",
      "epoch 34 iter 20, loss: 2.224, accuracy: 0.828\n",
      "epoch 34 iter 40, loss: 2.117, accuracy: 0.827\n",
      "epoch 34 iter 60, loss: 2.253, accuracy: 0.835\n",
      "epoch 34 iter 80, loss: 2.081, accuracy: 0.835\n",
      "epoch 34 iter 100, loss: 1.999, accuracy: 0.842\n",
      "epoch 34 iter 120, loss: 1.970, accuracy: 0.833\n",
      "epoch 34 iter 140, loss: 2.258, accuracy: 0.838\n",
      "epoch 34 iter 160, loss: 2.182, accuracy: 0.829\n",
      "epoch 34 iter 180, loss: 2.233, accuracy: 0.838\n",
      "epoch 34 iter 200, loss: 2.204, accuracy: 0.829\n",
      "epoch 34 iter 220, loss: 2.091, accuracy: 0.822\n",
      "epoch 34 iter 240, loss: 2.324, accuracy: 0.836\n",
      "epoch 34 iter 260, loss: 2.121, accuracy: 0.834\n",
      "epoch 34 iter 280, loss: 2.092, accuracy: 0.838\n",
      "epoch 35 iter 0, loss: 2.245, accuracy: 0.837\n",
      "epoch 35 iter 20, loss: 2.306, accuracy: 0.839\n",
      "epoch 35 iter 40, loss: 2.465, accuracy: 0.834\n",
      "epoch 35 iter 60, loss: 2.390, accuracy: 0.838\n",
      "epoch 35 iter 80, loss: 2.189, accuracy: 0.838\n",
      "epoch 35 iter 100, loss: 2.048, accuracy: 0.840\n",
      "epoch 35 iter 120, loss: 2.077, accuracy: 0.842\n",
      "epoch 35 iter 140, loss: 2.321, accuracy: 0.839\n",
      "epoch 35 iter 160, loss: 2.053, accuracy: 0.832\n",
      "epoch 35 iter 180, loss: 2.287, accuracy: 0.835\n",
      "epoch 35 iter 200, loss: 2.088, accuracy: 0.843\n",
      "epoch 35 iter 220, loss: 2.068, accuracy: 0.833\n",
      "epoch 35 iter 240, loss: 2.494, accuracy: 0.833\n",
      "epoch 35 iter 260, loss: 2.157, accuracy: 0.838\n",
      "epoch 35 iter 280, loss: 2.101, accuracy: 0.842\n",
      "epoch 36 iter 0, loss: 2.198, accuracy: 0.836\n",
      "epoch 36 iter 20, loss: 2.532, accuracy: 0.837\n",
      "epoch 36 iter 40, loss: 2.441, accuracy: 0.840\n",
      "epoch 36 iter 60, loss: 2.398, accuracy: 0.829\n",
      "epoch 36 iter 80, loss: 2.305, accuracy: 0.837\n",
      "epoch 36 iter 100, loss: 2.245, accuracy: 0.837\n",
      "epoch 36 iter 120, loss: 2.232, accuracy: 0.840\n",
      "epoch 36 iter 140, loss: 2.424, accuracy: 0.833\n",
      "epoch 36 iter 160, loss: 2.319, accuracy: 0.826\n",
      "epoch 36 iter 180, loss: 2.594, accuracy: 0.838\n",
      "epoch 36 iter 200, loss: 2.531, accuracy: 0.826\n",
      "epoch 36 iter 220, loss: 2.524, accuracy: 0.828\n",
      "epoch 36 iter 240, loss: 2.501, accuracy: 0.833\n",
      "epoch 36 iter 260, loss: 2.089, accuracy: 0.838\n",
      "epoch 36 iter 280, loss: 2.285, accuracy: 0.839\n",
      "epoch 37 iter 0, loss: 2.401, accuracy: 0.835\n",
      "epoch 37 iter 20, loss: 2.608, accuracy: 0.837\n",
      "epoch 37 iter 40, loss: 2.339, accuracy: 0.838\n",
      "epoch 37 iter 60, loss: 2.637, accuracy: 0.835\n",
      "epoch 37 iter 80, loss: 2.460, accuracy: 0.827\n",
      "epoch 37 iter 100, loss: 2.201, accuracy: 0.834\n",
      "epoch 37 iter 120, loss: 2.297, accuracy: 0.835\n",
      "epoch 37 iter 140, loss: 2.304, accuracy: 0.834\n",
      "epoch 37 iter 160, loss: 2.285, accuracy: 0.828\n",
      "epoch 37 iter 180, loss: 2.502, accuracy: 0.836\n",
      "epoch 37 iter 200, loss: 2.206, accuracy: 0.841\n",
      "epoch 37 iter 220, loss: 2.609, accuracy: 0.831\n",
      "epoch 37 iter 240, loss: 2.847, accuracy: 0.834\n",
      "epoch 37 iter 260, loss: 2.296, accuracy: 0.834\n",
      "epoch 37 iter 280, loss: 2.228, accuracy: 0.834\n",
      "epoch 38 iter 0, loss: 2.373, accuracy: 0.832\n",
      "epoch 38 iter 20, loss: 2.698, accuracy: 0.836\n",
      "epoch 38 iter 40, loss: 2.321, accuracy: 0.830\n",
      "epoch 38 iter 60, loss: 2.668, accuracy: 0.831\n",
      "epoch 38 iter 80, loss: 2.581, accuracy: 0.838\n",
      "epoch 38 iter 100, loss: 2.471, accuracy: 0.840\n",
      "epoch 38 iter 120, loss: 2.383, accuracy: 0.842\n",
      "epoch 38 iter 140, loss: 2.532, accuracy: 0.835\n",
      "epoch 38 iter 160, loss: 2.191, accuracy: 0.824\n",
      "epoch 38 iter 180, loss: 2.632, accuracy: 0.839\n",
      "epoch 38 iter 200, loss: 2.465, accuracy: 0.827\n",
      "epoch 38 iter 220, loss: 2.529, accuracy: 0.833\n",
      "epoch 38 iter 240, loss: 2.837, accuracy: 0.835\n",
      "epoch 38 iter 260, loss: 2.557, accuracy: 0.831\n",
      "epoch 38 iter 280, loss: 2.326, accuracy: 0.837\n",
      "epoch 39 iter 0, loss: 2.408, accuracy: 0.838\n",
      "epoch 39 iter 20, loss: 2.667, accuracy: 0.840\n",
      "epoch 39 iter 40, loss: 2.456, accuracy: 0.843\n",
      "epoch 39 iter 60, loss: 2.704, accuracy: 0.827\n",
      "epoch 39 iter 80, loss: 2.758, accuracy: 0.840\n",
      "epoch 39 iter 100, loss: 2.580, accuracy: 0.834\n",
      "epoch 39 iter 120, loss: 2.695, accuracy: 0.839\n",
      "epoch 39 iter 140, loss: 2.579, accuracy: 0.840\n",
      "epoch 39 iter 160, loss: 2.416, accuracy: 0.834\n",
      "epoch 39 iter 180, loss: 2.621, accuracy: 0.835\n",
      "epoch 39 iter 200, loss: 2.744, accuracy: 0.820\n",
      "epoch 39 iter 220, loss: 2.462, accuracy: 0.831\n",
      "epoch 39 iter 240, loss: 2.741, accuracy: 0.837\n",
      "epoch 39 iter 260, loss: 2.502, accuracy: 0.832\n",
      "epoch 39 iter 280, loss: 2.417, accuracy: 0.846\n",
      "epoch 40 iter 0, loss: 2.496, accuracy: 0.840\n",
      "epoch 40 iter 20, loss: 2.684, accuracy: 0.834\n",
      "epoch 40 iter 40, loss: 2.468, accuracy: 0.836\n",
      "epoch 40 iter 60, loss: 2.579, accuracy: 0.820\n",
      "epoch 40 iter 80, loss: 2.782, accuracy: 0.835\n",
      "epoch 40 iter 100, loss: 2.575, accuracy: 0.842\n",
      "epoch 40 iter 120, loss: 2.307, accuracy: 0.837\n",
      "epoch 40 iter 140, loss: 2.692, accuracy: 0.844\n",
      "epoch 40 iter 160, loss: 2.405, accuracy: 0.837\n",
      "epoch 40 iter 180, loss: 2.332, accuracy: 0.840\n",
      "epoch 40 iter 200, loss: 2.549, accuracy: 0.823\n",
      "epoch 40 iter 220, loss: 2.414, accuracy: 0.826\n",
      "epoch 40 iter 240, loss: 2.813, accuracy: 0.833\n",
      "epoch 40 iter 260, loss: 2.501, accuracy: 0.832\n",
      "epoch 40 iter 280, loss: 2.291, accuracy: 0.834\n",
      "epoch 41 iter 0, loss: 2.543, accuracy: 0.836\n",
      "epoch 41 iter 20, loss: 2.562, accuracy: 0.846\n",
      "epoch 41 iter 40, loss: 2.565, accuracy: 0.828\n",
      "epoch 41 iter 60, loss: 2.645, accuracy: 0.831\n",
      "epoch 41 iter 80, loss: 2.724, accuracy: 0.843\n",
      "epoch 41 iter 100, loss: 2.602, accuracy: 0.835\n",
      "epoch 41 iter 120, loss: 2.656, accuracy: 0.840\n",
      "epoch 41 iter 140, loss: 2.631, accuracy: 0.846\n",
      "epoch 41 iter 160, loss: 2.603, accuracy: 0.830\n",
      "epoch 41 iter 180, loss: 2.504, accuracy: 0.843\n",
      "epoch 41 iter 200, loss: 2.661, accuracy: 0.827\n",
      "epoch 41 iter 220, loss: 2.497, accuracy: 0.832\n",
      "epoch 41 iter 240, loss: 3.083, accuracy: 0.824\n",
      "epoch 41 iter 260, loss: 2.515, accuracy: 0.840\n",
      "epoch 41 iter 280, loss: 2.587, accuracy: 0.840\n",
      "epoch 42 iter 0, loss: 2.636, accuracy: 0.832\n",
      "epoch 42 iter 20, loss: 2.745, accuracy: 0.841\n",
      "epoch 42 iter 40, loss: 2.491, accuracy: 0.843\n",
      "epoch 42 iter 60, loss: 2.615, accuracy: 0.839\n",
      "epoch 42 iter 80, loss: 2.753, accuracy: 0.842\n",
      "epoch 42 iter 100, loss: 2.599, accuracy: 0.839\n",
      "epoch 42 iter 120, loss: 2.421, accuracy: 0.845\n",
      "epoch 42 iter 140, loss: 3.190, accuracy: 0.836\n",
      "epoch 42 iter 160, loss: 2.558, accuracy: 0.832\n",
      "epoch 42 iter 180, loss: 2.682, accuracy: 0.835\n",
      "epoch 42 iter 200, loss: 3.074, accuracy: 0.825\n",
      "epoch 42 iter 220, loss: 2.583, accuracy: 0.828\n",
      "epoch 42 iter 240, loss: 2.931, accuracy: 0.837\n",
      "epoch 42 iter 260, loss: 2.496, accuracy: 0.840\n",
      "epoch 42 iter 280, loss: 2.666, accuracy: 0.842\n",
      "epoch 43 iter 0, loss: 2.717, accuracy: 0.837\n",
      "epoch 43 iter 20, loss: 2.686, accuracy: 0.849\n",
      "epoch 43 iter 40, loss: 2.857, accuracy: 0.837\n",
      "epoch 43 iter 60, loss: 2.829, accuracy: 0.837\n",
      "epoch 43 iter 80, loss: 2.947, accuracy: 0.837\n",
      "epoch 43 iter 100, loss: 2.663, accuracy: 0.842\n",
      "epoch 43 iter 120, loss: 2.717, accuracy: 0.836\n",
      "epoch 43 iter 140, loss: 3.004, accuracy: 0.843\n",
      "epoch 43 iter 160, loss: 2.593, accuracy: 0.826\n",
      "epoch 43 iter 180, loss: 2.799, accuracy: 0.843\n",
      "epoch 43 iter 200, loss: 3.042, accuracy: 0.836\n",
      "epoch 43 iter 220, loss: 2.684, accuracy: 0.820\n",
      "epoch 43 iter 240, loss: 2.973, accuracy: 0.839\n",
      "epoch 43 iter 260, loss: 2.749, accuracy: 0.836\n",
      "epoch 43 iter 280, loss: 2.639, accuracy: 0.847\n",
      "epoch 44 iter 0, loss: 2.935, accuracy: 0.836\n",
      "epoch 44 iter 20, loss: 2.757, accuracy: 0.847\n",
      "epoch 44 iter 40, loss: 2.752, accuracy: 0.841\n",
      "epoch 44 iter 60, loss: 2.801, accuracy: 0.834\n",
      "epoch 44 iter 80, loss: 2.739, accuracy: 0.837\n",
      "epoch 44 iter 100, loss: 2.554, accuracy: 0.838\n",
      "epoch 44 iter 120, loss: 2.590, accuracy: 0.835\n",
      "epoch 44 iter 140, loss: 2.839, accuracy: 0.845\n",
      "epoch 44 iter 160, loss: 2.854, accuracy: 0.832\n",
      "epoch 44 iter 180, loss: 2.566, accuracy: 0.840\n",
      "epoch 44 iter 200, loss: 2.829, accuracy: 0.839\n",
      "epoch 44 iter 220, loss: 2.683, accuracy: 0.830\n",
      "epoch 44 iter 240, loss: 2.916, accuracy: 0.838\n",
      "epoch 44 iter 260, loss: 2.679, accuracy: 0.842\n",
      "epoch 44 iter 280, loss: 2.678, accuracy: 0.838\n",
      "epoch 45 iter 0, loss: 2.868, accuracy: 0.839\n",
      "epoch 45 iter 20, loss: 3.093, accuracy: 0.841\n",
      "epoch 45 iter 40, loss: 2.703, accuracy: 0.836\n",
      "epoch 45 iter 60, loss: 2.896, accuracy: 0.837\n",
      "epoch 45 iter 80, loss: 2.786, accuracy: 0.844\n",
      "epoch 45 iter 100, loss: 2.787, accuracy: 0.844\n",
      "epoch 45 iter 120, loss: 2.737, accuracy: 0.843\n",
      "epoch 45 iter 140, loss: 3.131, accuracy: 0.840\n",
      "epoch 45 iter 160, loss: 2.672, accuracy: 0.841\n",
      "epoch 45 iter 180, loss: 2.942, accuracy: 0.843\n",
      "epoch 45 iter 200, loss: 2.978, accuracy: 0.835\n",
      "epoch 45 iter 220, loss: 2.839, accuracy: 0.833\n",
      "epoch 45 iter 240, loss: 3.093, accuracy: 0.826\n",
      "epoch 45 iter 260, loss: 2.790, accuracy: 0.835\n",
      "epoch 45 iter 280, loss: 2.785, accuracy: 0.839\n",
      "epoch 46 iter 0, loss: 2.996, accuracy: 0.839\n",
      "epoch 46 iter 20, loss: 3.383, accuracy: 0.833\n",
      "epoch 46 iter 40, loss: 3.116, accuracy: 0.839\n",
      "epoch 46 iter 60, loss: 2.887, accuracy: 0.842\n",
      "epoch 46 iter 80, loss: 2.862, accuracy: 0.844\n",
      "epoch 46 iter 100, loss: 2.972, accuracy: 0.845\n",
      "epoch 46 iter 120, loss: 2.587, accuracy: 0.840\n",
      "epoch 46 iter 140, loss: 3.024, accuracy: 0.845\n",
      "epoch 46 iter 160, loss: 3.035, accuracy: 0.843\n",
      "epoch 46 iter 180, loss: 2.961, accuracy: 0.833\n",
      "epoch 46 iter 200, loss: 3.136, accuracy: 0.842\n",
      "epoch 46 iter 220, loss: 2.920, accuracy: 0.826\n",
      "epoch 46 iter 240, loss: 3.387, accuracy: 0.834\n",
      "epoch 46 iter 260, loss: 3.063, accuracy: 0.834\n",
      "epoch 46 iter 280, loss: 2.763, accuracy: 0.841\n",
      "epoch 47 iter 0, loss: 2.760, accuracy: 0.839\n",
      "epoch 47 iter 20, loss: 3.100, accuracy: 0.845\n",
      "epoch 47 iter 40, loss: 2.938, accuracy: 0.839\n",
      "epoch 47 iter 60, loss: 2.806, accuracy: 0.841\n",
      "epoch 47 iter 80, loss: 3.051, accuracy: 0.848\n",
      "epoch 47 iter 100, loss: 2.988, accuracy: 0.845\n",
      "epoch 47 iter 120, loss: 2.688, accuracy: 0.841\n",
      "epoch 47 iter 140, loss: 3.171, accuracy: 0.838\n",
      "epoch 47 iter 160, loss: 2.894, accuracy: 0.824\n",
      "epoch 47 iter 180, loss: 3.046, accuracy: 0.838\n",
      "epoch 47 iter 200, loss: 3.108, accuracy: 0.839\n",
      "epoch 47 iter 220, loss: 3.123, accuracy: 0.832\n",
      "epoch 47 iter 240, loss: 3.193, accuracy: 0.832\n",
      "epoch 47 iter 260, loss: 2.978, accuracy: 0.828\n",
      "epoch 47 iter 280, loss: 2.976, accuracy: 0.837\n",
      "epoch 48 iter 0, loss: 3.057, accuracy: 0.837\n"
     ]
    }
   ],
   "source": [
    "model_dict = apply_classification_loss(cnn_map)\n",
    "train_model_tensorboard(model_dict, dataset_generators, epoch_n=50, print_every=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and testing visualization results for the two convolutional layer network in part 1.2:**\n",
    "      \n",
    "1. Filters:\n",
    "\n",
    "<img src=\"filters.png\" style=\"weight:20px;\"> \n",
    "\n",
    "2. Loss:\n",
    "\n",
    "<img src=\"loss.png\" style=\"weight:50px;\"> \n",
    "\n",
    "3. Accuracy:\n",
    "\n",
    "<img src=\"accuracy.png\" style=\"weight:50px;\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plots show that the training accuracy(blue) is better then the testing accuracy(orange). Also the loss plot shown that we need regularization. The filters histograms show the weight values(x axis) vs. frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Bonus\n",
    "(20 points)\n",
    "\n",
    "### Q5.1 SVHN Net ++\n",
    "Improve the accuracy of SVHN Net beyond that of the provided demo: SVHN Net ++."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the homework I implemented an architecture similar to VGG Net:\n",
    "\n",
    "conv1: kernel_size = [3,3], filters = 64  \n",
    "conv2: kernel_size = [3,3], filters = 64  \n",
    "pool1: pool_size=[2, 2], strides=2  \n",
    "conv3: kernel_size = [3,3], filters = 128  \n",
    "conv4: kernel_size = [3,3], filters = 128  \n",
    "pool2: pool_size=[2, 2], strides=2  \n",
    "conv5: kernel_size = [3,3], filters = 256  \n",
    "conv6: kernel_size = [3,3], filters = 256  \n",
    "conv7: kernel_size = [3,3], filters = 256  \n",
    "pool3: pool_size=[2, 2], strides=2  \n",
    "conv8: kernel_size = [3,3], filters = 256  \n",
    "conv9: kernel_size = [3,3], filters = 256  \n",
    "conv10: kernel_size = [3,3], filters = 256  \n",
    "pool4: pool_size=[2, 2], strides=2  \n",
    "fc: units=1000  \n",
    "fc: units=1000  \n",
    "fc: units=500  \n",
    "  \n",
    "With this architecture I get an accuracy: 0.937  \n",
    "\n",
    "I also tried AlexNet, however I got a lower accuracy compared with the above architecture implemetation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_classification_loss_plus(model_function):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        with tf.device(\"/gpu:0\"):  # use gpu:0 if on GPU\n",
    "            x_ = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "            y_ = tf.placeholder(tf.int32, [None])\n",
    "            y_logits = model_function(x_)\n",
    "            \n",
    "            y_dict = dict(labels=y_, logits=y_logits)\n",
    "            losses = tf.nn.sparse_softmax_cross_entropy_with_logits(**y_dict)\n",
    "            cross_entropy_loss = tf.reduce_mean(losses)\n",
    "            trainer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-03)\n",
    "            train_op = trainer.minimize(cross_entropy_loss)\n",
    "            \n",
    "            y_pred = tf.argmax(tf.nn.softmax(y_logits), dimension=1)\n",
    "            correct_prediction = tf.equal(tf.cast(y_pred, tf.int32), y_)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    model_dict = {'graph': g, 'inputs': [x_, y_], 'train_op': train_op,\n",
    "                  'accuracy': accuracy, 'loss': cross_entropy_loss}\n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_vgg_net(x_):\n",
    "    conv1 = tf.layers.conv2d(\n",
    "            inputs=x_,\n",
    "            filters=64,  # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv1')\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "            inputs=conv1,\n",
    "            filters=64, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv2')\n",
    "    \n",
    "#     norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "#             name='norm2')\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv2, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=2, name = 'pool1')  # convolution stride\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "            inputs=pool1,\n",
    "            filters=128, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv3')\n",
    "    \n",
    "#     norm3 = tf.nn.lrn(conv3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "#             name='norm3')\n",
    "    \n",
    "#     pool3 = tf.layers.max_pooling2d(inputs=conv3, \n",
    "#                                     pool_size=[2, 2], \n",
    "#                                     strides=3, name = 'pool3')  # convolution stride\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "            inputs=conv3,\n",
    "            filters=128, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv4')\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv4, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=1, name = 'pool2')  # convolution stride\n",
    "    conv5 = tf.layers.conv2d(\n",
    "            inputs=pool2,\n",
    "            filters=256, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv5')\n",
    "    \n",
    "    conv6 = tf.layers.conv2d(\n",
    "            inputs=conv5,\n",
    "            filters=256, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv6')\n",
    "    \n",
    "    conv7 = tf.layers.conv2d(\n",
    "            inputs=conv6,\n",
    "            filters=256, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv7')      \n",
    "    \n",
    "    \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv7, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=1, name = 'pool3')  # convolution stride\n",
    "    \n",
    "    conv8 = tf.layers.conv2d(\n",
    "            inputs=pool3,\n",
    "            filters=256, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv8')\n",
    "    \n",
    "    conv9 = tf.layers.conv2d(\n",
    "            inputs=conv8,\n",
    "            filters=256, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv9')\n",
    "    \n",
    "    conv10 = tf.layers.conv2d(\n",
    "            inputs=conv9,\n",
    "            filters=256, # number of filters\n",
    "            kernel_size=[3, 3],\n",
    "            padding=\"same\",\n",
    "            activation=tf.nn.relu, name = 'conv10')      \n",
    "    \n",
    "    \n",
    "    pool4 = tf.layers.max_pooling2d(inputs=conv10, \n",
    "                                    pool_size=[2, 2], \n",
    "                                    strides=1, name = 'pool4')  # convolution stride\n",
    "    \n",
    "  \n",
    "    \n",
    "    pool_flat = tf.contrib.layers.flatten(pool4, scope='pool2flat')\n",
    "    dense1 = tf.layers.dense(inputs=pool_flat, units=1000, activation=tf.nn.relu)\n",
    "    dense2 = tf.layers.dense(inputs=dense1, units=1000, activation=tf.nn.relu)\n",
    "    dense3 = tf.layers.dense(inputs=dense2, units=500, activation=tf.nn.relu)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dense3, units=10)\n",
    "    return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "iteration 0 0\t loss: 6.004, accuracy: 0.111\n",
      "iteration 0 20\t loss: 2.235, accuracy: 0.196\n",
      "iteration 0 40\t loss: 2.237, accuracy: 0.196\n",
      "iteration 0 60\t loss: 2.237, accuracy: 0.167\n",
      "iteration 0 80\t loss: 2.228, accuracy: 0.196\n",
      "iteration 0 100\t loss: 2.204, accuracy: 0.196\n",
      "iteration 0 120\t loss: 2.218, accuracy: 0.210\n",
      "iteration 0 140\t loss: 2.038, accuracy: 0.291\n",
      "iteration 0 160\t loss: 1.846, accuracy: 0.383\n",
      "iteration 0 180\t loss: 1.651, accuracy: 0.470\n",
      "iteration 0 200\t loss: 1.260, accuracy: 0.609\n",
      "iteration 0 220\t loss: 1.135, accuracy: 0.641\n",
      "iteration 0 240\t loss: 0.977, accuracy: 0.702\n",
      "iteration 0 260\t loss: 0.761, accuracy: 0.766\n",
      "iteration 0 280\t loss: 0.672, accuracy: 0.803\n",
      "iteration 1 0\t loss: 0.654, accuracy: 0.805\n",
      "iteration 1 20\t loss: 0.625, accuracy: 0.810\n",
      "iteration 1 40\t loss: 0.561, accuracy: 0.834\n",
      "iteration 1 60\t loss: 0.549, accuracy: 0.835\n",
      "iteration 1 80\t loss: 0.520, accuracy: 0.850\n",
      "iteration 1 100\t loss: 0.481, accuracy: 0.861\n",
      "iteration 1 120\t loss: 0.455, accuracy: 0.867\n",
      "iteration 1 140\t loss: 0.439, accuracy: 0.873\n",
      "iteration 1 160\t loss: 0.478, accuracy: 0.854\n",
      "iteration 1 180\t loss: 0.406, accuracy: 0.888\n",
      "iteration 1 200\t loss: 0.401, accuracy: 0.885\n",
      "iteration 1 220\t loss: 0.391, accuracy: 0.883\n",
      "iteration 1 240\t loss: 0.371, accuracy: 0.891\n",
      "iteration 1 260\t loss: 0.353, accuracy: 0.900\n",
      "iteration 1 280\t loss: 0.389, accuracy: 0.885\n",
      "iteration 2 0\t loss: 0.361, accuracy: 0.897\n",
      "iteration 2 20\t loss: 0.350, accuracy: 0.900\n",
      "iteration 2 40\t loss: 0.352, accuracy: 0.898\n",
      "iteration 2 60\t loss: 0.363, accuracy: 0.897\n",
      "iteration 2 80\t loss: 0.346, accuracy: 0.903\n",
      "iteration 2 100\t loss: 0.316, accuracy: 0.911\n",
      "iteration 2 120\t loss: 0.312, accuracy: 0.909\n",
      "iteration 2 140\t loss: 0.323, accuracy: 0.909\n",
      "iteration 2 160\t loss: 0.352, accuracy: 0.897\n",
      "iteration 2 180\t loss: 0.285, accuracy: 0.919\n",
      "iteration 2 200\t loss: 0.306, accuracy: 0.914\n",
      "iteration 2 220\t loss: 0.316, accuracy: 0.908\n",
      "iteration 2 240\t loss: 0.292, accuracy: 0.917\n",
      "iteration 2 260\t loss: 0.299, accuracy: 0.914\n",
      "iteration 2 280\t loss: 0.307, accuracy: 0.914\n",
      "iteration 3 0\t loss: 0.350, accuracy: 0.899\n",
      "iteration 3 20\t loss: 0.301, accuracy: 0.914\n",
      "iteration 3 40\t loss: 0.304, accuracy: 0.912\n",
      "iteration 3 60\t loss: 0.293, accuracy: 0.920\n",
      "iteration 3 80\t loss: 0.285, accuracy: 0.922\n",
      "iteration 3 100\t loss: 0.310, accuracy: 0.914\n",
      "iteration 3 120\t loss: 0.286, accuracy: 0.918\n",
      "iteration 3 140\t loss: 0.308, accuracy: 0.918\n",
      "iteration 3 160\t loss: 0.305, accuracy: 0.914\n",
      "iteration 3 180\t loss: 0.277, accuracy: 0.922\n",
      "iteration 3 200\t loss: 0.340, accuracy: 0.907\n",
      "iteration 3 220\t loss: 0.351, accuracy: 0.895\n",
      "iteration 3 240\t loss: 0.286, accuracy: 0.918\n",
      "iteration 3 260\t loss: 0.265, accuracy: 0.925\n",
      "iteration 3 280\t loss: 0.265, accuracy: 0.928\n",
      "iteration 4 0\t loss: 0.363, accuracy: 0.904\n",
      "iteration 4 20\t loss: 0.269, accuracy: 0.926\n",
      "iteration 4 40\t loss: 0.316, accuracy: 0.909\n",
      "iteration 4 60\t loss: 0.334, accuracy: 0.915\n",
      "iteration 4 80\t loss: 0.269, accuracy: 0.927\n",
      "iteration 4 100\t loss: 0.284, accuracy: 0.921\n",
      "iteration 4 120\t loss: 0.270, accuracy: 0.926\n",
      "iteration 4 140\t loss: 0.289, accuracy: 0.924\n",
      "iteration 4 160\t loss: 0.294, accuracy: 0.918\n",
      "iteration 4 180\t loss: 0.287, accuracy: 0.918\n",
      "iteration 4 200\t loss: 0.285, accuracy: 0.921\n",
      "iteration 4 220\t loss: 0.287, accuracy: 0.921\n",
      "iteration 4 240\t loss: 0.281, accuracy: 0.923\n",
      "iteration 4 260\t loss: 0.305, accuracy: 0.922\n",
      "iteration 4 280\t loss: 0.258, accuracy: 0.931\n",
      "iteration 5 0\t loss: 0.301, accuracy: 0.923\n",
      "iteration 5 20\t loss: 0.275, accuracy: 0.923\n",
      "iteration 5 40\t loss: 0.293, accuracy: 0.923\n",
      "iteration 5 60\t loss: 0.297, accuracy: 0.922\n",
      "iteration 5 80\t loss: 0.285, accuracy: 0.927\n",
      "iteration 5 100\t loss: 0.272, accuracy: 0.927\n",
      "iteration 5 120\t loss: 0.292, accuracy: 0.919\n",
      "iteration 5 140\t loss: 0.273, accuracy: 0.930\n",
      "iteration 5 160\t loss: 0.263, accuracy: 0.931\n",
      "iteration 5 180\t loss: 0.244, accuracy: 0.932\n",
      "iteration 5 200\t loss: 0.312, accuracy: 0.921\n",
      "iteration 5 220\t loss: 0.276, accuracy: 0.927\n",
      "iteration 5 240\t loss: 0.288, accuracy: 0.919\n",
      "iteration 5 260\t loss: 0.296, accuracy: 0.925\n",
      "iteration 5 280\t loss: 0.281, accuracy: 0.930\n",
      "iteration 6 0\t loss: 0.290, accuracy: 0.929\n",
      "iteration 6 20\t loss: 0.240, accuracy: 0.935\n",
      "iteration 6 40\t loss: 0.290, accuracy: 0.925\n",
      "iteration 6 60\t loss: 0.293, accuracy: 0.922\n",
      "iteration 6 80\t loss: 0.288, accuracy: 0.928\n",
      "iteration 6 100\t loss: 0.267, accuracy: 0.928\n",
      "iteration 6 120\t loss: 0.275, accuracy: 0.924\n",
      "iteration 6 140\t loss: 0.284, accuracy: 0.929\n",
      "iteration 6 160\t loss: 0.284, accuracy: 0.926\n",
      "iteration 6 180\t loss: 0.273, accuracy: 0.927\n",
      "iteration 6 200\t loss: 0.280, accuracy: 0.930\n",
      "iteration 6 220\t loss: 0.279, accuracy: 0.928\n",
      "iteration 6 240\t loss: 0.289, accuracy: 0.926\n",
      "iteration 6 260\t loss: 0.339, accuracy: 0.929\n",
      "iteration 6 280\t loss: 0.296, accuracy: 0.925\n",
      "iteration 7 0\t loss: 0.327, accuracy: 0.923\n",
      "iteration 7 20\t loss: 0.257, accuracy: 0.935\n",
      "iteration 7 40\t loss: 0.318, accuracy: 0.921\n",
      "iteration 7 60\t loss: 0.316, accuracy: 0.924\n",
      "iteration 7 80\t loss: 0.294, accuracy: 0.923\n",
      "iteration 7 100\t loss: 0.305, accuracy: 0.926\n",
      "iteration 7 120\t loss: 0.297, accuracy: 0.925\n",
      "iteration 7 140\t loss: 0.323, accuracy: 0.932\n",
      "iteration 7 160\t loss: 0.314, accuracy: 0.923\n",
      "iteration 7 180\t loss: 0.300, accuracy: 0.920\n",
      "iteration 7 200\t loss: 0.296, accuracy: 0.931\n",
      "iteration 7 220\t loss: 0.276, accuracy: 0.934\n",
      "iteration 7 240\t loss: 0.314, accuracy: 0.920\n",
      "iteration 7 260\t loss: 0.314, accuracy: 0.931\n",
      "iteration 7 280\t loss: 0.300, accuracy: 0.930\n",
      "iteration 8 0\t loss: 0.355, accuracy: 0.922\n",
      "iteration 8 20\t loss: 0.272, accuracy: 0.933\n",
      "iteration 8 40\t loss: 0.324, accuracy: 0.920\n",
      "iteration 8 60\t loss: 0.311, accuracy: 0.923\n",
      "iteration 8 80\t loss: 0.302, accuracy: 0.924\n",
      "iteration 8 100\t loss: 0.277, accuracy: 0.933\n",
      "iteration 8 120\t loss: 0.309, accuracy: 0.920\n",
      "iteration 8 140\t loss: 0.326, accuracy: 0.931\n",
      "iteration 8 160\t loss: 0.347, accuracy: 0.906\n",
      "iteration 8 180\t loss: 0.318, accuracy: 0.922\n",
      "iteration 8 200\t loss: 0.309, accuracy: 0.922\n",
      "iteration 8 220\t loss: 0.312, accuracy: 0.925\n",
      "iteration 8 240\t loss: 0.310, accuracy: 0.929\n",
      "iteration 8 260\t loss: 0.289, accuracy: 0.935\n",
      "iteration 8 280\t loss: 0.280, accuracy: 0.934\n",
      "iteration 9 0\t loss: 0.317, accuracy: 0.930\n",
      "iteration 9 20\t loss: 0.314, accuracy: 0.924\n",
      "iteration 9 40\t loss: 0.305, accuracy: 0.927\n",
      "iteration 9 60\t loss: 0.318, accuracy: 0.929\n",
      "iteration 9 80\t loss: 0.324, accuracy: 0.929\n",
      "iteration 9 100\t loss: 0.317, accuracy: 0.929\n",
      "iteration 9 120\t loss: 0.362, accuracy: 0.915\n",
      "iteration 9 140\t loss: 0.410, accuracy: 0.919\n",
      "iteration 9 160\t loss: 0.325, accuracy: 0.920\n",
      "iteration 9 180\t loss: 0.328, accuracy: 0.925\n",
      "iteration 9 200\t loss: 0.334, accuracy: 0.921\n",
      "iteration 9 220\t loss: 0.375, accuracy: 0.928\n",
      "iteration 9 240\t loss: 0.319, accuracy: 0.928\n",
      "iteration 9 260\t loss: 0.289, accuracy: 0.932\n",
      "iteration 9 280\t loss: 0.316, accuracy: 0.935\n",
      "iteration 10 0\t loss: 0.371, accuracy: 0.928\n",
      "iteration 10 20\t loss: 0.320, accuracy: 0.926\n",
      "iteration 10 40\t loss: 0.341, accuracy: 0.926\n",
      "iteration 10 60\t loss: 0.360, accuracy: 0.922\n",
      "iteration 10 80\t loss: 0.371, accuracy: 0.926\n",
      "iteration 10 100\t loss: 0.329, accuracy: 0.930\n",
      "iteration 10 120\t loss: 0.404, accuracy: 0.913\n",
      "iteration 10 140\t loss: 0.367, accuracy: 0.924\n",
      "iteration 10 160\t loss: 0.335, accuracy: 0.922\n",
      "iteration 10 180\t loss: 0.346, accuracy: 0.924\n",
      "iteration 10 200\t loss: 0.322, accuracy: 0.929\n",
      "iteration 10 220\t loss: 0.352, accuracy: 0.937\n",
      "iteration 10 240\t loss: 0.376, accuracy: 0.914\n",
      "iteration 10 260\t loss: 0.346, accuracy: 0.926\n",
      "iteration 10 280\t loss: 0.357, accuracy: 0.929\n",
      "iteration 11 0\t loss: 0.417, accuracy: 0.922\n",
      "iteration 11 20\t loss: 0.327, accuracy: 0.931\n",
      "iteration 11 40\t loss: 0.384, accuracy: 0.918\n",
      "iteration 11 60\t loss: 0.386, accuracy: 0.923\n",
      "iteration 11 80\t loss: 0.334, accuracy: 0.930\n",
      "iteration 11 100\t loss: 0.409, accuracy: 0.921\n",
      "iteration 11 120\t loss: 0.347, accuracy: 0.926\n",
      "iteration 11 140\t loss: 0.363, accuracy: 0.925\n",
      "iteration 11 160\t loss: 0.350, accuracy: 0.924\n",
      "iteration 11 180\t loss: 0.344, accuracy: 0.932\n",
      "iteration 11 200\t loss: 0.360, accuracy: 0.928\n",
      "iteration 11 220\t loss: 0.364, accuracy: 0.932\n",
      "iteration 11 240\t loss: 0.375, accuracy: 0.931\n",
      "iteration 11 260\t loss: 0.400, accuracy: 0.921\n",
      "iteration 11 280\t loss: 0.337, accuracy: 0.931\n",
      "iteration 12 0\t loss: 0.372, accuracy: 0.935\n",
      "iteration 12 20\t loss: 0.369, accuracy: 0.925\n",
      "iteration 12 40\t loss: 0.417, accuracy: 0.922\n",
      "iteration 12 60\t loss: 0.342, accuracy: 0.928\n",
      "iteration 12 80\t loss: 0.344, accuracy: 0.927\n",
      "iteration 12 100\t loss: 0.378, accuracy: 0.928\n",
      "iteration 12 120\t loss: 0.402, accuracy: 0.923\n",
      "iteration 12 140\t loss: 0.391, accuracy: 0.924\n",
      "iteration 12 160\t loss: 0.400, accuracy: 0.926\n",
      "iteration 12 180\t loss: 0.405, accuracy: 0.922\n",
      "iteration 12 200\t loss: 0.404, accuracy: 0.922\n",
      "iteration 12 220\t loss: 0.353, accuracy: 0.931\n",
      "iteration 12 240\t loss: 0.365, accuracy: 0.926\n",
      "iteration 12 260\t loss: 0.350, accuracy: 0.923\n",
      "iteration 12 280\t loss: 0.375, accuracy: 0.930\n",
      "iteration 13 0\t loss: 0.348, accuracy: 0.935\n",
      "iteration 13 20\t loss: 0.416, accuracy: 0.923\n",
      "iteration 13 40\t loss: 0.405, accuracy: 0.931\n",
      "iteration 13 60\t loss: 0.454, accuracy: 0.918\n",
      "iteration 13 80\t loss: 0.314, accuracy: 0.929\n",
      "iteration 13 100\t loss: 0.429, accuracy: 0.931\n",
      "iteration 13 120\t loss: 0.375, accuracy: 0.929\n",
      "iteration 13 140\t loss: 0.406, accuracy: 0.927\n",
      "iteration 13 160\t loss: 0.359, accuracy: 0.928\n",
      "iteration 13 180\t loss: 0.383, accuracy: 0.930\n",
      "iteration 13 200\t loss: 0.386, accuracy: 0.923\n",
      "iteration 13 220\t loss: 0.347, accuracy: 0.929\n",
      "iteration 13 240\t loss: 0.306, accuracy: 0.937\n",
      "iteration 13 260\t loss: 0.351, accuracy: 0.936\n",
      "iteration 13 280\t loss: 0.383, accuracy: 0.929\n",
      "iteration 14 0\t loss: 0.392, accuracy: 0.926\n",
      "iteration 14 20\t loss: 0.387, accuracy: 0.934\n",
      "iteration 14 40\t loss: 0.444, accuracy: 0.930\n",
      "iteration 14 60\t loss: 0.428, accuracy: 0.921\n",
      "iteration 14 80\t loss: 0.418, accuracy: 0.922\n",
      "iteration 14 100\t loss: 0.425, accuracy: 0.925\n",
      "iteration 14 120\t loss: 0.510, accuracy: 0.908\n",
      "iteration 14 140\t loss: 0.352, accuracy: 0.925\n",
      "iteration 14 160\t loss: 0.371, accuracy: 0.930\n",
      "iteration 14 180\t loss: 0.369, accuracy: 0.930\n",
      "iteration 14 200\t loss: 0.451, accuracy: 0.927\n",
      "iteration 14 220\t loss: 0.343, accuracy: 0.930\n",
      "iteration 14 240\t loss: 0.398, accuracy: 0.931\n",
      "iteration 14 260\t loss: 0.409, accuracy: 0.928\n",
      "iteration 14 280\t loss: 0.400, accuracy: 0.928\n",
      "iteration 15 0\t loss: 0.421, accuracy: 0.928\n",
      "iteration 15 20\t loss: 0.368, accuracy: 0.928\n",
      "iteration 15 40\t loss: 0.405, accuracy: 0.926\n",
      "iteration 15 60\t loss: 0.368, accuracy: 0.933\n",
      "iteration 15 80\t loss: 0.375, accuracy: 0.925\n",
      "iteration 15 100\t loss: 0.387, accuracy: 0.933\n",
      "iteration 15 120\t loss: 0.397, accuracy: 0.933\n",
      "iteration 15 140\t loss: 0.461, accuracy: 0.924\n",
      "iteration 15 160\t loss: 0.419, accuracy: 0.924\n",
      "iteration 15 180\t loss: 0.402, accuracy: 0.922\n",
      "iteration 15 200\t loss: 0.425, accuracy: 0.928\n",
      "iteration 15 220\t loss: 0.395, accuracy: 0.926\n",
      "iteration 15 240\t loss: 0.375, accuracy: 0.932\n",
      "iteration 15 260\t loss: 0.421, accuracy: 0.930\n",
      "iteration 15 280\t loss: 0.480, accuracy: 0.930\n",
      "iteration 16 0\t loss: 0.533, accuracy: 0.926\n",
      "iteration 16 20\t loss: 0.418, accuracy: 0.931\n",
      "iteration 16 40\t loss: 0.450, accuracy: 0.922\n",
      "iteration 16 60\t loss: 0.457, accuracy: 0.921\n",
      "iteration 16 80\t loss: 0.385, accuracy: 0.926\n",
      "iteration 16 100\t loss: 0.388, accuracy: 0.927\n",
      "iteration 16 120\t loss: 0.464, accuracy: 0.925\n",
      "iteration 16 140\t loss: 0.549, accuracy: 0.920\n",
      "iteration 16 160\t loss: 0.478, accuracy: 0.923\n",
      "iteration 16 180\t loss: 0.343, accuracy: 0.930\n",
      "iteration 16 200\t loss: 0.483, accuracy: 0.931\n",
      "iteration 16 220\t loss: 0.385, accuracy: 0.929\n",
      "iteration 16 240\t loss: 0.434, accuracy: 0.932\n",
      "iteration 16 260\t loss: 0.401, accuracy: 0.927\n",
      "iteration 16 280\t loss: 0.383, accuracy: 0.927\n",
      "iteration 17 0\t loss: 0.393, accuracy: 0.927\n",
      "iteration 17 20\t loss: 0.411, accuracy: 0.933\n",
      "iteration 17 40\t loss: 0.467, accuracy: 0.930\n",
      "iteration 17 60\t loss: 0.450, accuracy: 0.925\n",
      "iteration 17 80\t loss: 0.389, accuracy: 0.917\n",
      "iteration 17 100\t loss: 0.474, accuracy: 0.927\n",
      "iteration 17 120\t loss: 0.411, accuracy: 0.933\n",
      "iteration 17 140\t loss: 0.432, accuracy: 0.931\n",
      "iteration 17 160\t loss: 0.414, accuracy: 0.928\n",
      "iteration 17 180\t loss: 0.481, accuracy: 0.933\n",
      "iteration 17 200\t loss: 0.451, accuracy: 0.927\n",
      "iteration 17 220\t loss: 0.359, accuracy: 0.928\n",
      "iteration 17 240\t loss: 0.413, accuracy: 0.932\n",
      "iteration 17 260\t loss: 0.470, accuracy: 0.929\n",
      "iteration 17 280\t loss: 0.441, accuracy: 0.929\n",
      "iteration 18 0\t loss: 0.419, accuracy: 0.932\n",
      "iteration 18 20\t loss: 0.437, accuracy: 0.925\n",
      "iteration 18 40\t loss: 0.442, accuracy: 0.933\n",
      "iteration 18 60\t loss: 0.462, accuracy: 0.933\n",
      "iteration 18 80\t loss: 0.383, accuracy: 0.928\n",
      "iteration 18 100\t loss: 0.456, accuracy: 0.932\n",
      "iteration 18 120\t loss: 0.431, accuracy: 0.935\n",
      "iteration 18 140\t loss: 0.519, accuracy: 0.931\n",
      "iteration 18 160\t loss: 0.473, accuracy: 0.930\n",
      "iteration 18 180\t loss: 0.480, accuracy: 0.928\n",
      "iteration 18 200\t loss: 0.465, accuracy: 0.933\n",
      "iteration 18 220\t loss: 0.350, accuracy: 0.925\n",
      "iteration 18 240\t loss: 0.426, accuracy: 0.937\n",
      "iteration 18 260\t loss: 0.398, accuracy: 0.927\n",
      "iteration 18 280\t loss: 0.442, accuracy: 0.931\n",
      "iteration 19 0\t loss: 0.487, accuracy: 0.923\n",
      "iteration 19 20\t loss: 0.375, accuracy: 0.932\n",
      "iteration 19 40\t loss: 0.441, accuracy: 0.930\n",
      "iteration 19 60\t loss: 0.394, accuracy: 0.934\n",
      "iteration 19 80\t loss: 0.445, accuracy: 0.926\n",
      "iteration 19 100\t loss: 0.452, accuracy: 0.933\n",
      "iteration 19 120\t loss: 0.460, accuracy: 0.931\n",
      "iteration 19 140\t loss: 0.465, accuracy: 0.926\n",
      "iteration 19 160\t loss: 0.391, accuracy: 0.930\n",
      "iteration 19 180\t loss: 0.474, accuracy: 0.935\n",
      "iteration 19 200\t loss: 0.574, accuracy: 0.933\n",
      "iteration 19 220\t loss: 0.434, accuracy: 0.927\n",
      "iteration 19 240\t loss: 0.452, accuracy: 0.929\n",
      "iteration 19 260\t loss: 0.479, accuracy: 0.929\n",
      "iteration 19 280\t loss: 0.517, accuracy: 0.930\n",
      "iteration 20 0\t loss: 0.549, accuracy: 0.927\n",
      "iteration 20 20\t loss: 0.480, accuracy: 0.929\n",
      "iteration 20 40\t loss: 0.414, accuracy: 0.932\n",
      "iteration 20 60\t loss: 0.417, accuracy: 0.934\n",
      "iteration 20 80\t loss: 0.420, accuracy: 0.936\n",
      "iteration 20 100\t loss: 0.404, accuracy: 0.930\n",
      "iteration 20 120\t loss: 0.412, accuracy: 0.937\n",
      "iteration 20 140\t loss: 0.508, accuracy: 0.934\n",
      "iteration 20 160\t loss: 0.500, accuracy: 0.930\n",
      "iteration 20 180\t loss: 0.460, accuracy: 0.927\n",
      "iteration 20 200\t loss: 0.516, accuracy: 0.931\n",
      "iteration 20 220\t loss: 0.459, accuracy: 0.931\n",
      "iteration 20 240\t loss: 0.459, accuracy: 0.929\n",
      "iteration 20 260\t loss: 0.489, accuracy: 0.923\n",
      "iteration 20 280\t loss: 0.495, accuracy: 0.933\n",
      "iteration 21 0\t loss: 0.516, accuracy: 0.931\n",
      "iteration 21 20\t loss: 0.452, accuracy: 0.929\n",
      "iteration 21 40\t loss: 0.461, accuracy: 0.932\n",
      "iteration 21 60\t loss: 0.445, accuracy: 0.925\n",
      "iteration 21 80\t loss: 0.466, accuracy: 0.928\n",
      "iteration 21 100\t loss: 0.451, accuracy: 0.929\n",
      "iteration 21 120\t loss: 0.415, accuracy: 0.935\n",
      "iteration 21 140\t loss: 0.619, accuracy: 0.932\n",
      "iteration 21 160\t loss: 0.438, accuracy: 0.935\n",
      "iteration 21 180\t loss: 0.468, accuracy: 0.930\n",
      "iteration 21 200\t loss: 0.513, accuracy: 0.929\n",
      "iteration 21 220\t loss: 0.484, accuracy: 0.926\n",
      "iteration 21 240\t loss: 0.453, accuracy: 0.932\n",
      "iteration 21 260\t loss: 0.488, accuracy: 0.932\n",
      "iteration 21 280\t loss: 0.477, accuracy: 0.923\n",
      "iteration 22 0\t loss: 0.474, accuracy: 0.926\n",
      "iteration 22 20\t loss: 0.467, accuracy: 0.933\n",
      "iteration 22 40\t loss: 0.406, accuracy: 0.931\n",
      "iteration 22 60\t loss: 0.420, accuracy: 0.935\n",
      "iteration 22 80\t loss: 0.404, accuracy: 0.935\n",
      "iteration 22 100\t loss: 0.449, accuracy: 0.928\n",
      "iteration 22 120\t loss: 0.475, accuracy: 0.935\n",
      "iteration 22 140\t loss: 0.601, accuracy: 0.928\n",
      "iteration 22 160\t loss: 0.473, accuracy: 0.928\n",
      "iteration 22 180\t loss: 0.485, accuracy: 0.932\n",
      "iteration 22 200\t loss: 0.503, accuracy: 0.930\n",
      "iteration 22 220\t loss: 0.475, accuracy: 0.927\n",
      "iteration 22 240\t loss: 0.473, accuracy: 0.929\n",
      "iteration 22 260\t loss: 0.489, accuracy: 0.932\n",
      "iteration 22 280\t loss: 0.477, accuracy: 0.932\n",
      "iteration 23 0\t loss: 0.425, accuracy: 0.933\n",
      "iteration 23 20\t loss: 0.516, accuracy: 0.930\n",
      "iteration 23 40\t loss: 0.423, accuracy: 0.934\n",
      "iteration 23 60\t loss: 0.523, accuracy: 0.933\n",
      "iteration 23 80\t loss: 0.506, accuracy: 0.924\n",
      "iteration 23 100\t loss: 0.433, accuracy: 0.930\n",
      "iteration 23 120\t loss: 0.455, accuracy: 0.932\n",
      "iteration 23 140\t loss: 0.433, accuracy: 0.932\n",
      "iteration 23 160\t loss: 0.530, accuracy: 0.924\n",
      "iteration 23 180\t loss: 0.528, accuracy: 0.929\n",
      "iteration 23 200\t loss: 0.559, accuracy: 0.936\n",
      "iteration 23 220\t loss: 0.436, accuracy: 0.937\n",
      "iteration 23 240\t loss: 0.494, accuracy: 0.931\n",
      "iteration 23 260\t loss: 0.413, accuracy: 0.931\n",
      "iteration 23 280\t loss: 0.529, accuracy: 0.930\n",
      "iteration 24 0\t loss: 0.542, accuracy: 0.928\n",
      "iteration 24 20\t loss: 0.450, accuracy: 0.934\n",
      "iteration 24 40\t loss: 0.427, accuracy: 0.939\n",
      "iteration 24 60\t loss: 0.474, accuracy: 0.933\n",
      "iteration 24 80\t loss: 0.477, accuracy: 0.929\n",
      "iteration 24 100\t loss: 0.508, accuracy: 0.929\n",
      "iteration 24 120\t loss: 0.440, accuracy: 0.931\n",
      "iteration 24 140\t loss: 0.473, accuracy: 0.930\n",
      "iteration 24 160\t loss: 0.481, accuracy: 0.927\n",
      "iteration 24 180\t loss: 0.465, accuracy: 0.932\n",
      "iteration 24 200\t loss: 0.440, accuracy: 0.935\n",
      "iteration 24 220\t loss: 0.505, accuracy: 0.932\n",
      "iteration 24 240\t loss: 0.429, accuracy: 0.935\n",
      "iteration 24 260\t loss: 0.493, accuracy: 0.932\n",
      "iteration 24 280\t loss: 0.523, accuracy: 0.932\n",
      "iteration 25 0\t loss: 0.545, accuracy: 0.931\n",
      "iteration 25 20\t loss: 0.465, accuracy: 0.933\n",
      "iteration 25 40\t loss: 0.490, accuracy: 0.935\n",
      "iteration 25 60\t loss: 0.452, accuracy: 0.934\n",
      "iteration 25 80\t loss: 0.502, accuracy: 0.936\n",
      "iteration 25 100\t loss: 0.522, accuracy: 0.931\n",
      "iteration 25 120\t loss: 0.426, accuracy: 0.931\n",
      "iteration 25 140\t loss: 0.473, accuracy: 0.938\n",
      "iteration 25 160\t loss: 0.599, accuracy: 0.925\n",
      "iteration 25 180\t loss: 0.544, accuracy: 0.926\n",
      "iteration 25 200\t loss: 0.524, accuracy: 0.929\n",
      "iteration 25 220\t loss: 0.404, accuracy: 0.931\n",
      "iteration 25 240\t loss: 0.444, accuracy: 0.934\n",
      "iteration 25 260\t loss: 0.448, accuracy: 0.931\n",
      "iteration 25 280\t loss: 0.492, accuracy: 0.931\n",
      "iteration 26 0\t loss: 0.487, accuracy: 0.926\n",
      "iteration 26 20\t loss: 0.536, accuracy: 0.933\n",
      "iteration 26 40\t loss: 0.456, accuracy: 0.932\n",
      "iteration 26 60\t loss: 0.525, accuracy: 0.927\n",
      "iteration 26 80\t loss: 0.547, accuracy: 0.934\n",
      "iteration 26 100\t loss: 0.508, accuracy: 0.937\n",
      "iteration 26 120\t loss: 0.440, accuracy: 0.931\n",
      "iteration 26 140\t loss: 0.527, accuracy: 0.929\n",
      "iteration 26 160\t loss: 0.552, accuracy: 0.920\n",
      "iteration 26 180\t loss: 0.500, accuracy: 0.926\n",
      "iteration 26 200\t loss: 0.481, accuracy: 0.934\n",
      "iteration 26 220\t loss: 0.430, accuracy: 0.932\n",
      "iteration 26 240\t loss: 0.483, accuracy: 0.931\n",
      "iteration 26 260\t loss: 0.509, accuracy: 0.931\n",
      "iteration 26 280\t loss: 0.530, accuracy: 0.933\n",
      "iteration 27 0\t loss: 0.553, accuracy: 0.935\n",
      "iteration 27 20\t loss: 0.437, accuracy: 0.927\n",
      "iteration 27 40\t loss: 0.456, accuracy: 0.933\n",
      "iteration 27 60\t loss: 0.483, accuracy: 0.931\n",
      "iteration 27 80\t loss: 0.457, accuracy: 0.930\n",
      "iteration 27 100\t loss: 0.472, accuracy: 0.929\n",
      "iteration 27 120\t loss: 0.495, accuracy: 0.925\n",
      "iteration 27 140\t loss: 0.524, accuracy: 0.934\n",
      "iteration 27 160\t loss: 0.532, accuracy: 0.933\n",
      "iteration 27 180\t loss: 0.511, accuracy: 0.935\n",
      "iteration 27 200\t loss: 0.532, accuracy: 0.932\n",
      "iteration 27 220\t loss: 0.500, accuracy: 0.928\n",
      "iteration 27 240\t loss: 0.476, accuracy: 0.938\n",
      "iteration 27 260\t loss: 0.478, accuracy: 0.934\n",
      "iteration 27 280\t loss: 0.588, accuracy: 0.934\n",
      "iteration 28 0\t loss: 0.544, accuracy: 0.935\n",
      "iteration 28 20\t loss: 0.445, accuracy: 0.933\n",
      "iteration 28 40\t loss: 0.473, accuracy: 0.936\n",
      "iteration 28 60\t loss: 0.478, accuracy: 0.934\n",
      "iteration 28 80\t loss: 0.488, accuracy: 0.934\n",
      "iteration 28 100\t loss: 0.525, accuracy: 0.932\n",
      "iteration 28 120\t loss: 0.394, accuracy: 0.930\n",
      "iteration 28 140\t loss: 0.521, accuracy: 0.937\n",
      "iteration 28 160\t loss: 0.641, accuracy: 0.934\n",
      "iteration 28 180\t loss: 0.541, accuracy: 0.927\n",
      "iteration 28 200\t loss: 0.475, accuracy: 0.932\n",
      "iteration 28 220\t loss: 0.470, accuracy: 0.930\n",
      "iteration 28 240\t loss: 0.404, accuracy: 0.933\n",
      "iteration 28 260\t loss: 0.520, accuracy: 0.937\n",
      "iteration 28 280\t loss: 0.592, accuracy: 0.927\n",
      "iteration 29 0\t loss: 0.574, accuracy: 0.928\n",
      "iteration 29 20\t loss: 0.516, accuracy: 0.929\n",
      "iteration 29 40\t loss: 0.507, accuracy: 0.932\n",
      "iteration 29 60\t loss: 0.469, accuracy: 0.929\n",
      "iteration 29 80\t loss: 0.579, accuracy: 0.934\n",
      "iteration 29 100\t loss: 0.459, accuracy: 0.925\n",
      "iteration 29 120\t loss: 0.485, accuracy: 0.924\n",
      "iteration 29 140\t loss: 0.526, accuracy: 0.929\n",
      "iteration 29 160\t loss: 0.519, accuracy: 0.917\n",
      "iteration 29 180\t loss: 0.489, accuracy: 0.927\n",
      "iteration 29 200\t loss: 0.472, accuracy: 0.934\n",
      "iteration 29 220\t loss: 0.592, accuracy: 0.925\n",
      "iteration 29 240\t loss: 0.444, accuracy: 0.934\n",
      "iteration 29 260\t loss: 0.428, accuracy: 0.933\n",
      "iteration 29 280\t loss: 0.611, accuracy: 0.933\n",
      "iteration 30 0\t loss: 0.557, accuracy: 0.932\n",
      "iteration 30 20\t loss: 0.468, accuracy: 0.931\n",
      "iteration 30 40\t loss: 0.535, accuracy: 0.933\n",
      "iteration 30 60\t loss: 0.516, accuracy: 0.932\n",
      "iteration 30 80\t loss: 0.500, accuracy: 0.935\n",
      "iteration 30 100\t loss: 0.525, accuracy: 0.937\n",
      "iteration 30 120\t loss: 0.471, accuracy: 0.933\n",
      "iteration 30 140\t loss: 0.525, accuracy: 0.931\n",
      "iteration 30 160\t loss: 0.627, accuracy: 0.923\n",
      "iteration 30 180\t loss: 0.603, accuracy: 0.930\n",
      "iteration 30 200\t loss: 0.538, accuracy: 0.923\n",
      "iteration 30 220\t loss: 0.573, accuracy: 0.925\n",
      "iteration 30 240\t loss: 0.496, accuracy: 0.932\n",
      "iteration 30 260\t loss: 0.428, accuracy: 0.929\n",
      "iteration 30 280\t loss: 0.554, accuracy: 0.932\n",
      "iteration 31 0\t loss: 0.541, accuracy: 0.932\n",
      "iteration 31 20\t loss: 0.510, accuracy: 0.934\n",
      "iteration 31 40\t loss: 0.513, accuracy: 0.934\n",
      "iteration 31 60\t loss: 0.443, accuracy: 0.936\n",
      "iteration 31 80\t loss: 0.452, accuracy: 0.933\n",
      "iteration 31 100\t loss: 0.474, accuracy: 0.933\n",
      "iteration 31 120\t loss: 0.425, accuracy: 0.936\n",
      "iteration 31 140\t loss: 0.527, accuracy: 0.932\n",
      "iteration 31 160\t loss: 0.566, accuracy: 0.929\n",
      "iteration 31 180\t loss: 0.473, accuracy: 0.932\n",
      "iteration 31 200\t loss: 0.500, accuracy: 0.933\n",
      "iteration 31 220\t loss: 0.561, accuracy: 0.934\n",
      "iteration 31 240\t loss: 0.525, accuracy: 0.936\n",
      "iteration 31 260\t loss: 0.511, accuracy: 0.934\n",
      "iteration 31 280\t loss: 0.560, accuracy: 0.936\n",
      "iteration 32 0\t loss: 0.576, accuracy: 0.930\n",
      "iteration 32 20\t loss: 0.505, accuracy: 0.927\n",
      "iteration 32 40\t loss: 0.482, accuracy: 0.932\n",
      "iteration 32 60\t loss: 0.437, accuracy: 0.935\n",
      "iteration 32 80\t loss: 0.507, accuracy: 0.937\n",
      "iteration 32 100\t loss: 0.557, accuracy: 0.930\n",
      "iteration 32 120\t loss: 0.514, accuracy: 0.931\n",
      "iteration 32 140\t loss: 0.545, accuracy: 0.936\n",
      "iteration 32 160\t loss: 0.526, accuracy: 0.933\n",
      "iteration 32 180\t loss: 0.642, accuracy: 0.931\n",
      "iteration 32 200\t loss: 0.521, accuracy: 0.934\n",
      "iteration 32 220\t loss: 0.522, accuracy: 0.929\n",
      "iteration 32 240\t loss: 0.567, accuracy: 0.925\n",
      "iteration 32 260\t loss: 0.527, accuracy: 0.930\n",
      "iteration 32 280\t loss: 0.511, accuracy: 0.931\n",
      "iteration 33 0\t loss: 0.608, accuracy: 0.926\n",
      "iteration 33 20\t loss: 0.604, accuracy: 0.925\n",
      "iteration 33 40\t loss: 0.474, accuracy: 0.933\n",
      "iteration 33 60\t loss: 0.453, accuracy: 0.937\n",
      "iteration 33 80\t loss: 0.549, accuracy: 0.937\n",
      "iteration 33 100\t loss: 0.463, accuracy: 0.932\n",
      "iteration 33 120\t loss: 0.432, accuracy: 0.927\n",
      "iteration 33 140\t loss: 0.515, accuracy: 0.937\n",
      "iteration 33 160\t loss: 0.723, accuracy: 0.926\n",
      "iteration 33 180\t loss: 0.492, accuracy: 0.934\n",
      "iteration 33 200\t loss: 0.520, accuracy: 0.927\n",
      "iteration 33 220\t loss: 0.472, accuracy: 0.934\n",
      "iteration 33 240\t loss: 0.487, accuracy: 0.936\n",
      "iteration 33 260\t loss: 0.501, accuracy: 0.933\n",
      "iteration 33 280\t loss: 0.644, accuracy: 0.935\n",
      "iteration 34 0\t loss: 0.653, accuracy: 0.931\n",
      "iteration 34 20\t loss: 0.544, accuracy: 0.926\n",
      "iteration 34 40\t loss: 0.512, accuracy: 0.932\n",
      "iteration 34 60\t loss: 0.463, accuracy: 0.932\n",
      "iteration 34 80\t loss: 0.508, accuracy: 0.937\n",
      "iteration 34 100\t loss: 0.491, accuracy: 0.930\n",
      "iteration 34 120\t loss: 0.422, accuracy: 0.936\n",
      "iteration 34 140\t loss: 0.401, accuracy: 0.939\n",
      "iteration 34 160\t loss: 0.555, accuracy: 0.933\n",
      "iteration 34 180\t loss: 0.529, accuracy: 0.937\n",
      "iteration 34 200\t loss: 0.484, accuracy: 0.938\n",
      "iteration 34 220\t loss: 0.509, accuracy: 0.939\n",
      "iteration 34 240\t loss: 0.642, accuracy: 0.935\n",
      "iteration 34 260\t loss: 0.548, accuracy: 0.937\n",
      "iteration 34 280\t loss: 0.505, accuracy: 0.937\n",
      "iteration 35 0\t loss: 0.512, accuracy: 0.935\n",
      "iteration 35 20\t loss: 0.600, accuracy: 0.931\n",
      "iteration 35 40\t loss: 0.487, accuracy: 0.937\n",
      "iteration 35 60\t loss: 0.510, accuracy: 0.936\n",
      "iteration 35 80\t loss: 0.526, accuracy: 0.934\n",
      "iteration 35 100\t loss: 0.545, accuracy: 0.929\n",
      "iteration 35 120\t loss: 0.504, accuracy: 0.932\n",
      "iteration 35 140\t loss: 0.577, accuracy: 0.933\n",
      "iteration 35 160\t loss: 0.567, accuracy: 0.930\n",
      "iteration 35 180\t loss: 0.682, accuracy: 0.931\n",
      "iteration 35 200\t loss: 0.452, accuracy: 0.933\n",
      "iteration 35 220\t loss: 0.491, accuracy: 0.936\n",
      "iteration 35 240\t loss: 0.511, accuracy: 0.933\n",
      "iteration 35 260\t loss: 0.502, accuracy: 0.934\n",
      "iteration 35 280\t loss: 0.577, accuracy: 0.935\n",
      "iteration 36 0\t loss: 0.592, accuracy: 0.935\n",
      "iteration 36 20\t loss: 0.477, accuracy: 0.938\n",
      "iteration 36 40\t loss: 0.527, accuracy: 0.934\n",
      "iteration 36 60\t loss: 0.559, accuracy: 0.930\n",
      "iteration 36 80\t loss: 0.563, accuracy: 0.933\n",
      "iteration 36 100\t loss: 0.642, accuracy: 0.931\n",
      "iteration 36 120\t loss: 0.529, accuracy: 0.929\n",
      "iteration 36 140\t loss: 0.510, accuracy: 0.932\n",
      "iteration 36 160\t loss: 0.494, accuracy: 0.926\n",
      "iteration 36 180\t loss: 0.518, accuracy: 0.933\n",
      "iteration 36 200\t loss: 0.562, accuracy: 0.936\n",
      "iteration 36 220\t loss: 0.477, accuracy: 0.930\n",
      "iteration 36 240\t loss: 0.502, accuracy: 0.936\n",
      "iteration 36 260\t loss: 0.493, accuracy: 0.938\n",
      "iteration 36 280\t loss: 0.529, accuracy: 0.941\n",
      "iteration 37 0\t loss: 0.551, accuracy: 0.939\n",
      "iteration 37 20\t loss: 0.554, accuracy: 0.937\n",
      "iteration 37 40\t loss: 0.473, accuracy: 0.937\n",
      "iteration 37 60\t loss: 0.522, accuracy: 0.940\n",
      "iteration 37 80\t loss: 0.660, accuracy: 0.934\n",
      "iteration 37 100\t loss: 0.478, accuracy: 0.932\n",
      "iteration 37 120\t loss: 0.516, accuracy: 0.936\n",
      "iteration 37 140\t loss: 0.618, accuracy: 0.927\n",
      "iteration 37 160\t loss: 0.516, accuracy: 0.935\n",
      "iteration 37 180\t loss: 0.512, accuracy: 0.932\n",
      "iteration 37 200\t loss: 0.509, accuracy: 0.933\n",
      "iteration 37 220\t loss: 0.515, accuracy: 0.936\n",
      "iteration 37 240\t loss: 0.564, accuracy: 0.930\n",
      "iteration 37 260\t loss: 0.499, accuracy: 0.935\n",
      "iteration 37 280\t loss: 0.537, accuracy: 0.935\n",
      "iteration 38 0\t loss: 0.536, accuracy: 0.936\n",
      "iteration 38 20\t loss: 0.571, accuracy: 0.935\n",
      "iteration 38 40\t loss: 0.503, accuracy: 0.936\n",
      "iteration 38 60\t loss: 0.542, accuracy: 0.936\n",
      "iteration 38 80\t loss: 0.548, accuracy: 0.934\n",
      "iteration 38 100\t loss: 0.532, accuracy: 0.928\n",
      "iteration 38 120\t loss: 0.550, accuracy: 0.933\n",
      "iteration 38 140\t loss: 0.528, accuracy: 0.934\n",
      "iteration 38 160\t loss: 0.473, accuracy: 0.931\n",
      "iteration 38 180\t loss: 0.513, accuracy: 0.936\n",
      "iteration 38 200\t loss: 0.513, accuracy: 0.934\n",
      "iteration 38 220\t loss: 0.481, accuracy: 0.933\n",
      "iteration 38 240\t loss: 0.534, accuracy: 0.930\n",
      "iteration 38 260\t loss: 0.514, accuracy: 0.931\n",
      "iteration 38 280\t loss: 0.605, accuracy: 0.934\n",
      "iteration 39 0\t loss: 0.586, accuracy: 0.932\n",
      "iteration 39 20\t loss: 0.552, accuracy: 0.930\n",
      "iteration 39 40\t loss: 0.458, accuracy: 0.931\n",
      "iteration 39 60\t loss: 0.560, accuracy: 0.934\n",
      "iteration 39 80\t loss: 0.653, accuracy: 0.930\n",
      "iteration 39 100\t loss: 0.597, accuracy: 0.929\n",
      "iteration 39 120\t loss: 0.552, accuracy: 0.931\n",
      "iteration 39 140\t loss: 0.669, accuracy: 0.921\n",
      "iteration 39 160\t loss: 0.588, accuracy: 0.922\n",
      "iteration 39 180\t loss: 0.496, accuracy: 0.928\n",
      "iteration 39 200\t loss: 0.507, accuracy: 0.930\n",
      "iteration 39 220\t loss: 0.555, accuracy: 0.930\n",
      "iteration 39 240\t loss: 0.534, accuracy: 0.934\n",
      "iteration 39 260\t loss: 0.515, accuracy: 0.931\n",
      "iteration 39 280\t loss: 0.577, accuracy: 0.924\n",
      "iteration 40 0\t loss: 0.557, accuracy: 0.924\n",
      "iteration 40 20\t loss: 0.473, accuracy: 0.929\n",
      "iteration 40 40\t loss: 0.461, accuracy: 0.928\n",
      "iteration 40 60\t loss: 0.505, accuracy: 0.937\n",
      "iteration 40 80\t loss: 0.563, accuracy: 0.934\n",
      "iteration 40 100\t loss: 0.477, accuracy: 0.936\n",
      "iteration 40 120\t loss: 0.590, accuracy: 0.936\n",
      "iteration 40 140\t loss: 0.553, accuracy: 0.936\n",
      "iteration 40 160\t loss: 0.645, accuracy: 0.930\n",
      "iteration 40 180\t loss: 0.683, accuracy: 0.931\n",
      "iteration 40 200\t loss: 0.494, accuracy: 0.937\n",
      "iteration 40 220\t loss: 0.544, accuracy: 0.937\n",
      "iteration 40 240\t loss: 0.580, accuracy: 0.935\n",
      "iteration 40 260\t loss: 0.533, accuracy: 0.933\n",
      "iteration 40 280\t loss: 0.620, accuracy: 0.936\n",
      "iteration 41 0\t loss: 0.678, accuracy: 0.937\n",
      "iteration 41 20\t loss: 0.670, accuracy: 0.932\n",
      "iteration 41 40\t loss: 0.673, accuracy: 0.930\n",
      "iteration 41 60\t loss: 0.463, accuracy: 0.929\n",
      "iteration 41 80\t loss: 0.554, accuracy: 0.929\n",
      "iteration 41 100\t loss: 0.489, accuracy: 0.932\n",
      "iteration 41 120\t loss: 0.542, accuracy: 0.933\n",
      "iteration 41 140\t loss: 0.512, accuracy: 0.935\n",
      "iteration 41 160\t loss: 0.552, accuracy: 0.931\n",
      "iteration 41 180\t loss: 0.516, accuracy: 0.926\n",
      "iteration 41 200\t loss: 0.469, accuracy: 0.933\n",
      "iteration 41 220\t loss: 0.599, accuracy: 0.924\n",
      "iteration 41 240\t loss: 0.508, accuracy: 0.935\n",
      "iteration 41 260\t loss: 0.522, accuracy: 0.937\n",
      "iteration 41 280\t loss: 0.594, accuracy: 0.934\n",
      "iteration 42 0\t loss: 0.534, accuracy: 0.936\n",
      "iteration 42 20\t loss: 0.438, accuracy: 0.933\n",
      "iteration 42 40\t loss: 0.538, accuracy: 0.937\n",
      "iteration 42 60\t loss: 0.492, accuracy: 0.935\n",
      "iteration 42 80\t loss: 0.547, accuracy: 0.938\n",
      "iteration 42 100\t loss: 0.502, accuracy: 0.936\n",
      "iteration 42 120\t loss: 0.527, accuracy: 0.934\n",
      "iteration 42 140\t loss: 0.524, accuracy: 0.931\n",
      "iteration 42 160\t loss: 0.559, accuracy: 0.935\n",
      "iteration 42 180\t loss: 0.595, accuracy: 0.937\n",
      "iteration 42 200\t loss: 0.546, accuracy: 0.940\n",
      "iteration 42 220\t loss: 0.561, accuracy: 0.931\n",
      "iteration 42 240\t loss: 0.467, accuracy: 0.933\n",
      "iteration 42 260\t loss: 0.525, accuracy: 0.933\n",
      "iteration 42 280\t loss: 0.538, accuracy: 0.928\n",
      "iteration 43 0\t loss: 0.552, accuracy: 0.930\n",
      "iteration 43 20\t loss: 0.571, accuracy: 0.936\n",
      "iteration 43 40\t loss: 0.659, accuracy: 0.934\n",
      "iteration 43 60\t loss: 0.577, accuracy: 0.932\n",
      "iteration 43 80\t loss: 0.561, accuracy: 0.934\n",
      "iteration 43 100\t loss: 0.618, accuracy: 0.932\n",
      "iteration 43 120\t loss: 0.518, accuracy: 0.931\n",
      "iteration 43 140\t loss: 0.522, accuracy: 0.931\n",
      "iteration 43 160\t loss: 0.555, accuracy: 0.930\n",
      "iteration 43 180\t loss: 0.529, accuracy: 0.932\n",
      "iteration 43 200\t loss: 0.664, accuracy: 0.937\n",
      "iteration 43 220\t loss: 0.666, accuracy: 0.935\n",
      "iteration 43 240\t loss: 0.436, accuracy: 0.933\n",
      "iteration 43 260\t loss: 0.574, accuracy: 0.933\n",
      "iteration 43 280\t loss: 0.588, accuracy: 0.923\n",
      "iteration 44 0\t loss: 0.501, accuracy: 0.929\n",
      "iteration 44 20\t loss: 0.604, accuracy: 0.931\n",
      "iteration 44 40\t loss: 0.549, accuracy: 0.930\n",
      "iteration 44 60\t loss: 0.577, accuracy: 0.931\n",
      "iteration 44 80\t loss: 0.572, accuracy: 0.936\n",
      "iteration 44 100\t loss: 0.574, accuracy: 0.929\n",
      "iteration 44 120\t loss: 0.570, accuracy: 0.934\n",
      "iteration 44 140\t loss: 0.586, accuracy: 0.932\n",
      "iteration 44 160\t loss: 0.652, accuracy: 0.934\n",
      "iteration 44 180\t loss: 0.729, accuracy: 0.930\n",
      "iteration 44 200\t loss: 0.637, accuracy: 0.931\n",
      "iteration 44 220\t loss: 0.545, accuracy: 0.931\n",
      "iteration 44 240\t loss: 0.564, accuracy: 0.929\n",
      "iteration 44 260\t loss: 0.513, accuracy: 0.939\n",
      "iteration 44 280\t loss: 0.565, accuracy: 0.940\n",
      "iteration 45 0\t loss: 0.615, accuracy: 0.934\n",
      "iteration 45 20\t loss: 0.538, accuracy: 0.935\n",
      "iteration 45 40\t loss: 0.531, accuracy: 0.935\n",
      "iteration 45 60\t loss: 0.528, accuracy: 0.932\n",
      "iteration 45 80\t loss: 0.563, accuracy: 0.933\n",
      "iteration 45 100\t loss: 0.519, accuracy: 0.924\n",
      "iteration 45 120\t loss: 0.473, accuracy: 0.937\n",
      "iteration 45 140\t loss: 0.517, accuracy: 0.935\n",
      "iteration 45 160\t loss: 0.616, accuracy: 0.934\n",
      "iteration 45 180\t loss: 0.562, accuracy: 0.936\n",
      "iteration 45 200\t loss: 0.520, accuracy: 0.936\n",
      "iteration 45 220\t loss: 0.569, accuracy: 0.935\n",
      "iteration 45 240\t loss: 0.526, accuracy: 0.933\n",
      "iteration 45 260\t loss: 0.550, accuracy: 0.930\n",
      "iteration 45 280\t loss: 0.616, accuracy: 0.935\n",
      "iteration 46 0\t loss: 0.619, accuracy: 0.934\n",
      "iteration 46 20\t loss: 0.594, accuracy: 0.924\n",
      "iteration 46 40\t loss: 0.610, accuracy: 0.924\n",
      "iteration 46 60\t loss: 0.530, accuracy: 0.930\n",
      "iteration 46 80\t loss: 0.463, accuracy: 0.932\n",
      "iteration 46 100\t loss: 0.492, accuracy: 0.934\n",
      "iteration 46 120\t loss: 0.528, accuracy: 0.932\n",
      "iteration 46 140\t loss: 0.567, accuracy: 0.935\n",
      "iteration 46 160\t loss: 0.641, accuracy: 0.934\n",
      "iteration 46 180\t loss: 0.720, accuracy: 0.931\n",
      "iteration 46 200\t loss: 0.568, accuracy: 0.934\n",
      "iteration 46 220\t loss: 0.458, accuracy: 0.930\n",
      "iteration 46 240\t loss: 0.486, accuracy: 0.932\n",
      "iteration 46 260\t loss: 0.448, accuracy: 0.938\n",
      "iteration 46 280\t loss: 0.501, accuracy: 0.937\n",
      "iteration 47 0\t loss: 0.548, accuracy: 0.938\n",
      "iteration 47 20\t loss: 0.545, accuracy: 0.938\n",
      "iteration 47 40\t loss: 0.508, accuracy: 0.928\n",
      "iteration 47 60\t loss: 0.466, accuracy: 0.930\n",
      "iteration 47 80\t loss: 0.498, accuracy: 0.933\n",
      "iteration 47 100\t loss: 0.548, accuracy: 0.931\n",
      "iteration 47 120\t loss: 0.541, accuracy: 0.932\n",
      "iteration 47 140\t loss: 0.556, accuracy: 0.934\n",
      "iteration 47 160\t loss: 0.682, accuracy: 0.930\n",
      "iteration 47 180\t loss: 0.609, accuracy: 0.930\n",
      "iteration 47 200\t loss: 0.658, accuracy: 0.934\n",
      "iteration 47 220\t loss: 0.664, accuracy: 0.935\n",
      "iteration 47 240\t loss: 0.541, accuracy: 0.931\n",
      "iteration 47 260\t loss: 0.486, accuracy: 0.936\n",
      "iteration 47 280\t loss: 0.593, accuracy: 0.935\n",
      "iteration 48 0\t loss: 0.639, accuracy: 0.934\n",
      "iteration 48 20\t loss: 0.611, accuracy: 0.931\n",
      "iteration 48 40\t loss: 0.679, accuracy: 0.929\n",
      "iteration 48 60\t loss: 0.614, accuracy: 0.924\n",
      "iteration 48 80\t loss: 0.725, accuracy: 0.930\n",
      "iteration 48 100\t loss: 0.629, accuracy: 0.932\n",
      "iteration 48 120\t loss: 0.510, accuracy: 0.932\n",
      "iteration 48 140\t loss: 0.661, accuracy: 0.933\n",
      "iteration 48 160\t loss: 0.629, accuracy: 0.925\n",
      "iteration 48 180\t loss: 0.592, accuracy: 0.930\n",
      "iteration 48 200\t loss: 0.513, accuracy: 0.933\n",
      "iteration 48 220\t loss: 0.591, accuracy: 0.933\n",
      "iteration 48 240\t loss: 0.547, accuracy: 0.936\n",
      "iteration 48 260\t loss: 0.492, accuracy: 0.936\n",
      "iteration 48 280\t loss: 0.504, accuracy: 0.936\n",
      "iteration 49 0\t loss: 0.578, accuracy: 0.937\n",
      "iteration 49 20\t loss: 0.625, accuracy: 0.939\n",
      "iteration 49 40\t loss: 0.637, accuracy: 0.937\n",
      "iteration 49 60\t loss: 0.581, accuracy: 0.939\n",
      "iteration 49 80\t loss: 0.691, accuracy: 0.932\n",
      "iteration 49 100\t loss: 0.620, accuracy: 0.929\n",
      "iteration 49 120\t loss: 0.597, accuracy: 0.933\n",
      "iteration 49 140\t loss: 0.603, accuracy: 0.929\n",
      "iteration 49 160\t loss: 0.609, accuracy: 0.932\n",
      "iteration 49 180\t loss: 0.592, accuracy: 0.935\n",
      "iteration 49 200\t loss: 0.539, accuracy: 0.935\n",
      "iteration 49 220\t loss: 0.574, accuracy: 0.933\n",
      "iteration 49 240\t loss: 0.598, accuracy: 0.930\n",
      "iteration 49 260\t loss: 0.573, accuracy: 0.931\n",
      "iteration 49 280\t loss: 0.583, accuracy: 0.935\n",
      "iteration 50 0\t loss: 0.633, accuracy: 0.931\n",
      "iteration 50 20\t loss: 0.436, accuracy: 0.935\n",
      "iteration 50 40\t loss: 0.562, accuracy: 0.934\n",
      "iteration 50 60\t loss: 0.590, accuracy: 0.933\n",
      "iteration 50 80\t loss: 0.576, accuracy: 0.933\n",
      "iteration 50 100\t loss: 0.619, accuracy: 0.929\n",
      "iteration 50 120\t loss: 0.527, accuracy: 0.928\n",
      "iteration 50 140\t loss: 0.559, accuracy: 0.933\n",
      "iteration 50 160\t loss: 0.624, accuracy: 0.937\n",
      "iteration 50 180\t loss: 0.779, accuracy: 0.936\n",
      "iteration 50 200\t loss: 0.625, accuracy: 0.936\n",
      "iteration 50 220\t loss: 0.490, accuracy: 0.934\n",
      "iteration 50 240\t loss: 0.604, accuracy: 0.935\n",
      "iteration 50 260\t loss: 0.542, accuracy: 0.933\n",
      "iteration 50 280\t loss: 0.584, accuracy: 0.934\n",
      "iteration 51 0\t loss: 0.621, accuracy: 0.933\n",
      "iteration 51 20\t loss: 0.731, accuracy: 0.932\n",
      "iteration 51 40\t loss: 0.666, accuracy: 0.928\n",
      "iteration 51 60\t loss: 0.581, accuracy: 0.933\n",
      "iteration 51 80\t loss: 0.546, accuracy: 0.937\n",
      "iteration 51 100\t loss: 0.588, accuracy: 0.934\n",
      "iteration 51 120\t loss: 0.613, accuracy: 0.937\n",
      "iteration 51 140\t loss: 0.548, accuracy: 0.936\n",
      "iteration 51 160\t loss: 0.615, accuracy: 0.933\n",
      "iteration 51 180\t loss: 0.644, accuracy: 0.937\n",
      "iteration 51 200\t loss: 0.615, accuracy: 0.934\n",
      "iteration 51 220\t loss: 0.639, accuracy: 0.935\n",
      "iteration 51 240\t loss: 0.750, accuracy: 0.931\n",
      "iteration 51 260\t loss: 0.656, accuracy: 0.931\n",
      "iteration 51 280\t loss: 0.638, accuracy: 0.932\n",
      "iteration 52 0\t loss: 0.653, accuracy: 0.931\n",
      "iteration 52 20\t loss: 0.797, accuracy: 0.928\n",
      "iteration 52 40\t loss: 0.637, accuracy: 0.931\n",
      "iteration 52 60\t loss: 0.600, accuracy: 0.931\n",
      "iteration 52 80\t loss: 0.634, accuracy: 0.931\n",
      "iteration 52 100\t loss: 0.591, accuracy: 0.930\n",
      "iteration 52 120\t loss: 0.656, accuracy: 0.933\n",
      "iteration 52 140\t loss: 0.586, accuracy: 0.930\n",
      "iteration 52 160\t loss: 0.550, accuracy: 0.925\n",
      "iteration 52 180\t loss: 0.566, accuracy: 0.933\n",
      "iteration 52 200\t loss: 0.481, accuracy: 0.936\n",
      "iteration 52 220\t loss: 0.573, accuracy: 0.936\n",
      "iteration 52 240\t loss: 0.579, accuracy: 0.933\n",
      "iteration 52 260\t loss: 0.527, accuracy: 0.937\n",
      "iteration 52 280\t loss: 0.602, accuracy: 0.936\n",
      "iteration 53 0\t loss: 0.643, accuracy: 0.931\n",
      "iteration 53 20\t loss: 0.553, accuracy: 0.936\n",
      "iteration 53 40\t loss: 0.627, accuracy: 0.934\n",
      "iteration 53 60\t loss: 0.647, accuracy: 0.934\n",
      "iteration 53 80\t loss: 0.667, accuracy: 0.938\n",
      "iteration 53 100\t loss: 0.679, accuracy: 0.933\n",
      "iteration 53 120\t loss: 0.559, accuracy: 0.935\n",
      "iteration 53 140\t loss: 0.504, accuracy: 0.931\n",
      "iteration 53 160\t loss: 0.632, accuracy: 0.935\n",
      "iteration 53 180\t loss: 0.702, accuracy: 0.933\n",
      "iteration 53 200\t loss: 0.669, accuracy: 0.931\n",
      "iteration 53 220\t loss: 0.662, accuracy: 0.930\n",
      "iteration 53 240\t loss: 0.631, accuracy: 0.935\n",
      "iteration 53 260\t loss: 0.602, accuracy: 0.936\n",
      "iteration 53 280\t loss: 0.614, accuracy: 0.930\n",
      "iteration 54 0\t loss: 0.623, accuracy: 0.932\n",
      "iteration 54 20\t loss: 0.659, accuracy: 0.932\n",
      "iteration 54 40\t loss: 0.557, accuracy: 0.919\n",
      "iteration 54 60\t loss: 0.685, accuracy: 0.925\n",
      "iteration 54 80\t loss: 0.540, accuracy: 0.928\n",
      "iteration 54 100\t loss: 0.580, accuracy: 0.930\n",
      "iteration 54 120\t loss: 0.577, accuracy: 0.933\n",
      "iteration 54 140\t loss: 0.497, accuracy: 0.932\n",
      "iteration 54 160\t loss: 0.569, accuracy: 0.933\n",
      "iteration 54 180\t loss: 0.571, accuracy: 0.934\n",
      "iteration 54 200\t loss: 0.664, accuracy: 0.936\n",
      "iteration 54 220\t loss: 0.630, accuracy: 0.933\n",
      "iteration 54 240\t loss: 0.621, accuracy: 0.935\n",
      "iteration 54 260\t loss: 0.661, accuracy: 0.935\n",
      "iteration 54 280\t loss: 0.654, accuracy: 0.935\n",
      "iteration 55 0\t loss: 0.667, accuracy: 0.936\n",
      "iteration 55 20\t loss: 0.744, accuracy: 0.929\n",
      "iteration 55 40\t loss: 0.652, accuracy: 0.933\n",
      "iteration 55 60\t loss: 0.662, accuracy: 0.930\n",
      "iteration 55 80\t loss: 0.544, accuracy: 0.931\n",
      "iteration 55 100\t loss: 0.664, accuracy: 0.934\n",
      "iteration 55 120\t loss: 0.668, accuracy: 0.936\n",
      "iteration 55 140\t loss: 0.567, accuracy: 0.931\n",
      "iteration 55 160\t loss: 0.574, accuracy: 0.931\n",
      "iteration 55 180\t loss: 0.521, accuracy: 0.932\n",
      "iteration 55 200\t loss: 0.676, accuracy: 0.932\n",
      "iteration 55 220\t loss: 0.590, accuracy: 0.931\n",
      "iteration 55 240\t loss: 0.593, accuracy: 0.935\n",
      "iteration 55 260\t loss: 0.594, accuracy: 0.934\n",
      "iteration 55 280\t loss: 0.609, accuracy: 0.935\n",
      "iteration 56 0\t loss: 0.694, accuracy: 0.934\n",
      "iteration 56 20\t loss: 0.551, accuracy: 0.934\n",
      "iteration 56 40\t loss: 0.544, accuracy: 0.932\n",
      "iteration 56 60\t loss: 0.535, accuracy: 0.937\n",
      "iteration 56 80\t loss: 0.613, accuracy: 0.938\n",
      "iteration 56 100\t loss: 0.649, accuracy: 0.935\n",
      "iteration 56 120\t loss: 0.544, accuracy: 0.935\n",
      "iteration 56 140\t loss: 0.547, accuracy: 0.930\n",
      "iteration 56 160\t loss: 0.528, accuracy: 0.936\n",
      "iteration 56 180\t loss: 0.553, accuracy: 0.935\n",
      "iteration 56 200\t loss: 0.568, accuracy: 0.937\n",
      "iteration 56 220\t loss: 0.546, accuracy: 0.936\n",
      "iteration 56 240\t loss: 0.625, accuracy: 0.932\n",
      "iteration 56 260\t loss: 0.581, accuracy: 0.936\n",
      "iteration 56 280\t loss: 0.628, accuracy: 0.932\n",
      "iteration 57 0\t loss: 0.688, accuracy: 0.928\n",
      "iteration 57 20\t loss: 0.592, accuracy: 0.933\n",
      "iteration 57 40\t loss: 0.745, accuracy: 0.931\n",
      "iteration 57 60\t loss: 0.643, accuracy: 0.932\n",
      "iteration 57 80\t loss: 0.501, accuracy: 0.934\n",
      "iteration 57 100\t loss: 0.547, accuracy: 0.931\n",
      "iteration 57 120\t loss: 0.634, accuracy: 0.936\n",
      "iteration 57 140\t loss: 0.637, accuracy: 0.934\n",
      "iteration 57 160\t loss: 0.658, accuracy: 0.933\n",
      "iteration 57 180\t loss: 0.613, accuracy: 0.931\n",
      "iteration 57 200\t loss: 0.732, accuracy: 0.933\n",
      "iteration 57 220\t loss: 0.673, accuracy: 0.932\n",
      "iteration 57 240\t loss: 0.632, accuracy: 0.933\n",
      "iteration 57 260\t loss: 0.615, accuracy: 0.934\n",
      "iteration 57 280\t loss: 0.617, accuracy: 0.937\n",
      "iteration 58 0\t loss: 0.677, accuracy: 0.936\n",
      "iteration 58 20\t loss: 0.725, accuracy: 0.935\n",
      "iteration 58 40\t loss: 0.500, accuracy: 0.936\n",
      "iteration 58 60\t loss: 0.555, accuracy: 0.932\n",
      "iteration 58 80\t loss: 0.605, accuracy: 0.936\n",
      "iteration 58 100\t loss: 0.684, accuracy: 0.934\n",
      "iteration 58 120\t loss: 0.573, accuracy: 0.935\n",
      "iteration 58 140\t loss: 0.603, accuracy: 0.938\n",
      "iteration 58 160\t loss: 0.657, accuracy: 0.935\n",
      "iteration 58 180\t loss: 0.638, accuracy: 0.932\n",
      "iteration 58 200\t loss: 0.599, accuracy: 0.931\n",
      "iteration 58 220\t loss: 0.564, accuracy: 0.935\n",
      "iteration 58 240\t loss: 0.599, accuracy: 0.936\n",
      "iteration 58 260\t loss: 0.546, accuracy: 0.937\n",
      "iteration 58 280\t loss: 0.580, accuracy: 0.933\n",
      "iteration 59 0\t loss: 0.750, accuracy: 0.928\n",
      "iteration 59 20\t loss: 0.588, accuracy: 0.932\n",
      "iteration 59 40\t loss: 0.567, accuracy: 0.928\n",
      "iteration 59 60\t loss: 0.510, accuracy: 0.929\n",
      "iteration 59 80\t loss: 0.592, accuracy: 0.930\n",
      "iteration 59 100\t loss: 0.621, accuracy: 0.930\n",
      "iteration 59 120\t loss: 0.508, accuracy: 0.932\n",
      "iteration 59 140\t loss: 0.567, accuracy: 0.938\n",
      "iteration 59 160\t loss: 0.664, accuracy: 0.927\n",
      "iteration 59 180\t loss: 0.637, accuracy: 0.930\n",
      "iteration 59 200\t loss: 0.668, accuracy: 0.928\n",
      "iteration 59 220\t loss: 0.526, accuracy: 0.934\n",
      "iteration 59 240\t loss: 0.612, accuracy: 0.934\n",
      "iteration 59 260\t loss: 0.529, accuracy: 0.931\n",
      "iteration 59 280\t loss: 0.617, accuracy: 0.932\n",
      "iteration 60 0\t loss: 0.638, accuracy: 0.931\n",
      "iteration 60 20\t loss: 0.546, accuracy: 0.932\n",
      "iteration 60 40\t loss: 0.581, accuracy: 0.931\n",
      "iteration 60 60\t loss: 0.721, accuracy: 0.933\n",
      "iteration 60 80\t loss: 0.672, accuracy: 0.932\n",
      "iteration 60 100\t loss: 0.601, accuracy: 0.932\n",
      "iteration 60 120\t loss: 0.574, accuracy: 0.930\n",
      "iteration 60 140\t loss: 0.500, accuracy: 0.933\n",
      "iteration 60 160\t loss: 0.549, accuracy: 0.931\n",
      "iteration 60 180\t loss: 0.617, accuracy: 0.931\n",
      "iteration 60 200\t loss: 0.601, accuracy: 0.934\n",
      "iteration 60 220\t loss: 0.677, accuracy: 0.928\n",
      "iteration 60 240\t loss: 0.613, accuracy: 0.936\n",
      "iteration 60 260\t loss: 0.667, accuracy: 0.933\n",
      "iteration 60 280\t loss: 0.772, accuracy: 0.931\n",
      "iteration 61 0\t loss: 0.802, accuracy: 0.929\n",
      "iteration 61 20\t loss: 0.667, accuracy: 0.934\n",
      "iteration 61 40\t loss: 0.704, accuracy: 0.930\n",
      "iteration 61 60\t loss: 0.648, accuracy: 0.935\n",
      "iteration 61 80\t loss: 0.627, accuracy: 0.937\n",
      "iteration 61 100\t loss: 0.675, accuracy: 0.935\n",
      "iteration 61 120\t loss: 0.693, accuracy: 0.938\n",
      "iteration 61 140\t loss: 0.633, accuracy: 0.940\n",
      "iteration 61 160\t loss: 0.746, accuracy: 0.933\n",
      "iteration 61 180\t loss: 0.768, accuracy: 0.927\n",
      "iteration 61 200\t loss: 0.747, accuracy: 0.931\n",
      "iteration 61 220\t loss: 0.724, accuracy: 0.927\n",
      "iteration 61 240\t loss: 0.633, accuracy: 0.929\n",
      "iteration 61 260\t loss: 0.711, accuracy: 0.929\n",
      "iteration 61 280\t loss: 0.680, accuracy: 0.933\n",
      "iteration 62 0\t loss: 0.623, accuracy: 0.930\n",
      "iteration 62 20\t loss: 0.552, accuracy: 0.931\n",
      "iteration 62 40\t loss: 0.543, accuracy: 0.932\n",
      "iteration 62 60\t loss: 0.732, accuracy: 0.932\n",
      "iteration 62 80\t loss: 0.692, accuracy: 0.927\n",
      "iteration 62 100\t loss: 0.761, accuracy: 0.929\n",
      "iteration 62 120\t loss: 0.475, accuracy: 0.928\n",
      "iteration 62 140\t loss: 0.524, accuracy: 0.933\n",
      "iteration 62 160\t loss: 0.559, accuracy: 0.928\n",
      "iteration 62 180\t loss: 0.552, accuracy: 0.932\n",
      "iteration 62 200\t loss: 0.703, accuracy: 0.933\n",
      "iteration 62 220\t loss: 0.652, accuracy: 0.933\n",
      "iteration 62 240\t loss: 0.742, accuracy: 0.923\n",
      "iteration 62 260\t loss: 0.563, accuracy: 0.929\n",
      "iteration 62 280\t loss: 0.686, accuracy: 0.934\n",
      "iteration 63 0\t loss: 0.800, accuracy: 0.930\n",
      "iteration 63 20\t loss: 0.723, accuracy: 0.922\n",
      "iteration 63 40\t loss: 0.577, accuracy: 0.932\n",
      "iteration 63 60\t loss: 0.613, accuracy: 0.930\n",
      "iteration 63 80\t loss: 0.617, accuracy: 0.930\n",
      "iteration 63 100\t loss: 0.775, accuracy: 0.930\n",
      "iteration 63 120\t loss: 0.607, accuracy: 0.929\n",
      "iteration 63 140\t loss: 0.765, accuracy: 0.925\n",
      "iteration 63 160\t loss: 0.742, accuracy: 0.930\n",
      "iteration 63 180\t loss: 0.646, accuracy: 0.932\n",
      "iteration 63 200\t loss: 0.712, accuracy: 0.933\n",
      "iteration 63 220\t loss: 0.627, accuracy: 0.930\n",
      "iteration 63 240\t loss: 0.767, accuracy: 0.928\n",
      "iteration 63 260\t loss: 0.555, accuracy: 0.931\n",
      "iteration 63 280\t loss: 0.565, accuracy: 0.930\n",
      "iteration 64 0\t loss: 0.641, accuracy: 0.926\n",
      "iteration 64 20\t loss: 0.561, accuracy: 0.932\n",
      "iteration 64 40\t loss: 0.491, accuracy: 0.933\n",
      "iteration 64 60\t loss: 0.701, accuracy: 0.932\n",
      "iteration 64 80\t loss: 0.650, accuracy: 0.936\n",
      "iteration 64 100\t loss: 0.625, accuracy: 0.934\n",
      "iteration 64 120\t loss: 0.661, accuracy: 0.931\n",
      "iteration 64 140\t loss: 0.885, accuracy: 0.933\n",
      "iteration 64 160\t loss: 0.721, accuracy: 0.930\n",
      "iteration 64 180\t loss: 0.521, accuracy: 0.928\n",
      "iteration 64 200\t loss: 0.543, accuracy: 0.926\n",
      "iteration 64 220\t loss: 0.615, accuracy: 0.932\n",
      "iteration 64 240\t loss: 0.524, accuracy: 0.933\n",
      "iteration 64 260\t loss: 0.483, accuracy: 0.934\n",
      "iteration 64 280\t loss: 0.579, accuracy: 0.936\n",
      "iteration 65 0\t loss: 0.565, accuracy: 0.937\n",
      "iteration 65 20\t loss: 0.642, accuracy: 0.937\n",
      "iteration 65 40\t loss: 0.566, accuracy: 0.940\n",
      "iteration 65 60\t loss: 0.645, accuracy: 0.938\n",
      "iteration 65 80\t loss: 0.640, accuracy: 0.937\n"
     ]
    }
   ],
   "source": [
    "cnn_plus_dict_alex = apply_classification_loss_plus(cnn_vgg_net)\n",
    "new_train_model(cnn_plus_dict_alex, dataset_generators, epoch_n=100, print_every=20, load_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Training and testing visualization results for the above architecture:\n",
    "      \n",
    "1. Filters:\n",
    "\n",
    "<img src=\"filters_5.png\" style=\"weight:20px;\"> \n",
    "\n",
    "2. Loss:\n",
    "\n",
    "<img src=\"loss_5.png\" style=\"weight:20px;\"> \n",
    "\n",
    "3. Accuracy:\n",
    "\n",
    "<img src=\"accuracy_5.png\" style=\"weight:20px;\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
